[
  {
    "objectID": "posts/VSCode-setup/VSCode_setup.html",
    "href": "posts/VSCode-setup/VSCode_setup.html",
    "title": "VS Code Setup",
    "section": "",
    "text": "Python 개발에 적합한 다양한 통합개발환경(Intergrated Developement Enviroment, IDE) 중에서 PyCharm은 강력한 기능과 Django 통합을 제공하지만 시스템 자원을 많이 소모하며 유료입니다. Jupyter Notebook은 데이터 과학에 최적화되어 있지만, 대규모 코드베이스 관리나 전통적인 IDE 기능에는 제한이 있습니다. Spyder는 과학 계산에 특화되어 있으나, 범용 개발에는 한계가 있습니다. 반면, Visual Studio Code (VS Code)는 확장성이 뛰어나며 다양한 프로그래밍 언어 지원과 시스템 자원 소모가 적은 경량의 IDE로, 필요에 따라 확장 기능을 추가할 수 있어 Python 개발을 포함한 여러 프로젝트를 효과적으로 관리할 수 있습니다.\n연구회에서는 Python 개발에 VS Code를 우선 추천합니다.",
    "crumbs": [
      "Python",
      "VS Code Setup"
    ]
  },
  {
    "objectID": "posts/VSCode-setup/VSCode_setup.html#python-ide-추천",
    "href": "posts/VSCode-setup/VSCode_setup.html#python-ide-추천",
    "title": "VS Code Setup",
    "section": "",
    "text": "Python 개발에 적합한 다양한 통합개발환경(Intergrated Developement Enviroment, IDE) 중에서 PyCharm은 강력한 기능과 Django 통합을 제공하지만 시스템 자원을 많이 소모하며 유료입니다. Jupyter Notebook은 데이터 과학에 최적화되어 있지만, 대규모 코드베이스 관리나 전통적인 IDE 기능에는 제한이 있습니다. Spyder는 과학 계산에 특화되어 있으나, 범용 개발에는 한계가 있습니다. 반면, Visual Studio Code (VS Code)는 확장성이 뛰어나며 다양한 프로그래밍 언어 지원과 시스템 자원 소모가 적은 경량의 IDE로, 필요에 따라 확장 기능을 추가할 수 있어 Python 개발을 포함한 여러 프로젝트를 효과적으로 관리할 수 있습니다.\n연구회에서는 Python 개발에 VS Code를 우선 추천합니다.",
    "crumbs": [
      "Python",
      "VS Code Setup"
    ]
  },
  {
    "objectID": "posts/VSCode-setup/VSCode_setup.html#설치-안내",
    "href": "posts/VSCode-setup/VSCode_setup.html#설치-안내",
    "title": "VS Code Setup",
    "section": "설치 안내",
    "text": "설치 안내\n공식문서(https://code.visualstudio.com/docs/setup/setup-overview)에서 자신의 운영체제에 맞는 안내를 참고하는 것이 이상적이며, 아래의 요약을 참고하여 설치 하셔도 됩니다.",
    "crumbs": [
      "Python",
      "VS Code Setup"
    ]
  },
  {
    "objectID": "posts/VSCode-setup/VSCode_setup.html#설치-파일",
    "href": "posts/VSCode-setup/VSCode_setup.html#설치-파일",
    "title": "VS Code Setup",
    "section": "설치 파일",
    "text": "설치 파일\n공식 웹사이트(https://code.visualstudio.com/Download)에서 운영 체제에 맞는 최신 설치 파일을 다운로드하고 설치합니다. Window 운영체제에서 몇가지 선택이 가능한데 System installer (모든 사용자들이 VS Code가 사용가능한 설치파일)를 추천하며, 2024년 9월 29일 기준으로 Windows 운영 체제에는 VSCodeSetup-1.93.1.exe 파일이 최신입니다.",
    "crumbs": [
      "Python",
      "VS Code Setup"
    ]
  },
  {
    "objectID": "posts/VSCode-setup/VSCode_setup.html#설치-경로",
    "href": "posts/VSCode-setup/VSCode_setup.html#설치-경로",
    "title": "VS Code Setup",
    "section": "설치 경로",
    "text": "설치 경로\nWindow 운영체제의 경우 기본 설치경로는 C:\\Users\\{Username}\\AppData\\Local\\Programs\\Microsoft VS Code이며 이를 추천합니다.",
    "crumbs": [
      "Python",
      "VS Code Setup"
    ]
  },
  {
    "objectID": "posts/VSCode-setup/VSCode_setup.html#vs-code-레이아웃",
    "href": "posts/VSCode-setup/VSCode_setup.html#vs-code-레이아웃",
    "title": "VS Code Setup",
    "section": "VS Code 레이아웃",
    "text": "VS Code 레이아웃\n설정을 설명함에 있어 VS Code 공식문서(https://code.visualstudio.com/docs)에서 사용된 용어를 사용하고자 합니다. 레이아웃 구성요소에 대한 용어는 그림 1 을 참고하시길 바랍니다. 그러나 “타이틀 및 메뉴 바”와 같은 용어는 공식 문서에 명시적으로 정의되지 않았지만 명확한 설명을 위해 필요하다고 생각되어 여기에서는 임의적으로 정의하여 사용하겠습니다.\n\n\n\n\n\n\n그림 1: Basic layout of VS Code",
    "crumbs": [
      "Python",
      "VS Code Setup"
    ]
  },
  {
    "objectID": "posts/VSCode-setup/VSCode_setup.html#python-확장기능-설치",
    "href": "posts/VSCode-setup/VSCode_setup.html#python-확장기능-설치",
    "title": "VS Code Setup",
    "section": "Python 확장(기능) 설치",
    "text": "Python 확장(기능) 설치\nVS Code에서 Python을 실행코드를 작성 및 실행할려면 Python이라는 확장(기능)을 설치해야 합니다. VS Code를 처음 실행하면 환영 페이지가 표시됩니다. 이 페이지에서 Python 확장을 설치하거나 대신 Ⓐ Activity bar의 확장 메뉴를 사용하여 설치할 수 있습니다. 설치된 확장 프로그램은 확장 프로그램 메뉴의 INSTALLED 섹션에서 확인할 수 있습니다 (그림 2). 이로써 VS code에서 Python을 사용할 수 있는 기본적인 설정을 되었습니다.\n\n\n\n\n\n\n그림 2: Python Extension in VS Code",
    "crumbs": [
      "Python",
      "VS Code Setup"
    ]
  },
  {
    "objectID": "posts/VSCode-setup/VSCode_setup.html#프로젝트-폴더명-추천",
    "href": "posts/VSCode-setup/VSCode_setup.html#프로젝트-폴더명-추천",
    "title": "VS Code Setup",
    "section": "프로젝트 폴더명 추천",
    "text": "프로젝트 폴더명 추천\nR 처럼 Python에서도 프로젝트별 독립관리는 프로젝트 폴더 단위로 구현됩니다. 우리 연구회에서는 R과 Python을 사용하므로 C: 루트 디렉토리 아래에 Projects란 폴더를 만들고 각 실행파일의 버전이 폴더명에 먼저 포함되고 이어서 프로젝트를 상징하는 간결한 이름를 부여할 것을 추천합니다 (그림 3).\n\n\n\nC:\\Projects\\R-x'.y'.z'-Project_Name'\\            # R project directory and project name example\n         └─ Python-x.y.z-Project_Name\\  # Python project directory and project name example\n\n\n그림 3: Project folder location and name example",
    "crumbs": [
      "Python",
      "VS Code Setup"
    ]
  },
  {
    "objectID": "posts/VSCode-setup/VSCode_setup.html#프로젝트별-가상환경-만들기",
    "href": "posts/VSCode-setup/VSCode_setup.html#프로젝트별-가상환경-만들기",
    "title": "VS Code Setup",
    "section": "프로젝트별 가상환경 만들기",
    "text": "프로젝트별 가상환경 만들기\n파이썬 가상 환경은 개발자가 각기 다른 프로젝트에서 필요로 하는 다양한 라이브러리와 파이썬 버전을 독립적으로 관리할 수 있게 해줍니다. 이는 서로 다른 의존성 요구 사항을 가진 여러 프로젝트를 동일한 시스템에서 충돌 없이 운영할 수 있도록 하며, 개발 환경을 격리시켜 한 프로젝트에서 발생하는 문제가 다른 프로젝트에 영향을 미치지 않도록 합니다. 또한, 가상 환경은 프로젝트의 특정 설정을 쉽게 다른 환경으로 복제하거나 배포할 수 있도록 지원함으로써, 개발과 테스트, 프로덕션 환경 간의 일관성을 유지할 수 있게 해주고, 팀 작업에서도 각 개발자가 동일한 설정에서 작업할 수 있도록 도와줍니다. 이러한 이유로, 가상 환경은 프로젝트의 안정성과 개발 효율성을 크게 향상시키는 중요한 도구입니다. 다음은 VS Code에서 Python 가상 환경을 구현하는 방법을 설명합니다.\n\n프로젝트 폴더 생성\n앞서의 설명처럼 프로젝트 폴더를 만듭니다. 그러나 VS Code에서는 폴더를 직접 생성할 수 있는 옵션이 없습니다. 따라서 프로젝트 폴더를 만들기 위해 Windows 탐색기를 사용하는 것이 좋습니다. (대신 VS Code의 타이틀 및 메뉴 바에 있는 터미널 탭을 사용하여 프로젝트 폴더를 만들 수 있지만, 이 방법은 Windows 탐색기를 사용하는 것보다 더 번거로울 수 있습니다.) 예를 들어 프로젝트 폴더를 다음과 같이 이름을 지어 만듭니다(예: C:-x.y.z-Project_Name).\n\n\n프로젝트 폴더 열기\n탐색기 메뉴(Ⓐ Activity bar)나 타이틀 및 메뉴 바의 파일 메뉴를 사용하여 프로젝트 폴더를 엽니다. (이는 이후에 터미널을 열 때, 프로젝트 폴더에서 열리게 하기 위함입니다.)\n\n\n새터미널 생성\n타이틀 및 메뉴 바에서 터미널(T) 메뉴 하부의 새터미널 메뉴를 선택하여 새로운 터미널을 Ⓓ 패널에 열리게 합니다. 이 때 열린 터미널이 만약 powershell이라면 패널 타이틀 바 우측에 있는 +(새 터미널) 기호 옆의 v(시작 프로필)메뉴를 선택하고 (그림 4), 터미널의 종류를 Command Prompt를 선택하여 새로운 Command Prompt 터미널을 생성해 줍니다.\n\n\n\n\n\n\n그림 4: Command Prompt Terminal Creating\n\n\n\n\n\nPython 가상 환경 생성\n새롭게 만들어진 터미널 내에서 다음 명령을 입력 및 실행합니다.\n\n\n\nCommand Prompt Terminal\n\npython -m venv venv\n\n\n\n\n\n\n\n\npython -m venv venv 의미는 ……\n\n\n\n\n\nPython의 내장 모듈 venv를 사용하여 새로운 가상 환경을 생성하는 명령입니다.\n1. python 이 부분은 시스템에 설치된 Python 인터프리터를 호출합니다. 명령을 실행하는 시스템에서 기본적으로 설정된 Python 버전을 사용하여 다음에 지정된 모듈을 실행합니다.\n2. -m 플래그는 Python에게 명령 라인에서 직접 모듈을 실행하도록 지시합니다. 이 플래그 다음에 오는 모듈 이름(venv 등)에 해당하는 파이썬 모듈을 찾아 그 모듈을 스크립트처럼 실행하게 합니다.\n3. 첫번째 venv는 Python에 내장된 가상 환경 생성 모듈의 이름입니다. 이 모듈은 가상 환경을 생성, 관리, 유지하는 데 사용되며, 이 가상 환경은 독립된 Python 실행 환경을 제공합니다. 이 환경 내에서는 독립된 파이썬 인터프리터, 라이브러리, 스크립트가 포함되어 있습니다.\n4. 두번째 venv는 생성될 가상 환경의 디렉토리 이름입니다. 이 예에서는 현재 디렉토리 내에 ’venv’라는 이름의 폴더를 생성하고, 그 안에 가상 환경을 구축합니다. 디렉토리 이름은 사용자가 원하는 어떤 이름으로도 지정할 수 있으며, 이 이름으로 생성된 폴더 안에 가상 환경이 설정됩니다.\n따라서 python -m venv venv 명령은 현재 작업 중인 디렉토리에 ’venv’라는 이름의 폴더를 생성하고, 그 안에 새로운 독립적인 Python 가상 환경을 설정합니다. 이 가상 환경은 다른 프로젝트와 독립적으로 Python 패키지를 설치하고 관리할 수 있는 개별적인 환경을 제공합니다. 이는 의존성 충돌을 방지하고 프로젝트 별로 다른 요구사항을 갖는 라이브러리들을 효과적으로 관리할 수 있게 해 줍니다.\n\n\n\n위 명령의 실행결과로써 프로젝트 폴더아래에 venv 가상화폴더가 생성되었습니다. 이는 탐색기 의 프로젝트폴더 아래에 venv라는 폴더가 보이면 성공한 것입니다 (그림 5).\n\n\n\n\n\n\n그림 5: Validation of venv Folder Creation\n\n\n\n가상화로 만들어진 venv 폴더하부에는 다음과 같은 폴더와 파일이 생성됩니다 (그림 6).\n\n\n\n(venv)/\n   ├── Include/                  # Folder for C/C++ header files\n   ├── Lib/                      # Folder for standard libraries and third-party packages\n   │      └── site-packages/     # Folder where packages installed via pip are located\n   ├── Scripts/                  # Folder containing executable scripts, such as pip\n   │      ├── activate           # Script to activate the virtual environment\n   │      ├── deactivate         # Script to deactivate the virtual environment\n   │      ├── python.exe         # Python executable for the virtual environment\n   │      └── pip.exe            # pip executable for managing packages in the virtual environment\n   └── pyvenv.cfg                # Configuration file for the virtual environment\n\n\n\n그림 6: (venv) Directory Structure\n\n\n\n가상화환경 내에서는 pip로 패키지를 설치하면 글로벌에 설치되는 것이 아니라 venv 가상폴더 내의 site-packages 폴더에 설치됩니다. 이로써 프로젝트별로 필요한 패키지를 독립적으로 관리할 수 있게 되며, 이를 통해 프로젝트 간의 의존성 충돌을 방지할 수 있습니다.\n\n\n프로젝트와 가상환경 연결\n타이틀과 메뉴 바의 보기(V) 메뉴에서 명령 팔레트 메뉴를 선택하면, 선택가능한 명령들이 리스트로 조회되며 이 중에서 Python: 인터프리터 선택 메뉴를 선택합니다 (그림 7).\n\n\n\n\n\n\n그림 7: Select Interpreter in Command Palette\n\n\n\n위의 선택에 따라 현재 상황에서 선택 가능한 모든 Python 인터프리터가 조회되며, 이중에서 직전에 만든 프로젝트 폴더 아래의 venv 가상화폴더 아래의 Scripts 폴더 내의 python.exe를 선택합니다 (그림 8).\n\n\n\n\n\n\n그림 8: Interpreter Selection\n\n\n\n\n\n가상환경 검증\n가상환경의 python 인터프리터를 선택하여 특정 프로젝트와 특정 가상환경의 인터프리터를 연결하더라도 화면에서는 아무런 변화가 없습니다. 오류없이 연결이 잘 되었는지 확인은 새 터널을 생성하면 그림 9 에서의 같이 터미널의 프롬프트에 (venv)의 가상화폴더를 괄호로 둘러싼 것이 보이게 되며, 이를 통해 성공적인 연결을 확인할 수 있으며 현재 가상화가 활성화되어 있음을 알 수 있습니다.\n\n\n\n\n\n\n그림 9: Validation of Virtual Environment Activation",
    "crumbs": [
      "Python",
      "VS Code Setup"
    ]
  },
  {
    "objectID": "posts/VSCode-setup/VSCode_setup.html#프로젝트별-설정저장",
    "href": "posts/VSCode-setup/VSCode_setup.html#프로젝트별-설정저장",
    "title": "VS Code Setup",
    "section": "프로젝트별 설정저장",
    "text": "프로젝트별 설정저장\n프로젝트폴더에 가상환경설정까지 마친 후 이 상태를 저장해 둘 수 있습니다. 이를 위해 타이틀 및 메뉴 바의 파일(F) 메뉴에서 작업영역을 다름이름으로 저장 메뉴를 선택하면 됩니다 (그림 10).\n\n\n\n\n\n\n그림 10: Workspaces Save as function in File Menu\n\n\n\n이 때 프로젝트 폴더에 프로젝트폴더이름.code-workspace 파일이 만들어지면 프로젝트폴더의 설정이 저장됩니다 (그림 11). 그리고 프로젝트를 다시 열 때 이 파일을 선택하면 프로젝트폴더의 설정이 자동으로 불러와집니다.\n\n\n\n\n\n\n그림 11: code-workspace File Creation",
    "crumbs": [
      "Python",
      "VS Code Setup"
    ]
  },
  {
    "objectID": "posts/survival-analysis/survival_analysis.html",
    "href": "posts/survival-analysis/survival_analysis.html",
    "title": "Survival analysis",
    "section": "",
    "text": "인터넷검색 시 정리가 잘 된 부분을 발췌하였습니다.\n지루한 일상의 소중함 중에서 ……. https://every-day-life.tistory.com/30\n\n1. Kaplan-Meier curve\n상당수의 의학논문에서 생존분석을 이용해서 분석을 하는 경우, Kaplan-Meier curve를 제시하고 그 후 cox 분석을 주요분석법으로 사용한다. Kaplan curve를 보여주는 이유는 아무래도 단조로운 논문에 그래도 그림이 하나쯤은 필요하기 때문이기도 하지만 더 큰 이유는 cox 분석을 사용하기 위한 주요 가정 중 하나인 proportional hazard assumption을 만족하는지를 Kaplan curve가 rough하게 보여주기 때문이다.\n마지막으로 proportional hazard에 대한 언급을 해 보자. cox 분석은 여러 분석법 중 신경 쓸 일 많지 않은 쉬운 분석법 중에 하나이다. 하지만 비례위험 가정은 꼭!!! 어기면 안 된다.  비례위험 가정에 대해 예를 들어보면, 암환자의 경우 진단 후 초/중반에는 사망위험이 높지만 시간이 지날수록 사망 위험도는 점차 감소하다,  5년 이상 생존하는 경우 사망위험이 일반인보다 약간 높을 정도까지 낮아진다. 만약 새로운 항암제의 효과에 대해 연구하고 싶다면 신/구 항암제의 위험도 차이가 초반에나 후반에나 동일해야 한다는 것이다. \n\n왼쪽 그림과 같이 시간에 상관없이 위험도는 동일한 간격을 가져야 한다. 만약 오른쪽 그림과 같이 위험도가 일정한 간격을 지니지 않을 경우 시간에 대해 별도의 배려를 해야만 한다.  \n비례위험가정을 확인하는 법은 몇 가지 방법이 있지만 SPSS에서 가능한 방법은 누적위험함수 그래프를 확인하는 법과 Cox 분석 내에서의 time dependent covariate를 압력하는 방법 2가지 이다. 결과가 통계적으로 유의하더라도 Kaplan curve 및 위험함수 그래프에서 두 선이 접점을 가지게 되면 비례위험가정을 만족하지 못하는 것으로 생각하는 편이 맞다(정확히는 Scheonfeld residual을 구해서 확인해야 하는데 SPSS에서는 이 과정이 불가능하다.). 그리고 논문 첫 figure로 Kaplan curve를 넣는 이유 중 하나가 비례위험가정만족을 보여주는 그림이기 때문이다. 만약 Kaplan curve에서 두 선의 교차가 발생했는데도 불구하고 시간에 대한 별도의 배려 없이 논문이 진행되었다면 독자들은 그 이후 결과를 전체적으로 신뢰할 수 없게 될 것이다.  (상대적으로 Kaplan curve에서는 비례위험가정을 만족하더라도 대상자의 수가 적어지는 후반부에 교차(접점?)가 일어날 가능성이 있다. 다른 방법으로 비례위험가정을 확인했고 문제가 없다면 누적위험함수 그래프를 대신 제시하는 것도 하나의 방법이다.)\n\n\n2. Cox\nCox 분석의 정식 명칭은 proportional hazards model regression analysis이다. 정식 명칭을 보면 앞에서 왜 그토록  proportional hazard assumption을 강조했는지와, Cox 분석도 일반화선형회귀분석의 한 분류라는 것을 알 수 있다. 전체적인 분위기는 로지스틱회귀분석과 놀라울 정도로 닮아 있다. 잔차분석이 그리 중요하지 않다던가… 연속형 변수 사용에 유의해야 한다던가… \n시간의 분포를 보면 연구의 대략적인 결과를 파악할 수 있다. 생존분석에서 시간은 사망하거나(event), 연구에서 중도탈락(censoring)한 두 가지 경우 중 하나이다. 시간의 histogram을 보면 전체적으로 right shifted 된 느낌인 가운데 0과 200근처가 우뚝 서있는 것을 볼 수 있다. 0에 가까운 봉우리는 아마도 작심삼일 들일 것이며, 200에 가까운 봉우리는 연구 종료에 따른 censoring일 것이다. 위 그림을 보면 연구 종료를 제외하면 censoring이 없음을 알 수 있다. 이는 이 연구가 굉장히 잘 관리된 연구 결과임을 보여준다.\n \n대부분의 연구에서 무시되고 있는 내용인데, 생존분석에서 중도탈락은 무작위(random)하게 이루어지는 것으로 가정된다. 하지만 실제 연구에서는 중도탈락이 의미를 지니는 경우가 많다. 치료약의 부작용이 심하거나, 환자가 스스로 판단하기에 호전이 없을 경우, 무작위 배정 결과가 중간에 환자에게 노출되어 위약군 환자가 연구에서 빠져나가는 경우… 어찌 보면 중도탈락은 사망결과만큼이나 중요한 결과이지만 일반적인 cox분석 결과에서는 중도탈락을 결과물로 제시하지 않는다. 하지만 연구 결과를 판단할 때 신약의 치료효과가 아무리 좋더라도 이해할 수 없는 이유로 치료군 혹은 placebo군의 중도탈락이 반대편에 비해 의미가 있을 정도로 많다면 그 결과는 신뢰하지 않는 것이 바람직하다.\n로지스틱회귀분석에서와 같이 생존분석에서도 연속변수를 분석하는 데에는 주의가 따른다. 따라서 적절한 값을 기준으로 잘라서 범주형 변수로 분석하는 것이 합리적이다. 하지만 대상자의 수가 많지 않아서 범주형 변수로 잘랐을 때 통계적으로 유의해지지 않는다던가, 범주형 변수로 변환하더라도 어느 값을 기준으로 몇 개의 범주로 나누는 것이 합리적인지 판단할 때에는 연속형 변수를 이용한 분석이 도움이 될 때도 있다. 이때 사용되는 것이 Martingale 잔차이지만 SPSS에서는 이를 지원하지 않기 때문에, SPSS를 이용해서 생존분석을 하는 경우 연속형 변수를 분석에 투입하면 안 된다.\n변수를 범주화시킬 때 주의사항은 임상적인 의미를 가지는 절단점이 있는 경우 그 점을 우선시하되, 나눈 후 각 범주에 속한 대상자들이 어느 정도 균등해지는 것도 고려해야 한다. 만약 systolic BP를 기준으로 한다고 했을 때 가장 최적의 절단점은 140일 것이다. 하지만 어떤 이유로 140mmHg 이상 혹은 이하의 대상자가 아주 많거나 적으면 그 변수를 분석에 투입한다고 해도 의미를 잃을 것이다. 그렇다고 systoloc BP를 quantile 값으로 나눠서 넣으면 분석은 잘되겠지만, 논문의 심사자 혹은 독자들은 왜 이걸 이리 잘랐지?라는 의문을 가질 수밖에 없다. 따라서 케이스 바이 케이스의 적절한 판단이 요구될 수 밖에 없다.\nproportional hazard 가정을 확인하는 방법으로는\n1) Kaplan curve 이용한 육안적 확인\n2) Schenofeld residual 그래프 이용한 육안적 확인\n3) Scheonfeld method 이용한 통계적 확인\n4) time dependent covariate 투입 후 통계적 유의성 확인 \n4가지 방법이 있다. SPSS에서는 2와 3번 방법은 불가능하다. 하지만 생존분석에서 비례위험가정의 중요성을 감안하면 다른 방법이 존재하며 이 부분은 SPSS의 한계가 있음을 알아야 한다.\n\n\n폐암환자의 성별에 따른 Kaplan curve와 위험함수 그래프이다. 앞에서 언급했듯이 논문에 Kaplan curve를 넣는 이유는 비례위험가정을 만족하는지 확인하기 위함이라고 하였다. Cox 분석에서 통계적으로 유의성을 가지는 변수가 (유의성 없는 변수는 접점이 몇 개 있던 몇 번 교차하던 상관없다.) Kaplan curve에서 접점을 지니거나 교차하면 비례위험 가정에서 벗어나 있을 가능성을 고려해야 한다. \n다만 실제 논문에는 위의 예제와 같이 성별에 따른 Kaplan curve보다는 논문의 주 목표인 치료법에 의한 Kaplan curve를 주로 넣게 될 것 같다. 문제는 시간이 어느 정도 흘러서 양쪽 그룹에 대상자가 줄어들게 되면 Kaplna curve에서는 비례위험 가정을 만족하는 상태에서도 접점 비슷한 모양이 보일 수 있다는 점이다. 당장 위의 예제만 봐도 시간 800근처에서 접점이 생길 뻔했다. \n비례위험가정의 확인은 어디까지나 위험함수를 가지고 하는 것이다. 편의 상 Kaplan curve를 논문에 넣기는 하지만 위의 예와 같이 누적위험함수에서는 별 문제없어 보이지만 Kaplan curve에서는 접점 비슷한 것이 보이는 경우, Kaplan curve를 그림으로 넣은 상황에서는 논문 내에 비례위험 가정이 어쩌고저쩌고 말로 변명해봐야 소용없는 경우가 있을 수 있다. 따라서 이런 경우 약간 덜 일반적일지라도 차라리 위험함수곡선을 제시하거나 아니면 SPSS말고 다른 통계 패키지를 이용해서 Schenfeld 잔차를 구해 이를 제시하고 그림은 Cox curve를 제시하는 것도 하나의 방법이다. \n하여간 Kaplan curve건 위험 함수 그래프이건 접점을 가지는 것은 비례위험가정을 만족하지 않는다는 것을 보여주는 상황이며 이에 대해서는 적절한 대응이 필요하다.\n\n\n분석팁\nEMR로부터 다운로드하거나 연구가가 작성한 자료는 주로 엑셀파일형태이다. 이를 R로 읽어오면 엑셀에서 각 컬럼별로 자료형태를 지정해 두었더라도 달라질 수 있어 적절한 숫자형(연속형변수)이나 문자형(범주형변수)으로 수정해야 한다.\n연속형변수의 생존분석을 위해서는 2분화가 일반적인데 cut-off를 결정하기 위해 ROC 분석보다는 maxstat 패키지의 maxstat.test()를 이용한다. (https://rpubs.com/cardiomoon/84975)\n비례위험가정과 log-rank test에서의 유의성 확인을 위해 Kaplan-Meier plot를 그린다. ’survminer’패키지의 ’ggsurvplot’함수\n이때 재발여부 등의 값은 단순히 numeric으로 0과 1로만 지정해야 할 수 있다. factor로 지정하면 Right censoered data only 오류가 발생할 수 있다.\nCox 단변량 다변량분석을 한다.\n웹에서 하는 R통계(web-r.org)에서는 이와 같은 방법으로 생존분석을 자동화하여 연속형변수는 cutpoint를 구해 자동으로 그래프를 그려준다. 또한 여러개의 변수를 영향변수(독립변수)로 넣어주면 각각의 변수에 대한 Cox비례위험 모형 및 각각의 survival curve를 그려주고 다변량 분석 및 stepwise backward elemination 까지 한번 입력으로 얻을 수 있으며 그 결과를 html또는 pdf로 다운받을 수 있고 그래프도 고해상도로 다운 받을 수 있다.\n다변량분석에서 결측치의 처리는 아래의 기준을 따른다.\n5% 이하의 결측치 비율: (이 내용는 chatGPT의 추천이므로 추후 검증이 필요함.)\n참고문헌: Little, R.J.A. & Rubin, D.B. (2002). Statistical Analysis with Missing Data (2nd Edition). Wiley-Interscience. ISBN: 978-0471183860. 근거: Little과 Rubin의 연구에서는 결측치가 5% 이하일 때, 무작위 결측(MCAR, Missing Completely at Random)으로 간주될 수 있으며, 이는 분석 결과에 큰 영향을 미치지 않는다는 점을 강조합니다. 따라서 결측치가 5% 이하인 경우, 데이터를 분석에 포함시키고 단순히 대체하거나 무시할 수 있습니다.\n5% ~ 20%의 결측치 비율: (이 내용는 chatGPT의 추천이므로 추후 검증이 필요함.)\n참고문헌: Schafer, J.L. (1997). Analysis of Incomplete Multivariate Data. CRC Press. ISBN: 978-0412040610. 근거: Schafer의 연구에서는 결측치가 5%에서 20% 사이일 경우, 결측치의 패턴과 원인을 분석하고 적절한 대체 방법을 사용하는 것이 중요하다고 언급합니다. 이 범위 내의 결측치는 분석 방법에 따라 처리 방법을 다르게 적용할 수 있으며, 결측치 대체 방법의 선택이 분석 결과에 중요한 영향을 미칠 수 있습니다.\n결측치를 대체는 일반적으로 간편하게는 평균값으로 대체하는 것과 다소 복잡하게는 회귀모델을 이용하는 방법이 있다. 자세한 방법은 R 코딩 예시를 참고한다.\n암환자 생존분석자료의 검증 분석대상자들의 나이에 대한 검증 해당암의 우리나라 연령대별 발생율과 비교하는 것을 고려해 보았다. 5세구간으로 남녀가 비교가 가능하다. 대장암자료로 생존분석한 예시 코드 참고를 바란다.",
    "crumbs": [
      "Statistics",
      "Survival analysis"
    ]
  },
  {
    "objectID": "posts/RStudio-setup/RStudio_setup.html",
    "href": "posts/RStudio-setup/RStudio_setup.html",
    "title": "RStudio setup",
    "section": "",
    "text": "RStudio와 VS Code는 모두 각자의 특징을 가진 R 프로그래밍을 위한 통합 개발 환경(IDE)입니다. RStudio는 전용화된 환경으로 R 언어와 관련된 다양한 기능을 직관적으로 제공하며, R 코드 작성, 데이터 시각화, 리포팅 등에 최적화되어 있습니다. 반면에 VS Code는 다양한 프로그래밍 언어를 지원하며, Marketplace에서 제공하는 확장 기능을 통해 개발자가 필요한 기능을 추가할 수 있는 유연성을 가지고 있습니다. VS Code는 경량화된 성능과 통합 터미널 기능을 제공하여 다양한 개발 환경에서 활용될 수 있지만, R에 특화된 기능은 상대적으로 부족할 수 있습니다.\n연구회에서는 RStudio를 우선 추천합니다.",
    "crumbs": [
      "R",
      "RStudio setup"
    ]
  },
  {
    "objectID": "posts/RStudio-setup/RStudio_setup.html#r-통합개발환경-선택",
    "href": "posts/RStudio-setup/RStudio_setup.html#r-통합개발환경-선택",
    "title": "RStudio setup",
    "section": "",
    "text": "RStudio와 VS Code는 모두 각자의 특징을 가진 R 프로그래밍을 위한 통합 개발 환경(IDE)입니다. RStudio는 전용화된 환경으로 R 언어와 관련된 다양한 기능을 직관적으로 제공하며, R 코드 작성, 데이터 시각화, 리포팅 등에 최적화되어 있습니다. 반면에 VS Code는 다양한 프로그래밍 언어를 지원하며, Marketplace에서 제공하는 확장 기능을 통해 개발자가 필요한 기능을 추가할 수 있는 유연성을 가지고 있습니다. VS Code는 경량화된 성능과 통합 터미널 기능을 제공하여 다양한 개발 환경에서 활용될 수 있지만, R에 특화된 기능은 상대적으로 부족할 수 있습니다.\n연구회에서는 RStudio를 우선 추천합니다.",
    "crumbs": [
      "R",
      "RStudio setup"
    ]
  },
  {
    "objectID": "posts/RStudio-setup/RStudio_setup.html#rstudio-설치안내문서",
    "href": "posts/RStudio-setup/RStudio_setup.html#rstudio-설치안내문서",
    "title": "RStudio setup",
    "section": "RStudio 설치안내문서",
    "text": "RStudio 설치안내문서\nRStudio 공식사이트 (https://posit.co/)에 설치에 대한 공식문서는 없어 보입니다. 그러나 설치는 어렵지 않으며 아래의 요약을 참고하여 설치 하셔도 됩니다.",
    "crumbs": [
      "R",
      "RStudio setup"
    ]
  },
  {
    "objectID": "posts/RStudio-setup/RStudio_setup.html#rstudio-설치파일",
    "href": "posts/RStudio-setup/RStudio_setup.html#rstudio-설치파일",
    "title": "RStudio setup",
    "section": "RStudio 설치파일",
    "text": "RStudio 설치파일\n자신의 운영체제에 맞는 최신버전의 RStudio를 아래의 공식 다운로드 사이트(https://posit.co/downloads/)에서 다운로드 후 (2024년 9월 27일 현재 원도우데스크탑용의 최신설치파일은 RStudio-2024.09.0-375.exe입니다.)\ndefault 폴더에 설치합니다.\n설치 이후 RStudio을 실행한 후 상단의 탭매뉴 중 Tools 메뉴 &gt; Global Options… &gt; R General &gt; Basic 탭에서 아래의 예시와 같이 설치하신 최신버전의 R 실행경로를 선택해 주시면 됩니다. (드물게 지난 버전의 R의 만든 프로젝트를 지난 버전으로 실행하고 싶다면 이 메뉴에서 과거 버전의 R 실행파일의 경로를 지정해주시고 해당 프로젝트를 열어서 사용하시면 됩니다.)\n\n\n\nR version: example\n\n[64-bit] C:\\R\\R-4.4.1\n\n\nDefault working directory (when not in a project)지정은 아래의 예시와 같이 프로젝트를 관리하는 상위 폴더를 추천 드립니다.\n\n\n\nDefault working directory: example\n\nC:\\Projects\n\n\nRStudio 매뉴얼은 개발사인 posit이 만든 https://docs.posit.co/ide/user/을 참고하시길 바랍니다.\n개발자들은 R을 command line interface로 사용하기 보다는 RStudio로 사용한다고 생각됩니다. 그러한 측면에서 R 사용법과 RStudio 사용법은 밀접하게 연계된 셈이며, 사용법에 대한 자료는 RStudio를 개발한 posit에서 만든 RSudio에 내장된 Tutorials가 있습니다. 링크를 타고들어가보면 Beginners, Intermediates, Experts 과정들이 있으므로 상황에 맞는 과정들을 선택해서 시작하면 좋습니다.\n(RStudio에서는 아래의 그림 1 과 같이 git와 같은 version control interface 사용여부에 대한 설정이 있으며 이를 check 해야 새로운 프로젝트를 만들 때 git 사용여부가 옵션으로 선택이 가능해집니다. )\n\n\n\n\n\n\n그림 1: RStudio에서 git 사용여부 설정",
    "crumbs": [
      "R",
      "RStudio setup"
    ]
  },
  {
    "objectID": "posts/RStudio-setup/RStudio_setup.html#패키지-종속성-관리를-위한-renv",
    "href": "posts/RStudio-setup/RStudio_setup.html#패키지-종속성-관리를-위한-renv",
    "title": "RStudio setup",
    "section": "패키지 종속성 관리를 위한 renv",
    "text": "패키지 종속성 관리를 위한 renv\n원래 R에서 패키지는 해당버전 R의 설치폴더 하부의 library 폴더에 설치됩니다. renv는 R 프로젝트에서 패키지 의존성을 관리하기 위해 설계된 도구로써, renv를 설치하고 활성화하면 해당 프로젝트 폴더 하부에 renv 폴더가 만들어지고, 그 하부에 패키지를 설치하게 됩니다. 또한 설치된 패키지들의 정보를 renv.lock 파일에 관리하게 됩니다. 이러한 방법으로 R에서는 프로젝트별로 패키지를 관리할 수 있으므로 필자를 이를 추천합니다.\nRStudio에서 새로운 프로젝트를 생성할 때 renv 사용여부를 check하면 자동으로 설정됩니다.\n사용법에 대해서는 https://rstudio.github.io/renv/articles/renv.html 참고하시길 바랍니다.",
    "crumbs": [
      "R",
      "RStudio setup"
    ]
  },
  {
    "objectID": "posts/RStudio-setup/RStudio_setup.html#r-rstudio-폴더관리-추천",
    "href": "posts/RStudio-setup/RStudio_setup.html#r-rstudio-폴더관리-추천",
    "title": "RStudio setup",
    "section": "R & RStudio 폴더관리 추천",
    "text": "R & RStudio 폴더관리 추천\n\n프로젝트 폴더관리\nProject 폴더를 C:\\Projects 하위폴더에 R 버전과 프로젝트명을 폴더명으로 하여 관리하는 것을 추천합니다.\n\n\n\nC:\\Projects\\\n      └─ R-x.y.z-Project_Name\n\n\n그림 2: Recommended nomenclautue for Project directory name",
    "crumbs": [
      "R",
      "RStudio setup"
    ]
  },
  {
    "objectID": "posts/R-syntax/R_syntax.html",
    "href": "posts/R-syntax/R_syntax.html",
    "title": "R syntax",
    "section": "",
    "text": "심도깊은 이해를 원하시면 R manual 중 R language definition과 번역본 ( https://translation.r-project.org/man/R-lang/R-lang-ko.html#Objects)을 참고하시길 바랍니다.\n아래는 위의 내용을 일부 발췌한 것과 이해원회장님의 강의자료를 바탕으로 합니다.",
    "crumbs": [
      "R",
      "R syntax"
    ]
  },
  {
    "objectID": "posts/R-syntax/R_syntax.html#기본유형basic-types",
    "href": "posts/R-syntax/R_syntax.html#기본유형basic-types",
    "title": "R syntax",
    "section": "기본유형(Basic types)",
    "text": "기본유형(Basic types)\n\nVectors\n벡터들은 데이터를 포함하고 있는 인접한 셀들과 같이 생각될 수 있습니다.셀들은 x[5]와 같이 인덱싱 조작(indexing operation)을 통하여 접근 되어집니다. 더 자세한 사항은 Indexing에 설명되어 있습니다.\nR은 여섯 가지의 기본 (‘atomic’, 아토믹) 벡터를 가지고 있습니다. 이들은 논리형(logical), 정수형(integer), 실수형(real), 복소수형(complex), 문자열 (string) 또는 문자 (character), 그리고 원형(raw)입니다. 다음의 표는 유형이 다른 벡터들의 모드와 저장모드들을 정리하였습니다.\n\n\n\n\ntypeof\nmode\nstorage.mode\n\n\n\n\nlogical\nlogical\nlogical\n\n\ninteger\nnumeric\ninteger\n\n\ndouble\nnumeric\ndouble\n\n\ncomplex\ncomplex\ncomplex\n\n\ncharacter\ncharacter\ncharacter\n\n\nraw\nraw\nraw\n\n\n\n\n\ndouble: 실수형 데이터\n\nR에서 숫자형 데이터는 기본적으로 실수형 데이터로 인식됩니다. 이는 프로그래밍의 융통성을 부여합니다. 아래의 예시처럼 소수점이 있든, 소수점이 없는 형태를 변수에 할당하든 기본적으로 실수형으로 인식됩니다.\n\nnumeric_value&lt;-pi; print(numeric_value); typeof(numeric_value); typeof(1+1)\n\n[1] 3.141593\n\n\n[1] \"double\"\n\n\n[1] \"double\"\n\n\n\ninteger: 정수형 데이터\n\n하지만 소수점이 없는 정수를 명시적으로 변수에 할당할 때(대문자L을 끝에 붙임)와 범위연산자(range operator = colon operator)가 명시적으로 정수를 할당할 때는 정수형이 만들어집니다.\n\ninteger_value &lt;-42L; typeof(integer_value); typeof(1:3); typeof(1L+1L)\n\n[1] \"integer\"\n\n\n[1] \"integer\"\n\n\n[1] \"integer\"\n\n\n\ncharacter: 문자형 데이터\n\n“abc”, “a”, “a123xz” 등 quotation mark로 된 문자열\n\nletters[5:10]; paste(\"ab\",\"cde\", sep = \"\")\n\n[1] \"e\" \"f\" \"g\" \"h\" \"i\" \"j\"\n\n\n[1] \"abcde\"\n\n\n\nas.character(345); as.numeric(\"23.5\")\n\n[1] \"345\"\n\n\n[1] 23.5\n\n\n\nsub(\"a\",\"x\", \"father and grandpa\"); gsub(\"a\",\"x\", \"father and grandpa\")\n\n[1] \"fxther and grandpa\"\n\n\n[1] \"fxther xnd grxndpx\"\n\n\n\n(ex2 &lt;- 'The \"R\" project for statistical computing')\n\n[1] \"The \\\"R\\\" project for statistical computing\"\n\n\n\ncomplex: 복소수형 데이터\n\n\ncomplex_value&lt;-(1+sqrt(2)*1i)*(1-sqrt(2)*1i); print(complex_value); typeof(complex_value) # complex 연산\n\n[1] 3+0i\n\n\n[1] \"complex\"\n\n\n\nraw: 주로 이진 데이터(binary data)를 표현하는 데 사용됩니다. raw 타입은 주로 파일 입출력 또는 네트워크 통신에서 원시 데이터를 다룰 때 사용됩니다. 이 데이터는 변환 없이 그대로 저장되고 전달됩니다.\n\n벡터의기본유형에서 typeof 함수와 mode 함수의 반환값들을 비교하면 아래의 그림과 같습니다.\n\n\n\n기본벡터에서 type와 mode의 관계\n\n\n아래서부터는 퀴즈를 풀어보시기 바랍니다\nR에서는 모든 변수가 벡터 (열) 로 되어 있다. 다음 연산결과를 예상해 보시오\n\n1:3 + 2:4 ; 1:10 + 1:2\n\n[1] 3 5 7\n\n\n [1]  2  4  4  6  6  8  8 10 10 12\n\n\n\npaste(LETTERS[1:10],1:3,sep = \"-\"); paste(LETTERS[1:3],1:10)\n\n [1] \"A-1\" \"B-2\" \"C-3\" \"D-1\" \"E-2\" \"F-3\" \"G-1\" \"H-2\" \"I-3\" \"J-1\"\n\n\n [1] \"A 1\"  \"B 2\"  \"C 3\"  \"A 4\"  \"B 5\"  \"C 6\"  \"A 7\"  \"B 8\"  \"C 9\"  \"A 10\"\n\n\nvector의 특징은 모든 요소가 단일한 것이라는 점이다. NA 값을 제외하고는 모든 요소가 같아야 하기 때문에 서로 다른 성질의 것을 입력하게 되면 에러가 생기거나 변형된다.\n\nc(1,2,3); c(1,2,3,\"a\")\n\n[1] 1 2 3\n\n\n[1] \"1\" \"2\" \"3\" \"a\"\n\n\n\narray : multidimensional vector\n\n\n(arr1 &lt;- array(data=1:90, dim = c(6,5,3))) # 3Dimensional array\n\n, , 1\n\n     [,1] [,2] [,3] [,4] [,5]\n[1,]    1    7   13   19   25\n[2,]    2    8   14   20   26\n[3,]    3    9   15   21   27\n[4,]    4   10   16   22   28\n[5,]    5   11   17   23   29\n[6,]    6   12   18   24   30\n\n, , 2\n\n     [,1] [,2] [,3] [,4] [,5]\n[1,]   31   37   43   49   55\n[2,]   32   38   44   50   56\n[3,]   33   39   45   51   57\n[4,]   34   40   46   52   58\n[5,]   35   41   47   53   59\n[6,]   36   42   48   54   60\n\n, , 3\n\n     [,1] [,2] [,3] [,4] [,5]\n[1,]   61   67   73   79   85\n[2,]   62   68   74   80   86\n[3,]   63   69   75   81   87\n[4,]   64   70   76   82   88\n[5,]   65   71   77   83   89\n[6,]   66   72   78   84   90\n\n\n\narr1[6,4,2] # 3Dimensional indexing\n\n[1] 54\n\n\n\nwhich(arr1==54, arr.ind = TRUE )\n\n     dim1 dim2 dim3\n[1,]    6    4    2\n\n\n\nmatrix : 2dimensional vector\n\n\nmatrix(data = c(3,4,5,6,7,8),\n       nrow=2,\n       ncol=3, # nrow=2 하나만 지정해도 ncol=3은 내부적으로 결정됨\n       byrow = TRUE, # data assign 하는 방향\n       dimnames = list(c(\"pt_1\", \"pt_2\"), # row names\n                       c(\"var1\",\"var2\",\"var3\")) # col names\n              )\n\n     var1 var2 var3\npt_1    3    4    5\npt_2    6    7    8\n\n\n\nx &lt;- 2:9 ; names(x) &lt;- x # x의 이름을 부여\nx %o% x # = outer function : outer(x,x, FUN=\"*\")\n\n   2  3  4  5  6  7  8  9\n2  4  6  8 10 12 14 16 18\n3  6  9 12 15 18 21 24 27\n4  8 12 16 20 24 28 32 36\n5 10 15 20 25 30 35 40 45\n6 12 18 24 30 36 42 48 54\n7 14 21 28 35 42 49 56 63\n8 16 24 32 40 48 56 64 72\n9 18 27 36 45 54 63 72 81\n\n\n\ndata frame : vector를 구성요소로 한 list의 형태 (외형적으로 보면 2dimension으로 보인다) dataframe의 구성요소는 vector들 (각각의 vector는 동일한 데이터 타입이라야 함)\n\n\n## dataframe 만들기\ndf1 &lt;- data.frame( col1 = c(\"A\", \"B\", \"Anyone\", \"None\"),\ncol2 = c(160, 170, 180, 200),\ncol3 = c(TRUE, FALSE, FALSE, TRUE)\n)\ndf1\n\n    col1 col2  col3\n1      A  160  TRUE\n2      B  170 FALSE\n3 Anyone  180 FALSE\n4   None  200  TRUE\n\n\n\n데이터프레임 이름 &lt;- data.frame(컬럼이름= c(data_1, …. , data_n), ….. ) 이런 형식으로 데이터 프레임을 만들 수 있다. 데이터프레임이 R의 기본적인 데이터 양식이기 때문에 이를 다루는 방법이 다양하게 존재함\n\n\n## dataframe cell 찾기\ndf1[3,2] #3행 2열의 데이터\n\n[1] 180\n\n\n\n## column 이름으로 찾기\ndf1$col1 ; df1[, \"col1\"]; df1[\"col1\"] ### df1의 col1 열을 찾는 방법들\n\n[1] \"A\"      \"B\"      \"Anyone\" \"None\"  \n\n\n[1] \"A\"      \"B\"      \"Anyone\" \"None\"  \n\n\n    col1\n1      A\n2      B\n3 Anyone\n4   None\n\n\n\ndf1[,1]\n\n[1] \"A\"      \"B\"      \"Anyone\" \"None\"  \n\n\n\n\n리스트(Lists)\n리스트 (“generic vectors”)는 데이터 저장(data storage)의 또 다른 종류입니다. 리스트들의 구성요소는 어떠한 유형의 R 객체들이 될 수 있습니다. 즉, 리스트의 구성요소들은 같은 유형일 필요가 없습니다.리스트의 구성요소들은 세가지 다른 인덱싱 조작(indexing operation)에 의하여 접근되어 집니다. 자세한 사항은 Indexing에 설명되어 있습니다\n리스트도 벡터의 종류이긴 하지만, 리스트 유형을 제외한 기본 벡터의 종류들을 atomic vectors(벡터를 구성하는데 있어 더 이상 하위단계로 분류할 수 최소의 기본구성단위 요소만으로 된 벡터 – 아토믹 벡터)라고 합니다.\n\n필자주: 데이터구조적인 측면에서 R에서의 vecter와 list 개념을 비교하면 같은 데이터 타입으로 구성된 1차원 구조를 vector라 하고, 2차원 구조는 matrix, 3차원 구조는 array가 됩니다. 데이터타입이 다르면 리스트가 됩니다. 데이터프레임은 2차원이지만 컬럼별로 데이터 타입이 다른 경우로 대부분의 엑셀자료에 해당합니다.\n\n\n\n\nVector와 List의 비교\n\n\n\nlist : R에만 있는 독특한 데이터타입이다. 이것은 모든 데이터 타입을 담을 수 있는 형태이고 자료의 길이가 달라도 같이 담을 수가 있게 되어 있다. 또한 리스트 속에 리스트를 넣을 수 있기에 다단계로 nesting 되는 구조로 만들 수 있다.\n\n\nsample_list &lt;- list(data1=df1, data2 = arr1, data3 = x%o%x)\nstr(sample_list)\n\nList of 3\n $ data1:'data.frame':  4 obs. of  3 variables:\n  ..$ col1: chr [1:4] \"A\" \"B\" \"Anyone\" \"None\"\n  ..$ col2: num [1:4] 160 170 180 200\n  ..$ col3: logi [1:4] TRUE FALSE FALSE TRUE\n $ data2: int [1:6, 1:5, 1:3] 1 2 3 4 5 6 7 8 9 10 ...\n $ data3: num [1:8, 1:8] 4 6 8 10 12 14 16 18 6 9 ...\n  ..- attr(*, \"dimnames\")=List of 2\n  .. ..$ : chr [1:8] \"2\" \"3\" \"4\" \"5\" ...\n  .. ..$ : chr [1:8] \"2\" \"3\" \"4\" \"5\" ...\n\n\n\nsample_list$data1\n\n    col1 col2  col3\n1      A  160  TRUE\n2      B  170 FALSE\n3 Anyone  180 FALSE\n4   None  200  TRUE\n\n\n\nsample_list$data1[,3]\n\n[1]  TRUE FALSE FALSE  TRUE",
    "crumbs": [
      "R",
      "R syntax"
    ]
  },
  {
    "objectID": "posts/R-syntax/R_syntax.html#속성attribute",
    "href": "posts/R-syntax/R_syntax.html#속성attribute",
    "title": "R syntax",
    "section": "속성(Attribute)",
    "text": "속성(Attribute)\nNULL을 제외한 모든 object들은 그들에게 부여된 하나 이상의 attribute들을 가질 수 있습니다. Attribute들은 모든 element들이 이름지어진 곳에 pairlist처럼 저장되지만, name=value pair들의 세트처럼 생각되어야만 합니다. attribute들의 목록은 attributes를 사용하여 얻을 수 있고 attributes&lt;-에 의해 설정됩니다. 각각의 구성요소들은 attr와 attr&lt;-를 사용하여 접근됩니다.\n몇몇의 attribute들은 (예를들어 factor들을 위한 levels&lt;-) 특별한 accessor function들을 가지고있고 이들은 사용가능할 때만 사용되어야만 합니다. 실행의 숨겨진 디테일에 추가적으로, 그들은 추가적인operation들을 실행할 지도 모릅니다. R은 특별한 attribute을 포함하고 일관적인 확인들을 강요하는 attr&lt;-와 attributes&lt;-로의 call들을 가로채려고 시도합니다.\n행렬들과 열들은 간단하게말해서 dim attribute를 가진 벡터들이고 옵션적으로 dimnames가 벡터에 부여되어있습니다.\nAttribute들은 R에 사용된 class structure을 이행하하기위해 사용되었습니다. 만약 object가 class attribute를 가지고 있다면 그 attribute는 평가 도중 검토될 것입니다. R의 class structure은 Object-oriented programming에 자세하게 설명되어있습니다.\n\nNames\nNames 속성은, 존재할 때, 벡터나 목록의 각각의 요소들에 label을 합니다. Object가 존재하는 names의 속성을 프린트하려고 할 때, 요소들을 label하기위하여 쓰여집니다. Names 속성은 예를들어quantile(x)[“25%”]와 같은 indexing 목적으로도 쓰여질 수 있습니다.\nnames와 names&lt;- 구성들을 사용하여 name들을 얻거나 설정할 수도 있습니다. 뒷쪽 것 (names&lt;-)은 names 속성이 적합한 타입과 길이를 가지고있는지를 확실히 하기 위해 필요한 일관적인 체크를 수행할 것입니다.\nPairlist들과 일차원 행들은 특별하게 대해집니다. Pairlist object들에는, 가상의 names 속성이 사용되어집니다; names 속성은 사실상 목록 구성요소들의 태그에서부터 구성됩니다. 일차원 행들에서 names 속성은 실제로dimnames[[1]]에 접근합니다.\n\n\nDimensions\ndim 속성은 행들을 이행하기위하여 쓰여집니다. 행의 내용은 열방향순서의 벡터안에 저장되고, 그 dim 속성은 각각의 행의 규모를 명시하는 정수의 벡터입니다. R은 벡터의 길이가dimension 길이의 산출물임을 확실하게 합니다. 하나 이상의 dimension의 길이가 0일 수도 있습니다.\n벡터는 dim 속성이 없는 반면, 일차원 행은 길이가 1인 dim 속성을 가지고 있기때문에, 일차원 행과 같지 않습니다.\n\n\nDimnames\n행은 문자 벡터의 목록인 dimnames 속성을 사용하여 각각의 dimension을 따로 이름지을 수도 있습니다. dimnames 목록이 자기 자신의 이름을 가지고 있을 수 있으며, 그러면 이는 행들을 프린트 할 때 extent heading들로 쓰여집니다.\n\n\nClasses\nR은class 속성을 통해 주로 컨트롤되는 정교한 class 시스테을 가지고 있습니다. 이 속성은object가 inherit하는 곳의 class들의 목록을 포함하고있는 문자 벡터입니다. 이 형태들은 R의 “일반적인 방법을” 기능의 기초를 형성합니다.\n이 속성은 사용자에의한 제한 없이도 가상적으로 접근되고 조작될 수 있습니다. 여기에는 object가 class 방법들이 예상하는 구성요소들을 확실히 포함하고 있는지를 확인하는 것이 없습니다. 그러므로 class 속성을 대신하는 것은 조심해서 해야만하며, 이들이 사용 가능할 때는 구체적인 창출과 강제 function들이 선호되어야만합니다.\n\n\nTime series attributes\ntsp 속성은 시계열 분석, 시작, 끝, 그리고 빈도의 매개변수를 붙잡고 있기위해 사용됩니다. 이 구성은 월간 혹은 분기별 데이터처럼 주기적인 하부구조를 가진 series들을 다루기위해 주로 사용됩니다.",
    "crumbs": [
      "R",
      "R syntax"
    ]
  },
  {
    "objectID": "posts/R-syntax/R_syntax.html#special-compound-objects",
    "href": "posts/R-syntax/R_syntax.html#special-compound-objects",
    "title": "R syntax",
    "section": "Special compound objects",
    "text": "Special compound objects\n\nFactors\nFactor들은 유한 값들을 가질 수 있는 아이템들 (성별, 사회계층 등)을 설명하기위하여 사용됩니다. Factor는 levels 속성과 “factor” class를 가집니다. 선택적으로, factor이 modeling function들에 사용되었을 때 사용된 parametrisation을 조정하기위한 contrasts 속성도 포함하고 있을 수 있습니다.\nFactor는 순수하게 명목상이거나 순차적인 카테고리일 수도 있습니다. 순차적인 카테고리일 경우, 그렇게 정의되어야만하고 class 벡터c(“ordered”,” factor”)를 가집니다.\n\n필자주: 순차적인 범주형변수에서 요인화를 할 때 아래와 같이 속성에서 ordered = TRUE로 설정해야 함을 의미하여 class로 확인하면 ordered도 같이 출력됨을 의미합니다.\n\n\nsize &lt;- factor(c(\"중간\", \"낮음\", \"높음\", \"중간\", \"낮음\"), \n              levels = c(\"낮음\", \"중간\", \"높음\"), \n              ordered = TRUE)\nprint(size)\n\n[1] 중간 낮음 높음 중간 낮음\nLevels: 낮음 &lt; 중간 &lt; 높음\n\n\n\nclass(size)\n\n[1] \"ordered\" \"factor\" \n\n\n\n\nData frame objects\n데이터 프레임은 SAS 혹은 SPSS 데이터 셋을 가장 비슷하게 흉내내는 R structure들 입니다..\n데이터 프레임은 모두가 같은 길이(행렬일 경우에는 열의 갯수)를 가지고있는 벡터들, factor들, 행렬들의 목록입니다. 추가적으로, 데이터 프레임은 일반적으로 값들을 label하는 names 속성과 행데이터를 label하는 row.names 속성을 가지고 있습니다.\n\n\nTime objects\nR에서 시간과 날짜를 다루기 위해 다양한 객체 유형들이 사용됩니다. 각 객체는 특정 용도에 맞춰 설계되었으며, 시계열 데이터 분석, 시간대 처리, 시간 간격 계산 등 다양한 작업에 활용됩니다. Date, POSIXct, POSIXlt 같은 기본 객체들 외에도, lubridate와 hms 패키지에서 제공하는 객체들이 더욱 세분화된 시간 데이터 처리를 가능하게 합니다.\n\nDate 객체\n\n설명: Date 객체는 날짜를 일 단위로 표현합니다. 시간 정보는 포함하지 않으며, 주로 연도, 월, 일로 구성된 데이터를 다룹니다.\n주요 용도: 날짜를 다루고, 날짜 간의 차이를 계산할 때 사용됩니다.\n예시:\n\n\ntoday &lt;- Sys.Date(); print(today); class(today); typeof(today)\n\n[1] \"2024-10-04\"\n\n\n[1] \"Date\"\n\n\n[1] \"double\"\n\n\n\n\nPOSIXct 객체\n\n설명: POSIXct 객체는 날짜와 시간을 초 단위로 저장합니다. 이는 유닉스 타임스탬프처럼 시간대(time zone)를 고려하여 시간 데이터를 다룹니다. 숫자 벡터로 저장되며, 시계열 데이터를 처리할 때 유용합니다.\n주요 용도: 시계열 데이터 분석, 시간 계산, 시간대 관리.\n예시\n\n\ncurrent_time &lt;- Sys.time()\nprint(current_time); class(current_time); typeof(current_time)\n\n[1] \"2024-10-04 14:17:58 KST\"\n\n\n[1] \"POSIXct\" \"POSIXt\" \n\n\n[1] \"double\"\n\n\n\n\nPOSIXlt 객체\n\n설명: POSIXlt 객체는 리스트 형태로 날짜와 시간 데이터를 저장하며, 연도, 월, 일, 시, 분, 초 등 각각의 요소로 분리됩니다. 사람이 읽기 쉬운 형태로 데이터가 저장되며, 개별 요소를 쉽게 접근할 수 있습니다.\n주요 용도: 날짜와 시간의 세부 요소를 조작할 때 유용.\n\n예시\n\n(time1 &lt;- as.POSIXlt(\"1960-01-01\")); class(time1); typeof(time1)\n\n[1] \"1960-01-01 KST\"\n\n\n[1] \"POSIXlt\" \"POSIXt\" \n\n\n[1] \"list\"\n\n\n\n\ndifftime 객체\n\n설명: difftime 객체는 두 날짜 또는 시간 간의 차이를 나타냅니다. 차이는 일(day), 시간(hour), 분(minute), 초(second) 등의 단위로 표현됩니다.\n주요 용도: 시간 간격 또는 지속 시간 계산.\n예시\n\nfirst &lt;- \"2022-08-20 08:15:22\" ; second &lt;- \"2022-01-01 20:04:48\"\ndifftime(first, second); difftime(first, second, units = \"hours\")\n\nTime difference of 230.5073 days\n\n\nTime difference of 5532.176 hours\n\ndifftime1&lt;-difftime(first, second)\nclass(difftime1); typeof(difftime1)\n\n[1] \"difftime\"\n\n\n[1] \"double\"\n\n\n\n\nfirst2 &lt;- as.POSIXlt(first); second2 &lt;- as.POSIXlt(second)\nsecond2 - first2\n\nTime difference of -230.5073 days\n\n\n\n## difftime(first, second, units = \"months\")\n## match.arg(units)에서 다음과 같은 에러가 발생했습니다:\n## 'arg' should be one of “auto”, “secs”, “mins”, “hours”, “days”, “weeks”\n\n\n\nhms 객체 (hms 패키지)\n\n설명: hms 객체는 시, 분, 초를 저장하고 다루기 위한 객체입니다. 하루 시간을 다루는 데 유용하며, 타임스탬프 없이 시간을 표현할 수 있습니다.\n주요 용도: 시, 분, 초 단위의 시간 데이터 관리.\n예시:\n\nlibrary(hms)\ntime_of_day &lt;- hms::as_hms(\"12:34:56\")\nprint(time_of_day)\n\n12:34:56\n\n\n\n\n\nInterval, Period, Duration 객체 (lubridate 패키지)\n\n설명: Interval, Period, Duration 객체는 lubridate 패키지에서 제공되며, 각각 시간 간격을 다루는 데 특화되어 있습니다.\n\nInterval: 시작 시간과 종료 시간을 포함하는 시간 간격.\nPeriod: 달력상의 시간 단위 (예: 월, 일, 년)로 표현된 기간.\nDuration: 일정한 시간 간격을 초 단위로 표현.\n\n주요 용도: 시간 간격 계산, 특정 기간 동안의 시간 변화 분석.\n예시\n\nsuppressMessages(library(lubridate))\n\nstart_time &lt;- as.POSIXct(\"2024-08-08 08:00:00\")\nend_time &lt;- as.POSIXct(\"2024-08-08 12:00:00\")\ninterval &lt;- interval(start_time, end_time)\nprint(interval)\n\n[1] 2024-08-08 08:00:00 KST--2024-08-08 12:00:00 KST\n\nperiod &lt;- months(3) + days(10)\nprint(period)\n\n[1] \"3m 10d 0H 0M 0S\"\n\nduration &lt;- as.duration(period)\nprint(duration)\n\n[1] \"8753400s (~14.47 weeks)\"",
    "crumbs": [
      "R",
      "R syntax"
    ]
  },
  {
    "objectID": "posts/R-syntax/R_syntax.html#data-manipulation",
    "href": "posts/R-syntax/R_syntax.html#data-manipulation",
    "title": "R syntax",
    "section": "Data Manipulation",
    "text": "Data Manipulation\n\nData reading\ndata file이 존재하는 디렉토리를 먼저 설정해주어야 합니다. 이를 위한 명령어는 setwd() = set working directory 라는 의미 setwd(“C:/R/projects/R-4.4.1-RPythonStudy_HANJM”) 와 같이 디렉토리를 설정해줄 수도 있지만, 만약 디렉토리를 찾기 어렵다면 setwd( choose.dir() ) 와 같은 명령으로 파일탐색기를 열어서 디렉토리를 선택할 수 있습니다. 현재 사용 할 xlsx 파일들이 다음 디렉토리에 있다고 가정합니다.\n\nsetwd(\"C:/R/projects/R-4.4.1-RPythonStudy_HANJM/raw_data\")\nlibrary(readxl)\ndir(pattern = \"*.xlsx\")\n\n[1] \"deidentified_han20230213.xlsx\"\n\nxlsxfiles &lt;- dir(pattern = \"*.xlsx\")\nptinfo &lt;- read_xlsx(xlsxfiles[1])\n\n\n\nBinding tables\n데이터프레임 결합 방법들\nrbind(), cbind(), merge()\n\n\n\n데이터프레임 결합방법\n\n\n** 당연한 이야기지만 rbind는 컬럼의 갯수가 같아야 하고, cbind는 행의 갯수가 같아야 합니다.\n\n\nJoin (Merge) tables\nmerge function\nmerge(x, y, by = intersect(names(x), names(y)), ## 공통된 컬럼하나를 결합용 키로 선택\nby.x = by, by.y = by, all = FALSE, all.x = all, all.y = all, ## x와 y의 결합용 키의 이름이 서로 다를 경우에는 독립적으로 지정\nsort = TRUE, suffixes = c(“.x”,“.y”), no.dups = TRUE,\nincomparables = NULL, …)\n\ndf1 &lt;- data.frame( ID = 1:10, Name = c(\"Lee\",\"Kim\",\"Park\", \"Kang\",\n\"Shin\", \"Lim\", \"Kwon\", \"Choi\", \"Nam\", \"Baek\" ),\nScore = as.integer(rnorm(10, 80,6 ))\n)\ndf2 &lt;- data.frame( ID = sample(1:10, 9, replace = F),\nDepartment = sample( c(\"IM\",\"GS\",\"GY\",\"PD\" ),9, replace = T),\nAge = as.integer(rnorm(9, 40,6 )) )\ndf1\n\n   ID Name Score\n1   1  Lee    85\n2   2  Kim    76\n3   3 Park    72\n4   4 Kang    87\n5   5 Shin    94\n6   6  Lim    88\n7   7 Kwon    73\n8   8 Choi    94\n9   9  Nam    78\n10 10 Baek    91\n\n\n\nmerged_df &lt;- merge(df1,df2, by=\"ID\", all = TRUE) # full join\nmerged_df\n\n   ID Name Score Department Age\n1   1  Lee    85         PD  52\n2   2  Kim    76         IM  36\n3   3 Park    72         IM  37\n4   4 Kang    87         GS  46\n5   5 Shin    94         PD  31\n6   6  Lim    88         PD  35\n7   7 Kwon    73         GY  35\n8   8 Choi    94         GY  37\n9   9  Nam    78       &lt;NA&gt;  NA\n10 10 Baek    91         IM  40\n\n\n\n\nTypes of Join merge\n함수를 실행하여 데이터를 결합할 때에는 데이터 join 방법이 다음과 같이 4가지가 있다. 두개의 df에서 모든 데이터가 완전하게 존재하지 않기 때문에 일치하지 않는 부분에 대한 처리규칙이 중요하다.\n\n\n\nTypes of Join\n\n\nmerge 함수의 옵션에서 all = TRUE 를 선택하면 full join, all.x 는 left join, all.y는 right join이 된다.\nall= FALSE 인 경우에는 당연히 inner join dplyr package에는 개별적인 join 함수가 있는데 그것을 사용해도 됨\ninner_join(df1, df2), left_join(df1, df2), right_join(df1, df2), full_join(df1, df2) left_join(df2, df1) : alternative right join\n\n\nReshape data",
    "crumbs": [
      "R",
      "R syntax"
    ]
  },
  {
    "objectID": "posts/R-syntax/R_syntax.html#pipeline-operator",
    "href": "posts/R-syntax/R_syntax.html#pipeline-operator",
    "title": "R syntax",
    "section": "Pipeline operator",
    "text": "Pipeline operator\nlibrary magrittr 를 사용하면 pipeline 연산자를 쓸 수 있게 된다. %&gt;% 형식이다.\n만약 c(“A”,“B”,“C”) 라는 데이터를 “ABC” 로 paste 한 다음에 다시 tolower 함수를 적용하여 “abc”로 변환하는 작업을 한다고 하자. 그런 경우에는 다음과 같이 코딩을 해야 한다. 하지만 pipeline operator를 사용하면 함수 중첩을 줄이고 코드를 이해하기 쉽게 사용할 수 있다.\n\nlibrary(magrittr)\ntolower(paste(c(\"A\",\"B\",\"C\"), collapse = \"\"))\n\n[1] \"abc\"\n\n\n\nc(\"A\",\"B\",\"C\") %&gt;% paste(., collapse = \"\") %&gt;% tolower\n\n[1] \"abc\"\n\n\n\n## 첫번째 인자로 들어가기 위해서 . 을 사용함",
    "crumbs": [
      "R",
      "R syntax"
    ]
  },
  {
    "objectID": "posts/R-syntax/R_syntax.html#basic-latex-code",
    "href": "posts/R-syntax/R_syntax.html#basic-latex-code",
    "title": "R syntax",
    "section": "Basic LaTeX code",
    "text": "Basic LaTeX code",
    "crumbs": [
      "R",
      "R syntax"
    ]
  },
  {
    "objectID": "posts/R/introduction_to_R.html",
    "href": "posts/R/introduction_to_R.html",
    "title": "Introduciton to R",
    "section": "",
    "text": "R 개발역사\nR은 뉴질랜드 오클랜드 대학교의 Ross Ihaka와 Robert Gentleman에 의해 개발되었으며, 1993년에 처음 출시되었습니다. 이 언어는 Bell Laboratories의 John Chambers 등 여러 개발자가 개발한 S 프로그래밍 언어의 오픈소스 대안으로 구상되었습니다. R의 설계 철학은 데이터 분석을 위한 사용자 친화적인 환경을 제공하는 데 중점을 두었으며, 확장성과 사용 용이성에 중점을 두었습니다(Ihaka & Gentleman, 1996).\n수년 동안 R은 전 세계 개발자와 연구 커뮤니티의 기여로 인해 상당한 개선을 거쳤습니다. 커뮤니티에 의해 개발된 함수와 데이터 세트를 모은 R 패키지를 호스팅하기 위해 종합 R 아카이브 네트워크(CRAN)가 설립되었습니다. 2024년 기준으로, CRAN에는 생물통계학 및 역학을 포함한 다양한 학문 분야를 위한 통계 방법, 기계 학습 알고리즘 및 특수 도구를 다루는 18,000개 이상의 패키지가 있습니다(CRAN, 2024).\n\n\nR과 의학연구\nR이 의학연구에서 중요한 도구로 자리잡게 된 이유는 그 유연성, 강력한 통계 기능, 그리고 특화된 패키지의 사용 가능성 때문입니다. 예를 들어, Terry Therneau가 개발한 survival 패키지는 임상 시험 및 역학 연구에서 중요한 방법인 생존 분석을 위한 종합적인 도구 모음을 제공합니다(Therneau, 2000). 또한, caret 패키지는 예측 모델을 구축하고 평가하는 과정을 간소화하여, 정밀 의학에서 개별 환자에게 맞춘 치료를 제공하는 데 점점 더 많이 사용되고 있습니다(Kuhn, 2008).\nR이 의학연구에서 중요한 이유 중 하나는 방대하고 복잡한 데이터 세트를 처리할 수 있는 능력입니다. 의료데이터가 점점 더 디지털화됨에 따라 연구자들은 방대한 이질적인 데이터를 분석하는 도전에 직면하게 됩니다. R의 데이터 조작 및 시각화 기능, 특히 dplyr 및 ggplot2 와 같은 패키지를 통해 연구자들은 데이터를 효과적으로 탐색하고 해석할 수 있으며, 전통적인 방법으로는 놓칠 수 있는 인사이트를 발견할 수 있습니다(Wickham, 2016).\n의학연구의 복잡성이 증가하고 빅데이터의 부상이 가속화됨에 따라, R은 의료 연구자들에게 중요한 도구로 자리잡았습니다. 다양한 소스의 데이터를 통합하고, 복잡한 통계 분석을 수행하며, 재현 가능한 연구를 생성할 수 있는 능력은 현대 의학연구에서 R을 필수적인 도구로 만들고 있습니다. 또한, R의 오픈소스 특성은 연구자들이 협력하고 그들의 방법을 공유할 수 있도록 하여, 더 강력하고 투명한 과학적 실천을 가능하게 합니다.\n의학연구 분야가 계속 진화함에 따라 R의 중요성은 더욱 커질 것입니다. 환자의 유전자 프로필에 기반한 개별 맞춤 치료가 이루어지는 정밀 의학과 같은 새로운 분야는 R이 제공하는 고급 분석 기능에 크게 의존하고 있습니다. 또한, 임상 연구에 기계 학습 방법을 통합하는 작업은 R을 통해 환자 치료에서 새로운 인사이트와 혁신을 가져올 것으로 기대됩니다.\n\n\nReferences\n\nIhaka, R., & Gentleman, R. (1996). R: A language for data analysis and graphics. Journal of Computational and Graphical Statistics, 5(3), 299-314.\nTherneau, T. (2000). A package for survival analysis in S. Mayo Clinic.\nKuhn, M. (2008). Building predictive models in R using the caret package. Journal of Statistical Software, 28(5), 1-26.\nWickham, H. (2016). ggplot2: Elegant graphics for data analysis. Springer-Verlag.\nHuber, W., Carey, V. J., Gentleman, R., et al. (2015). Orchestrating high-throughput genomic analysis with Bioconductor. Nature Methods, 12(2), 115-121.\nHarrell, F. E. (2015). Regression modeling strategies: With applications to linear models, logistic and ordinal regression, and survival analysis. Springer.",
    "crumbs": [
      "R",
      "Introduciton to R"
    ]
  },
  {
    "objectID": "posts/Python-setup/Python_setup.html",
    "href": "posts/Python-setup/Python_setup.html",
    "title": "Python setup",
    "section": "",
    "text": "Python 공식사이트에서 제공하는 공식문서(https://docs.python.org/3/using/index.html)를 참고하는 것이 이상적이겠지만, 아래의 요약을 참고하여 설치 하셔도 됩니다.",
    "crumbs": [
      "Python",
      "Python setup"
    ]
  },
  {
    "objectID": "posts/Python-setup/Python_setup.html#설치안내문서",
    "href": "posts/Python-setup/Python_setup.html#설치안내문서",
    "title": "Python setup",
    "section": "",
    "text": "Python 공식사이트에서 제공하는 공식문서(https://docs.python.org/3/using/index.html)를 참고하는 것이 이상적이겠지만, 아래의 요약을 참고하여 설치 하셔도 됩니다.",
    "crumbs": [
      "Python",
      "Python setup"
    ]
  },
  {
    "objectID": "posts/Python-setup/Python_setup.html#설치-파일",
    "href": "posts/Python-setup/Python_setup.html#설치-파일",
    "title": "Python setup",
    "section": "설치 파일",
    "text": "설치 파일\n공식 Python 웹사이트(https://www.python.org/)에서 운영체제에 적합한 최신 Python 인터프리터를 다운로드하고 설치합니다. 2024년 9월 6일 기준으로 Windows 운영 체제의 경우 python-3.12.6-amd64.exe 설치파일(2024년 9월 6일 release)이 최신입니다.",
    "crumbs": [
      "Python",
      "Python setup"
    ]
  },
  {
    "objectID": "posts/Python-setup/Python_setup.html#설치옵션",
    "href": "posts/Python-setup/Python_setup.html#설치옵션",
    "title": "Python setup",
    "section": "설치옵션",
    "text": "설치옵션\n\nInstall Now와 Customize installation 중의 선택\n윈도우에 처음 설치하는 경우에는 연구회에서는 Install Now 대신 Customize installation 선택을 추천합니다 (그림 1). 이는 설치경로를 우리가 원하는데로 C:\\Python\\Python-x.y.z로 설정할 수 있는 장점이 있습니다. (개인의 취향에 따라 Python을 P로 x.y.z를 xyz로 줄이셔도 됩니다.) (Command line interface 에서 경로를 입력할 때를 가정하면 짧고 직관적인게 좋습니다.).\n\n\nAdd python.exe to PATH\nPython 설치 시 실행 파일의 경로를 시스템의 환경 변수(PATH)에 등록하는 것은 유용합니다 (그림 1). 이 설정을 통해 Visual Studio Code와 같은 통합 개발 환경(IDE)에서 Python 인터프리터를 자동으로 인식할 수 있게 됩니다.\n또한, 이 설정은 명령 프롬프트나 터미널에서 Python 실행 파일이 위치한 폴더가 아닌 다른 위치에서도 ‘python’ 명령어를 직접 입력하여 Python을 실행할 수 있게 해줍니다. 이는 개발자가 어느 위치에서나 Python 코드를 실행하고 테스트할 수 있는 유연성을 제공합니다.\n\n\n\n\n\n\n그림 1: Selecting Customize installation and adding to PATH\n\n\n\n\n\nOptional Features\nOptional Feature 선택 단계에서는 전 항목 선택하시는 것을 추천드립니다 (그림 2).\n\n\n\n\n\n\n그림 2: Checking all the options on Optional Features",
    "crumbs": [
      "Python",
      "Python setup"
    ]
  },
  {
    "objectID": "posts/Python-setup/Python_setup.html#설치-확인",
    "href": "posts/Python-setup/Python_setup.html#설치-확인",
    "title": "Python setup",
    "section": "설치 확인",
    "text": "설치 확인\n\n\n\n\n\n\nPython이 올바르게 설치되었는지 확인하려면,\n\n\n\n\n\nWin + R을 눌러 실행 대화창을 열고 cmd를 입력하여 명령 프롬프트를 실행합니다.\n\n\n\nCommand Prompt\n\ncmd\n\n\n명령 프롬프트에서 다음 명령을 입력하여 설치된 Python 버전이 예상 버전과 일치하는지 확인합니다.\n\n\n\nCommand Prompt\n\npython --version\n\n\n또는\n\n\n\nCommand Prompt\n\npython --V",
    "crumbs": [
      "Python",
      "Python setup"
    ]
  },
  {
    "objectID": "posts/Python-setup/Python_setup.html#폴더-구조",
    "href": "posts/Python-setup/Python_setup.html#폴더-구조",
    "title": "Python setup",
    "section": "폴더 구조",
    "text": "폴더 구조\n일반적인 구조는 그림 3 와 같으며 설치옵션에 따라 달라질 수 있습니다.\n\n\n\nC:\\Python\\Python-x.y.z\\                # Top-level Python installation directory\n           ├─ DLLs\\                   # Dynamic Link Libraries folder\n           ├─ Doc\\                    # Documentation folder (optional installation)\n           ├─ include\\                # C/C++ header files folder\n           ├─ Lib\\                    # Standard library and third-party packages folder\n           │   └─ site-packages\\      # Folder for packages installed via pip\n           ├─ libs\\                   # Additional libraries folder\n           ├─ Scripts\\                # Scripts folder, contains executable files like pip\n           ├─ tcl\\                    # Tcl/Tk libraries folder\n           ├─ python.exe              # Python executable file\n           └─ pythonw.exe             # Python executable for GUI applications without a console window\n\n\n그림 3: Python Installation Directory Structure with Full Option",
    "crumbs": [
      "Python",
      "Python setup"
    ]
  },
  {
    "objectID": "posts/Python-setup/Python_setup.html#새로운-버전의-python-실행파일-설치하기",
    "href": "posts/Python-setup/Python_setup.html#새로운-버전의-python-실행파일-설치하기",
    "title": "Python setup",
    "section": "새로운 버전의 Python 실행파일 설치하기",
    "text": "새로운 버전의 Python 실행파일 설치하기\n새로운 버전의 실행파일의 설치 시 Upgrade Now가 아닌 Customize installation을 추천합니다 그림 4.\n\n\n\n\n\n\n그림 4: Selecting customize installation option during upgrading\n\n\n\n이 때 아래와 같은 명명방식으로 새로운 경로에 설치하는 것을 추천합니다. (개인의 취향에 따라 Python을 P로 x.y.z를 xyz로 줄이셔도 됩니다.)\n\n\n\nInstall Window\n\nC:\\Python\\Python-x'.y'.z'\\  \n\n\n\n\n\n\n\n\n새로운 경로에 설치하는 이유는 ……,\n\n\n\n\n\n기존의 실행파일로 된 프로젝트를 그대로 유지하기 위해서입니다. 이는 드물겠지만 새로운 실행파일이 기존의 프로젝트에서 오류가 발생하거나 혹은 기존의 패키지와 새로운 실행파일의 호환이 제한되거나 오류가 발생할 수도 있기 때문입니다. 새로운 경로에 설치하면 폴더 구조는 그림 5 와 같이 될 것입니다.\n\n\n\n\n\n\nC:\\Python\\Python-x.y.z\\     # existing Python installation directory\n       └─ Python-x'.y'.z'\\  # New Python installation directory\n\n\n그림 5: Python customize Installation with new release and Directory Structure",
    "crumbs": [
      "Python",
      "Python setup"
    ]
  },
  {
    "objectID": "posts/outlier-detection/outlier_detection.html",
    "href": "posts/outlier-detection/outlier_detection.html",
    "title": "Outliers detection in continuous variables",
    "section": "",
    "text": "데이터가 정규분포를 보인다면 평균으로부터 3 표준편차 이상 떨어져 있으면 이상치로 판단할 수 있습니다.\n아래 그림 1 는 제가 만든 시각화의 예시입니다. 히스토그램에 평균과 3 표준편차를 표시하고, 이상치를 붉은색 원으로 표시해 보았습니다 (소스코드는 프로젝트 원격저장소 source 폴더의 my_histogram_for_outlier_detection.R에 있습니다.)\n\n\n\n\n\n\n\n\n그림 1: Histogram of AGE\n\n\n\n\n\n\n\n\n\n\n\n\n\n그림 2: Histogram of CA19-9\n\n\n\n\n\n그림 1 는 나이 데이터를 히스토그램으로 만든 것이며 이상치가 보이지 않는 경우입니다. 그림 2 는 종양표지자 CA 19-9를 히스토그램으로 만든 것이며 빨간원으로 표시된 이상치가 3개 있는 경우입니다.\n\n\n\n박스-콕스 변환(Box-Cox Transformation)은 정규분포가 아닌 데이터를 다음의 식을 이용하여 정규분포에 가깝게 변환시켜 줍니다.\n\n박스-콕스 변환을 취하기 위해서는 데이터가 모두 양수여야 된다는 조건이 필요하며 보통 원 데이터의 최소값이 양수가 되도록 어떤 값을 더하는 shift주는 식으로 해결할 수 있습니다 (https://blog.naver.com/pmw9440/221713858254). 특정 데이터의 최적의 정규화 식을 찾는 과정은 최적의 λ 을 찾는 것이라 할 수 있습니다. 여기서 특기할만한 λ 의 값은 0, 1 인데, λ = 0이면 log(x) 로그변환을 의미하고 λ = 1이면 g(x) = x-1이 되므로 이는 항등변환과 같게 됩니다.\n위의 그림에서와 같이 CA 19-9 측정값은 정규분포를 보이지 않으므로 정규분포로 변환 후 히스토그램을 그리면 그림 3 와 같습니다.\n\n\n\n\n\n\n\n\n그림 3: Histogram of CA19-9 after log transformation\n\n\n\n\n\nx축을 로그를 취하니 정규분포모양이 되었으며 이상치도 1개로 감소되었습니다 (그림 3).",
    "crumbs": [
      "R",
      "Outliers detection in continuous variables"
    ]
  },
  {
    "objectID": "posts/outlier-detection/outlier_detection.html#연속형변수-이상치outlier-검출",
    "href": "posts/outlier-detection/outlier_detection.html#연속형변수-이상치outlier-검출",
    "title": "Outliers detection in continuous variables",
    "section": "",
    "text": "데이터가 정규분포를 보인다면 평균으로부터 3 표준편차 이상 떨어져 있으면 이상치로 판단할 수 있습니다.\n아래 그림 1 는 제가 만든 시각화의 예시입니다. 히스토그램에 평균과 3 표준편차를 표시하고, 이상치를 붉은색 원으로 표시해 보았습니다 (소스코드는 프로젝트 원격저장소 source 폴더의 my_histogram_for_outlier_detection.R에 있습니다.)\n\n\n\n\n\n\n\n\n그림 1: Histogram of AGE\n\n\n\n\n\n\n\n\n\n\n\n\n\n그림 2: Histogram of CA19-9\n\n\n\n\n\n그림 1 는 나이 데이터를 히스토그램으로 만든 것이며 이상치가 보이지 않는 경우입니다. 그림 2 는 종양표지자 CA 19-9를 히스토그램으로 만든 것이며 빨간원으로 표시된 이상치가 3개 있는 경우입니다.\n\n\n\n박스-콕스 변환(Box-Cox Transformation)은 정규분포가 아닌 데이터를 다음의 식을 이용하여 정규분포에 가깝게 변환시켜 줍니다.\n\n박스-콕스 변환을 취하기 위해서는 데이터가 모두 양수여야 된다는 조건이 필요하며 보통 원 데이터의 최소값이 양수가 되도록 어떤 값을 더하는 shift주는 식으로 해결할 수 있습니다 (https://blog.naver.com/pmw9440/221713858254). 특정 데이터의 최적의 정규화 식을 찾는 과정은 최적의 λ 을 찾는 것이라 할 수 있습니다. 여기서 특기할만한 λ 의 값은 0, 1 인데, λ = 0이면 log(x) 로그변환을 의미하고 λ = 1이면 g(x) = x-1이 되므로 이는 항등변환과 같게 됩니다.\n위의 그림에서와 같이 CA 19-9 측정값은 정규분포를 보이지 않으므로 정규분포로 변환 후 히스토그램을 그리면 그림 3 와 같습니다.\n\n\n\n\n\n\n\n\n그림 3: Histogram of CA19-9 after log transformation\n\n\n\n\n\nx축을 로그를 취하니 정규분포모양이 되었으며 이상치도 1개로 감소되었습니다 (그림 3).",
    "crumbs": [
      "R",
      "Outliers detection in continuous variables"
    ]
  },
  {
    "objectID": "posts/group-comparison/group_comparison.html",
    "href": "posts/group-comparison/group_comparison.html",
    "title": "Group comparison in continuous variables",
    "section": "",
    "text": "추론통계\n의학 연구에서 전체 환자를 대상으로 데이터를 수집하는 것은 현실적으로 불가능한 경우가 많습니다. 추론 통계는 표본 데이터를 통해 모집단의 특성을 추정합니다.\n\n표본 통계량 (Sample Statistics): 표본에서 계산된 평균, 표준편차, 비율 등의 통계적 수치. 이 값들은 모집단의 특성을 추정하는 데 사용됩니다.\n신뢰구간 (Confidence Interval): 표본 통계량을 바탕으로, 모집단의 모수가 특정 범위 내에 있을 확률을 나타냅니다. 예를 들어, 95% 신뢰구간은 해당 구간 내에 모집단의 평균이 존재할 확률이 95%라는 것을 의미합니다.\n\n\n\n\n\n\n\n노트\n\n\n\n모수(母數, parametric)적 방법은 모집단이 특정한 분포를 따르고, 그 분포를 특정하는 평균(平均, mean), 분산(分散, variance) 등을 추정하는 기법임에 반해, 비모수(非母數, non-parametric) 방법은 모집단의 특정 분포를 가정하지 않고 순위(順位, ranks) 등을 사용하여 추정하는 것입니다.\n\n\n\n\n\n정규분포\n정규분포(Normal Distribution)는 다양한 데이터가 평균을 중심으로 대칭적으로 분포하는 확률분포이며 가우스분포라고도 합니다 (방정식 1 , 그림 1) .\n\n\n\n\\[ f(x) = \\frac{1}{\\sigma \\sqrt{2\\pi}} \\exp\\left(-\\frac{(x - \\mu)^2}{2\\sigma^2}\\right)  \\tag{1}\\]\n\n\\(f(x)\\) : 확률 밀도 함수\n\\(\\mu\\) : 평균(mean)\n\\(\\sigma\\) : 표준편차(standard deviation)\n\\(\\sigma^2\\) : 분산(variance)\n\n\n\n\n\n\n\n\n\n\n\n그림 1: Comparison of Normal Distributions with Different Variances\n\n\n\n\n\n\n\n정규분포는 그림 1 에서처럼 평균(\\(\\mu\\))과 표준편차(\\(\\sigma\\))에 따라 그 형태가 달라집니다. 이로 인해 서로 다른 정규분포를 비교하거나, 특정 데이터가 정규분포 내에서 어떤 위치에 있는지를 평가하는 것이 어렵습니다.\n\n\nZ-분포\nZ-분포는 정규분포에서 데이터를 표준화(standardization)하여 얻어진 분포로, 평균이 0이고 표준편차가 1인 표준정규분포입니다 (방정식 2, 그림 2).\n\n\n  \\[\nf(z) = \\frac{1}{\\sqrt{2\\pi}} \\exp\\left(-\\frac{z^2}{2}\\right)\n\\tag{2}\\]\n\n\\(z\\): 표준화된 확률변수(Z-값)\n\\(f(z)\\): 해당 \\(z\\) 값에서의 확률 밀도\n\\(\\frac{1}{\\sqrt{2\\pi}}\\): 정규화 상수, 전체 확률 밀도가 1이 되도록 조정\n\n\n\n\n\n\n\n\n\n\n\n그림 2: Standard Normal Distributions with Z-value\n\n\n\n\n\n\n\nZ-분포에서 Z-값은 통계검정량(test statistic)으로 사용되며, 특정 데이터 포인트가 평균으로부터 얼마나 떨어져 있는지를 표준편차 단위로 나타냅니다. Z-값은 다음과 같이 계산됩니다: 방정식 3\n\\[\nZ = \\frac{X - \\mu}{\\sigma}\n\\tag{3}\\]\n\n\\(Z\\): 표준화된 값 (Z-값)\n\\(X\\): 관측된 데이터 값\n\\(\\mu\\): 모집단 평균\n\\(\\sigma\\): 모집단 표준편차\n\nZ-분포의 활용은 다음과 같습니다.\n\n통계적 가설 검정: Z-값을 사용하여 특정 데이터가 평균에서 얼마나 떨어져 있는지를 판단하고, 이를 바탕으로 가설 검정을 수행합니다.\n신뢰구간 계산: Z-분포는 신뢰구간을 계산할 때 사용됩니다. 특정 신뢰수준에서의 Z-값을 이용해 구간을 설정합니다.\n확률 계산: Z-값을 통해 특정 데이터가 주어진 정규분포에서 얼마나 자주 발생할지를 확률적으로 계산할 수 있습니다.\n\n\n\n중심극한정리\n어떤 모집단의 분포가 무엇이든 간에 표본 크기가 충분히 크면(일반적으로 \\(n≥30\\)) 표본 평균의 분포는 정규분포에 근사하게 된다는 것이며, 표본 평균의 분포는 모집단의 평균 \\(\\mu\\)를 중심으로 하고, 표준오차(SE, Standard Error)인 \\(\\frac{\\sigma}{\\sqrt{n}}\\)를 표준편차로 가지는 정규분포에 근사하게 됩니다 그림 3.\n\n\n\n\n\n\n그림 3: Illustration of Central Theorem (https://velog.io/ted_log/중심극한정리와와-신뢰구간)\n\n\n\n이를 기반으로 모평균의 95% 신뢰구간을 추정하면 다음과 같습니다: 방정식 4\n\\[\n\\overline{X} \\pm Z_{\\alpha/2} \\cdot \\frac{\\sigma}{\\sqrt{n}}\n\\tag{4}\\]\n\n\\(\\overline{X}\\) : 표본 평균\n\\(Z_{\\alpha/2}\\) : 95% 신뢰수준에서의 Z-값(약 1.96)\n\\(\\frac{\\sigma}{\\sqrt{n}}\\) : 표본 평균의 표준오차\n\n위 신뢰구간 추정식은 모집단의 표준편차 \\(\\sigma\\)를 알고 있다는 가정하에 유도되었습니다. 그러나 실제로는 모집단의 표준편차 \\(\\sigma\\)를 알 수 없는 경우가 대부분입니다. 이 경우 \\(\\sigma\\)를 사용할 수 없으므로 표본 표준편차 \\(s\\)를 사용해야 합니다. 따라서 신뢰구간 추정식은 다음과 같이 수정됩니다: 방정식 5\n\\[\n\\overline{X} \\pm Z_{\\alpha/2} \\cdot \\frac{s}{\\sqrt{n}}\n\\tag{5}\\]\n여기서 \\(s\\)는 표본 표준편차입니다.\n위의 전제들은 표본의 크기가 크다는 전제가 있기 때문에 표본의 크기가 작다면 모평균을 추정이 제한적이게 됩니다.\n\n\nt-분포\nt-분포는 1908년, 영국의 통계학자 윌리엄 고셋에 의해 처음으로 개발되었습니다. 당시 고셋은 맥주 양조 회사인 기네스(Guinness)에서 일하고 있었고, 소규모 실험에서 발생하는 불확실성을 다루기 위해 새로운 통계적 방법을 개발할 필요가 있었습니다.\n필명 ‘Student’: 고셋은 회사의 기밀 유지 정책 때문에 자신의 이름을 사용하지 못했고, 대신 ‘Student’라는 필명으로 논문을 발표했습니다. 그래서 t-분포는 종종 Student’s t-distribution이라고 불립니다.\n고셋은 정규분포와 카이제곱분포의 관계를 사용하여 t-분포를 도출했습니다. 카이제곱분포는 정규분포에서 도출된 분포로, 모집단의 분산을 모를 때 표본 분산을 통해 도출됩니다.\n표본 평균이 정규분포를 따르며, 표본 분산이 독립적인 카이제곱분포를 따른다는 사실에 기초해 t-분포를 수학적으로 유도했습니다 방정식 6.\n\n\n\n\n\n\n노트\n\n\n\n이는 t-검정에서는 모집단이 정규분포를 따른다는 가정을 전제하고 있음을 시사합니다.\n\n\n\\[\nf(t) = \\frac{\\Gamma\\left(\\frac{\\nu + 1}{2}\\right)}{\\sqrt{\\nu \\pi} \\, \\Gamma\\left(\\frac{\\nu}{2}\\right)} \\left(1 + \\frac{t^2}{\\nu}\\right)^{-\\frac{\\nu + 1}{2}}\n\\tag{6}\\]\n여기서:\n\n\\(t\\): t-분포의 확률변수\n\\(\\nu\\): 자유도(degrees of freedom)\n\\(\\Gamma\\): 감마 함수 (Gamma function),\n\\(\\Gamma(n)\\)은 \\((n-1)!\\)과 동일한 의미를 가짐\n\n이 수식에서 t-분포의 모양은 자유도 \\(\\nu\\)에 따라 달라지며, 자유도가 클수록 t-분포는 표준정규분포에 가까워집니다.\n\n\\(\\nu\\)가 작을수록, t-분포의 꼬리 부분이 더 두터워져서 극단적인 값이 나올 확률이 더 높습니다.\n\\(\\nu\\)가 무한대로 커지면, t-분포는 표준정규분포와 동일하게 됩니다.\n\nt-통계량은 다음과 같이 정의됩니다: 방정식 7\n\\[\nt = \\frac{\\overline{X} - \\mu}{\\frac{s}{\\sqrt{n}}}\n\\tag{7}\\]\n\n\\(\\overline{X}\\) : 표본 평균,\n\\(\\mu\\) : 모집단 평균,\n\\(s\\) : 표본 표준편차,\n\\(n\\) : 표본 크기입니다.\n\nt-통계량의 의미는 다음과 같습니다.\n표본평균과 모평균의 비교:\nt-통계량은 표본평균과 가설에서 설정한 모집단 평균 \\(\\mu\\) 간의 차이가 표본 표준오차(SE) 대비 얼마나 큰지를 나타냅니다. 즉, t-값은 표본평균이 모집단 평균과 얼마나 떨어져 있는지를 표준오차의 단위로 표현한 값입니다.\n가설 검정에서의 사용:\nt-분포를 이용한 가설 검정에서는 계산된 t-값과 t-분포의 임계값을 비교하여 귀무가설을 기각할지 결정합니다. 예를 들어, t-값이 t-분포의 임계값을 벗어나면, 두 평균 간에 유의미한 차이가 있다고 판단하고 귀무가설을 기각합니다.\n자유도와 t-분포:\nt-통계량은 t-분포를 따르며, 이 t-분포의 모양은 자유도(degrees of freedom, df)에 따라 달라집니다. 자유도는 일반적으로 \\(n - 1\\)로 계산되며, 표본 크기가 커질수록 t-분포는 표준정규분포에 가까워집니다. 표본 크기가 작을 때는 t-분포의 꼬리가 더 두터워지며, 이는 극단적인 t-값이 나올 가능성을 더 잘 반영합니다.\nt-값의 해석:\nt-값이 크면 클수록 표본평균과 모집단 평균 간의 차이가 크다고 해석됩니다. t-값이 0에 가까울수록 표본평균이 모집단 평균과 유사하다는 의미입니다.\n\n\n\n\n\n\n그림 4: 표준정규분포와 t분포의 차이\n\n\n\n\n\nt-분포를 이용한 모평균 신뢰구간\nt-분포를 이용하여 모평균의 신뢰구간을 구하는 식은 다음과 같습니다: 방정식 8\n\\[\n\\overline{X} \\pm t_{\\alpha/2, \\, df} \\cdot \\frac{s}{\\sqrt{n}}\n\\tag{8}\\]\n여기서 각 요소는 다음을 의미합니다:\n\n\\(\\overline{X}\\) : 표본 평균\n\\(t_{\\alpha/2, \\, df}\\) : 신뢰수준 \\(\\alpha\\)에 해당하는 t-값, 자유도 \\(df\\) (일반적으로 \\(df = n - 1\\))에 따라 결정\n\\(s\\): 표본 표준편차\n\\(n\\): 표본 크기\n\\(\\frac{s}{\\sqrt{n}}\\): 표준오차(SE), 표본 평균이 모집단 평균을 얼마나 잘 추정하는지를 나타냄\n\n예를 들어, 표본 크기가 \\(n = 25\\), 표본 평균이 \\(\\overline{X} = 100\\), 표본 표준편차가 \\(s = 10\\)이며, 95% 신뢰구간을 계산하려고 한다면, \\(t_{\\alpha/2, \\, 24}\\) 값을 찾고 이 식을 사용하여 신뢰구간을 계산할 수 있습니다.\n\n\n두 평균의 비교\n모평균 추정에서 t-분포 통계량인 t를 산출하는 것은 모평균과 표본평균의 차이를 표준오차로 보정하여 구하지만, 두 평균의 비교(t-검정)에서는 두 평균의 차이를 보정할 때 두 표본의 분산이 모두 사용되므로 결합분산(pooled variance)을 이용하여 보정하게 됩니다 방정식 9.\n\n\n\n\n\n\n노트\n\n\n\n이때 결합분산은 두 모집단의 분산이 같다는 가정하에 계산됩니다.\n\n\n\\[\nt = \\frac{\\overline{X}_1 - \\overline{X}_2}{\\sqrt{s_p^2 \\left(\\frac{1}{n_1} + \\frac{1}{n_2}\\right)}}\n\\tag{9}\\]\n여기서: - \\(\\overline{X}_1\\), \\(\\overline{X}_2\\) 는 각각 두 표본의 평균입니다. - \\(n_1\\), \\(n_2\\) 는 각각 두 표본의 크기입니다. - \\(s_p^2\\)는 두 표본의 결합분산(pooled variance)으로, 다음과 같이 계산됩니다: 방정식 10\n\\[\ns_p^2 = \\frac{(n_1 - 1)s_1^2 + (n_2 - 1)s_2^2}{n_1 + n_2 - 2}\n\\tag{10}\\]\n여기서 \\(s_1^2\\)와 \\(s_2^2\\)는 각각 두 표본의 분산입니다.\n\n\nR에서의 t-검정\n기본적으로 t.test() 함수를 사용하여 수행할 수 있습니다. t-검정에는 단일 표본 t-검정, 독립 표본 t-검정, 대응 표본 t-검정이 있습니다. R에서 t.test() 함수의 주요 인자는 벡터입니다. t.test() 함수는 기본적으로 두 가지 벡터를 입력받아 두 그룹 간의 평균 차이를 비교합니다. 다음은 t.test() 함수의 주요 인자들과 그 설명입니다:\n\n1. x (필수 인자)\n\n첫 번째 그룹의 데이터를 나타내는 벡터입니다.\n예시: t.test(x = c(5, 6, 7, 8, 9))\n\n\n\n2. y (선택적 인자)\n\n두 번째 그룹의 데이터를 나타내는 벡터입니다.\n만약 y 인자를 제공하지 않으면, t.test()는 단일 표본 t-검정을 수행합니다.\n예시: t.test(x = c(5, 6, 7, 8, 9), y = c(10, 11, 12, 13, 14))\n\n\n\n3. alternative (선택적 인자)\n\n대립가설의 형태를 지정합니다. \"two.sided\", \"greater\", \"less\" 중 하나를 사용할 수 있습니다.\n기본값은 \"two.sided\"입니다.\n\n\n\n4. mu (선택적 인자)\n\n단일 표본 t-검정에서 가설 검정의 기준이 되는 모집단 평균을 지정합니다. 기본값은 mu = 0입니다.\n\n\n\n5. paired (선택적 인자)\n\n두 벡터가 짝지어진 데이터인지 여부를 지정합니다.\nTRUE로 설정하면 대응 표본 t-검정을 수행합니다. 기본값은 FALSE입니다.\n\n\n\n6. var.equal (선택적 인자)\n\n두 벡터의 분산이 같다고 가정할지를 지정합니다.\nTRUE로 설정하면 분산이 동일하다고 가정하며 Student의 t-검정을 수행합니다. 기본값은 FALSE이며, 이 경우 Welch의 t-검정이 수행됩니다.\n\n\n\n7. conf.level (선택적 인자)\n\n신뢰구간의 신뢰수준을 지정합니다. 기본값은 0.95(95% 신뢰수준)입니다.\n\n\n\n단일 표본 t-검정 (One-Sample t-test)\n단일 표본 t-검정은 한 표본의 평균이 특정 값과 다른지를 검정하는 데 사용됩니다.\n예시 코드와 실행결과 (여기서 mu는 비교하고자 하는 모집단 평균입니다.)\n\n# 예시 데이터\ndata &lt;- c(5.2, 4.9, 6.3, 5.8, 5.4, 5.7, 5.1)\n\n# 단일 표본 t-검정\nt.test(data, mu = 5.5)\n\n\n    One Sample t-test\n\ndata:  data\nt = -0.078567, df = 6, p-value = 0.9399\nalternative hypothesis: true mean is not equal to 5.5\n95 percent confidence interval:\n 5.040799 5.930630\nsample estimates:\nmean of x \n 5.485714 \n\n\n\n\n독립 표본 t-검정 (Independent Two-Sample t-test)\n독립 표본 t-검정은 두 독립된 그룹 간의 평균 차이를 검정하는 데 사용됩니다. 그룹 간의 분산이 같다고 가정하는 경우와 그렇지 않은 경우에 따라 달라집니다.\n예시 코드와 실행결과\n\n# 예시 데이터\ngroup1 &lt;- c(6.1, 5.9, 6.3, 6.5, 6.0)\ngroup2 &lt;- c(5.8, 5.7, 5.9, 6.0, 5.6)\n\n# 독립 표본 t-검정\nt.test(group1, group2)\n\n\n    Welch Two Sample t-test\n\ndata:  group1 and group2\nt = 2.7941, df = 6.908, p-value = 0.02711\nalternative hypothesis: true difference in means is not equal to 0\n95 percent confidence interval:\n 0.054515 0.665485\nsample estimates:\nmean of x mean of y \n     6.16      5.80 \n\n\n\n기본적으로, t.test() 함수는 두 그룹 간의 분산이 같다고 가정하지 않습니다. 만약 분산이 같다고 가정하려면 var.equal = TRUE 인자를 추가합니다.\n\n\n# 분산이 같다고 가정한 t-검정\nt.test(group1, group2, var.equal = TRUE)\n\n\n    Two Sample t-test\n\ndata:  group1 and group2\nt = 2.7941, df = 8, p-value = 0.02341\nalternative hypothesis: true difference in means is not equal to 0\n95 percent confidence interval:\n 0.06289215 0.65710785\nsample estimates:\nmean of x mean of y \n     6.16      5.80 \n\n\n\n\n대응 표본 t-검정 (Paired t-test)\n대응 표본 t-검정은 같은 대상에서 두 번의 측정을 수행한 결과(예: 치료 전후)를 비교하는 데 사용됩니다.\n예시 코드와 실행결과\n\n# 예시 데이터\nbefore &lt;- c(5.5, 5.7, 5.8, 5.9, 5.6)\nafter &lt;- c(6.0, 5.8, 6.2, 6.1, 6.0)\n\n# 대응 표본 t-검정\nt.test(before, after, paired = TRUE)\n\n\n    Paired t-test\n\ndata:  before and after\nt = -4.3546, df = 4, p-value = 0.01211\nalternative hypothesis: true mean difference is not equal to 0\n95 percent confidence interval:\n -0.5240262 -0.1159738\nsample estimates:\nmean difference \n          -0.32 \n\n\n\n여기서 paired = TRUE 인자는 두 표본이 짝을 이루고 있음을 지정합니다.\n\n\n\nt-검정 결과 해석\nt.test() 함수의 결과는 다음과 같은 요소들을 포함하는 리스트로 반환됩니다:\n\nt-value: t-통계량 값\ndf: 자유도 (degrees of freedom)\np-value: p-값, 귀무가설을 기각할지 여부를 결정하는 데 사용됩니다.\nconf.int: 지정된 신뢰수준에 대한 신뢰구간\nmean of x/y: 각 그룹의 평균 예시 결과:\n\n\n# 결과 예시\nt.test(group1, group2)\n\n\n    Welch Two Sample t-test\n\ndata:  group1 and group2\nt = 2.7941, df = 6.908, p-value = 0.02711\nalternative hypothesis: true difference in means is not equal to 0\n95 percent confidence interval:\n 0.054515 0.665485\nsample estimates:\nmean of x mean of y \n     6.16      5.80 \n\n\n\n이 결과를 해석할 때, p-값이 유의수준(예: 0.05)보다 작으면 귀무가설을 기각하고, 두 그룹 간의 평균에 유의미한 차이가 있다고 결론지을 수 있습니다.\n\n\n\n\nWelch t-검정\n\n이질적 분산: 두 그룹의 분산이 서로 다를 수 있다는 가정을 전제로 합니다. 이는 데이터가 다양한 조건에서 수집된 경우에 특히 유용합니다.\n자유도의 조정: Welch t-검정은 자유도를 조정하여 두 그룹의 분산이 다를 때 표본 크기와 분산의 차이를 반영합니다. 자유도는 두 그룹의 분산과 표본 크기에 따라 달라지며, 다음과 같은 식으로 계산됩니다:\n\n\\[\ndf = \\frac{\\left(\\frac{s_1^2}{n_1} + \\frac{s_2^2}{n_2}\\right)^2}{\\frac{\\left(\\frac{s_1^2}{n_1}\\right)^2}{n_1 - 1} + \\frac{\\left(\\frac{s_2^2}{n_2}\\right)^2}{n_2 - 1}}\n\\]\n여기서:\n\n\\(s_1^2\\), \\(s_2^2\\)는 각각 두 그룹의 표본 분산,\n\\(n_1\\), \\(n_2\\)는 각각 두 그룹의 표본 크기입니다.\n\n\n비대칭적 신뢰구간: Welch t-검정은 t-분포를 따르지 않으며, 신뢰구간이 비대칭적일 수 있습니다. 이는 데이터의 분포가 비대칭적일 때 더 정확한 신뢰구간을 제공합니다.\n\n\nWelch t-검정의 t-통계량은 다음과 같이 계산됩니다: 방정식 11\n\\[\nt = \\frac{\\overline{X}_1 - \\overline{X}_2}{\\sqrt{\\frac{s_1^2}{n_1} + \\frac{s_2^2}{n_2}}}\n\\tag{11}\\]\n여기서:\n\n\\(\\overline{X}_1\\)와 \\(\\overline{X}_2\\)는 각각 두 그룹의 표본 평균,\n\\(s_1^2\\)와 \\(s_2^2\\)는 각각 두 그룹의 표본 분산,\n\\(n_1\\)와 \\(n_2\\)는 각각 두 그룹의 표본 크기입니다.\n\nR에서의 Welch t-검정 수행 방법 R에서 Welch t-검정을 수행하기 위해 t.test() 함수를 사용합니다. 기본적으로 t.test() 함수는 두 집단의 분산이 같지 않다고 가정하여 Welch t-검정을 수행합니다.\n\n# 두 그룹의 데이터 생성\ngroup1 &lt;- c(6.1, 5.9, 6.3, 6.5, 6.0)\ngroup2 &lt;- c(5.8, 5.7, 5.9, 6.0, 5.6)\n\n# Welch t-검정 수행\nresult &lt;- t.test(group1, group2)\n\n# 결과 출력\nprint(result)\n\n\n    Welch Two Sample t-test\n\ndata:  group1 and group2\nt = 2.7941, df = 6.908, p-value = 0.02711\nalternative hypothesis: true difference in means is not equal to 0\n95 percent confidence interval:\n 0.054515 0.665485\nsample estimates:\nmean of x mean of y \n     6.16      5.80 \n\n\n\n\nMann-Whitney U-검정\n\nWilcoxon의 기초 작업\n1945년: 프랭크 윌콕슨(Frank Wilcoxon)이 비모수적 방법을 기반으로 두 그룹 간의 차이를 비교하는 Wilcoxon 순위합 검정을 처음으로 제안했습니다. Wilcoxon의 접근법은 두 집단 간의 차이를 순위로 변환하여 순위 합을 비교하는 것이었으며, 이는 정규분포를 가정하지 않고도 두 독립된 표본 간의 차이를 평가할 수 있는 중요한 방법으로 자리 잡았습니다.\n\n\nMann과 Whitney의 확장\n1947년: 헨리 B. 만(Henry B. Mann)과 도로시 로빈스 와이트니(Dorothy Robbins Whitney)는 Wilcoxon의 순위합 검정을 확장하고 일반화했습니다. Mann과 Whitney는 두 독립된 표본의 순위를 비교하는 새로운 방법을 제안했으며, 이 방법은 Mann-Whitney U 검정으로 알려지게 되었습니다.\n이 검정법은 두 그룹 간의 차이를 평가하기 위해 U 통계량을 도입했습니다. U 통계량은 두 그룹의 순위를 비교하여 계산되며, 두 그룹이 동일한 분포를 따를 경우 U 통계량의 기대값이 계산됩니다. 귀무가설이 참일 때 이 U 통계량의 분포는 알려진 분포를 따르며, 이를 통해 p-값을 계산할 수 있습니다.\n\n\n비모수적 방법의 중요성\nMann-Whitney U 검정의 개발은 비모수적 방법의 중요성을 강조했습니다. 정규분포를 가정하지 않고도 데이터를 분석할 수 있는 방법을 제공했으며, 이는 특히 작은 표본이나 비정규 분포의 데이터를 다루는 데 매우 유용했습니다.\nMann-Whitney U 검정은 데이터의 실제 값이 아닌 순위를 사용하여 통계적 검정을 수행하므로, 이상값(outliers)이나 비대칭 분포의 영향을 덜 받습니다. 이 검정은 두 그룹 간의 차이를 비교할 때, 중앙값의 차이에 대한 강력한 비모수적 대안으로 널리 사용됩니다.\n\n\nMann-Whitney U 검정의 계산 과정:\n첫 번째 그룹에 대한 U 통계량:\n\\[\nU_1 = R_1 - \\frac{n_1 (n_1 + 1)}{2}\n\\]\n두 번째 그룹에 대한 U 통계량:\n\\[\nU_2 = R_2 - \\frac{n_2 (n_2 + 1)}{2}\n\\]\n여기서:\n\n\\(R_1\\)과 \\(R_2\\)는 각각 첫 번째와 두 번째 그룹의 순위 합,\n\\(n_1\\)과 \\(n_2\\)는 각각 첫 번째와 두 번째 그룹의 표본 크기입니다.\n\n최종적으로 두 값 중 작은 U 통계량이 선택되며, 이 값에 따라 두 그룹 간의 차이가 유의미한지를 판단합니다.\n\n# 필요한 패키지 로드\nlibrary(ggplot2)\n\n# 정규분포를 따르지 않는 두 그룹 데이터 생성\nset.seed(123)\ngroup1 &lt;- rexp(30, rate = 0.2)  # 지수분포\ngroup2 &lt;- rexp(30, rate = 0.3) + 2  # 다른 지수분포 + 상수로 이동\n\n# t-검정 수행\nt_test_result &lt;- t.test(group1, group2)\nt_test_p_value &lt;- t_test_result$p.value\n\n# Mann-Whitney U 검정 수행\nu_test_result &lt;- wilcox.test(group1, group2)\nu_test_p_value &lt;- u_test_result$p.value\n\n# 결과 출력\ncat(\"t-검정 p-값:\", t_test_p_value, \"\\n\")\n\nt-검정 p-값: 0.1227817 \n\ncat(\"Mann-Whitney U 검정 p-값:\", u_test_p_value, \"\\n\")\n\nMann-Whitney U 검정 p-값: 0.03576713 \n\n# 두 그룹의 분포를 히스토그램으로 시각화\ndf &lt;- data.frame(\n  value = c(group1, group2),\n  group = factor(c(rep(\"Group 1\", 30), rep(\"Group 2\", 30)))\n)\n\np &lt;- ggplot(df, aes(x = value, fill = group)) +\n  geom_histogram(position = \"identity\", alpha = 0.6, bins = 15) +\n  theme_minimal() +\n  labs(title = \"Comparison of Two Non-Normal Distributions\",\n       x = \"Value\", y = \"Frequency\") +\n  theme(legend.position = \"top\")\n\n# 그래프 출력\nprint(p)",
    "crumbs": [
      "Statistics",
      "Group comparison in continuous variables"
    ]
  },
  {
    "objectID": "posts/chi-square-test/Chi_square_test.html",
    "href": "posts/chi-square-test/Chi_square_test.html",
    "title": "Chi-Square Test",
    "section": "",
    "text": "카이제곱 검정(Chi-Square Test)은 영국의 통계학자 칼 피어슨(Karl Pearson)에 의해 1900년에 개발되었으며, 범주형 데이터의 관찰된 빈도와 기대되는 빈도 간의 차이를 분석하여 두 변수 간에 독립성 또는 데이터가 특정 이론적 분포에 적합한지를 검증하는 통계적 방법입니다."
  },
  {
    "objectID": "posts/chi-square-test/Chi_square_test.html#역사",
    "href": "posts/chi-square-test/Chi_square_test.html#역사",
    "title": "Chi-Square Test",
    "section": "",
    "text": "카이제곱 검정(Chi-Square Test)은 영국의 통계학자 칼 피어슨(Karl Pearson)에 의해 1900년에 개발되었으며, 범주형 데이터의 관찰된 빈도와 기대되는 빈도 간의 차이를 분석하여 두 변수 간에 독립성 또는 데이터가 특정 이론적 분포에 적합한지를 검증하는 통계적 방법입니다."
  },
  {
    "objectID": "posts/chi-square-test/Chi_square_test.html#통계량",
    "href": "posts/chi-square-test/Chi_square_test.html#통계량",
    "title": "Chi-Square Test",
    "section": "통계량",
    "text": "통계량\n피어슨은 검정 통계량으로 각 셀에서 관찰된 빈도와 기대값의 차이를 구하고, 그 차이를 제곱하여 절대값을 반영했습니다. 그런 다음, 상대적인 비교를 위해 이를 기대값으로 나누어 검정 통계량을 계산했습니다 방정식 1.\n\\[\n\\chi^2 = \\sum \\frac{(O_{ij} - E_{ij})^2}{E_{ij}}\n\\tag{1}\\]"
  },
  {
    "objectID": "posts/chi-square-test/Chi_square_test.html#확률밀도함수-및-분포",
    "href": "posts/chi-square-test/Chi_square_test.html#확률밀도함수-및-분포",
    "title": "Chi-Square Test",
    "section": "확률밀도함수 및 분포",
    "text": "확률밀도함수 및 분포\n이로부터 유도된 확률밀도함수 방정식 2 및 그래프 그림 1 는 자유도에 따라 다양한 형태를 가지며, 자유도가 증가할수록 정규분포에 근사됩니다.\n\\[ f(x; k) = \\frac{1}{2^{k/2} \\Gamma(k/2)} x^{(k/2) - 1} e^{-x/2}, \\quad x &gt; 0  \\tag{2}\\]\n\n\\(k\\) : degrees of freedom\n\\(Γ(k/2)\\) : Gamma function\n\\(x\\) : the value of the Chi-Square statistic\n\\(e\\) : the base of the natural logarithm, approximately equal to 2.718.\n\n\n\n\n\n\n\n\n\n그림 1: Comparison of Normal and Chi-Square Distributions with Different degrees of freedom"
  },
  {
    "objectID": "posts/chi-square-test/Chi_square_test.html#통계적-활용",
    "href": "posts/chi-square-test/Chi_square_test.html#통계적-활용",
    "title": "Chi-Square Test",
    "section": "통계적 활용",
    "text": "통계적 활용\n\n전제조건\n각 셀의 예상 빈도가 5 이상일 때 사용할 수 있습니다. 예상 빈도가 낮을 경우 카이제곱 검정의 근사치가 정확하지 않을 수 있습니다.\n\n\n독립성 검정\n카이제곱 검정은 독립성 검정에 널리 사용됩니다. 예를 들어, 두 변수 간의 관계가 독립적인지 여부를 확인하거나, 통계적으로 유의한 관계가 있는지를 확인할 때 사용됩니다.\n\n\n적합도 검정\n카이제곱 검정은 적합도 검정에도 사용됩니다. 이는 관측된 데이터가 이론적 분포와 일치하는지를 확인하는 데 사용됩니다. 예를 들어, 주사위를 60번 던졌을 때 각 숫자가 나오는 빈도가 균일한지를 확인할 수 있습니다."
  },
  {
    "objectID": "posts/chi-square-test/Chi_square_test.html#r에서의-카이스퀘어-검정",
    "href": "posts/chi-square-test/Chi_square_test.html#r에서의-카이스퀘어-검정",
    "title": "Chi-Square Test",
    "section": "R에서의 카이스퀘어 검정",
    "text": "R에서의 카이스퀘어 검정\n아래의 림크를 참조하시길 바랍니다."
  },
  {
    "objectID": "posts/basic-statistics/basic_statistics.html",
    "href": "posts/basic-statistics/basic_statistics.html",
    "title": "Basic statistics functions",
    "section": "",
    "text": "t-test\nR function : t.test -\noption arguments : alternative = c(“two.sided”, “less”, “greater”), formula (종속변수~ 독립변수)\nhelp files : ?t.test 를 치면 함수의 argument, values(results), detail에 대해서 설명이 나옴\n\nlibrary(survival)\ndata(\"rotterdam\")\n\nWarning in data(\"rotterdam\"): data set 'rotterdam' not found\n\ngroup1 &lt;- rotterdam[ rotterdam$grade == 2, \"age\"]\ngroup2 &lt;- rotterdam[ rotterdam$grade != 2, \"age\"]\nt.test(group1, group2) ## unmatched 임의의 두개의 vector로 비교\n\n\n    Welch Two Sample t-test\n\ndata:  group1 and group2\nt = -1.7437, df = 1444.4, p-value = 0.08143\nalternative hypothesis: true difference in means is not equal to 0\n95 percent confidence interval:\n -1.959901  0.115264\nsample estimates:\nmean of x mean of y \n 54.38161  55.30393 \n\n\n\nt.test(age~meno,data=rotterdam) ## matched 한개의 데이터프레임에서 paired t-test\n\n\n    Welch Two Sample t-test\n\ndata:  age by meno\nt = -76.545, df = 2972.8, p-value &lt; 2.2e-16\nalternative hypothesis: true difference in means between group 0 and group 1 is not equal to 0\n95 percent confidence interval:\n -21.53192 -20.45636\nsample estimates:\nmean in group 0 mean in group 1 \n       43.30107        64.29521 \n\n\n\n\n𝜒2 (chi-square) test\nR function : chisq.test\n\ntable(rotterdam[,c(\"hormon\",\"size\")])\n\n      size\nhormon &lt;=20 20-50  &gt;50\n     0 1283  1119  241\n     1  104   172   63\n\n\n\nchisq.test(table(rotterdam[,c(\"hormon\",\"size\")]), correct = TRUE)\n\n\n    Pearson's Chi-squared test\n\ndata:  table(rotterdam[, c(\"hormon\", \"size\")])\nX-squared = 51.92, df = 2, p-value = 5.317e-12\n\n\n\nchisq.test(rotterdam$hormon, rotterdam$chemo)\n\n\n    Pearson's Chi-squared test with Yates' continuity correction\n\ndata:  rotterdam$hormon and rotterdam$chemo\nX-squared = 29.771, df = 1, p-value = 4.862e-08\n\n\n\nx &lt;- matrix(c(12, 5, 7, 7), ncol = 2) ## matrix를 만들어서 검정하는 방법\nx\n\n     [,1] [,2]\n[1,]   12    7\n[2,]    5    7\n\n\n\nchisq.test(x)$p.value ## chisq test의 결과물은 list이다 여기서 p.value 부분만 출력\n\n[1] 0.4233054\n\n\n\nchisq.test(x, simulate.p.value = TRUE, B = 10000)$p.value\n\n[1] 0.2890711\n\n\n\n\nGeneralized linear regression and Loess smoothing (LOcal regrESSion)\nR function : glm (generalized linear models) 다중 선형회귀\n\nsuppressMessages(library(ggplot2))\ndata(economics, package=\"ggplot2\")\neconomics$index &lt;- 1:nrow(economics) # create index variable\nglm_model1 &lt;- glm(psavert~pop, data = economics)\nsummary(glm_model1)\n\n\nCall:\nglm(formula = psavert ~ pop, data = economics)\n\nCoefficients:\n              Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept)  2.595e+01  4.812e-01   53.92   &lt;2e-16 ***\npop         -6.758e-05  1.852e-06  -36.48   &lt;2e-16 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n(Dispersion parameter for gaussian family taken to be 2.645601)\n\n    Null deviance: 5034.6  on 573  degrees of freedom\nResidual deviance: 1513.3  on 572  degrees of freedom\nAIC: 2191.4\n\nNumber of Fisher Scoring iterations: 2\n\n\n\nanova(glm_model1)\n\nAnalysis of Deviance Table\n\nModel: gaussian, link: identity\n\nResponse: psavert\n\nTerms added sequentially (first to last)\n\n     Df Deviance Resid. Df Resid. Dev    F    Pr(&gt;F)    \nNULL                   573     5034.6                   \npop   1   3521.3       572     1513.3 1331 &lt; 2.2e-16 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n\n\nplot(glm_model1)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n# 데이터 선택\neconomics &lt;- economics[100:180, ]  # 좁은 범위 선택\n\n# Loess 모델 생성\nloessMod10 &lt;- loess(uempmed ~ index, data=economics, span=0.10)  # 10% smoothing span\nloessMod25 &lt;- loess(uempmed ~ index, data=economics, span=0.25)\nloessMod50 &lt;- loess(uempmed ~ index, data=economics, span=0.50)\n\n# 예측값 계산\nsmoothed10 &lt;- predict(loessMod10)\nsmoothed25 &lt;- predict(loessMod25)\nsmoothed50 &lt;- predict(loessMod50)\n\n# 그래프 그리기\nplot(economics$date, economics$uempmed, type=\"l\", main=\"Loess Smoothing and Prediction\", xlab=\"Date\", ylab=\"Unemployment Median\")\n\n# 예측된 smoothed 라인 추가\nlines(economics$date, smoothed10, col=\"red\")\nlines(economics$date, smoothed25, col=\"green\")\nlines(economics$date, smoothed50, col=\"blue\")\n\n위 코드가 제 개발환경에서 실행시 오류가 발생하므로 추후 수정해서 올려 드리겠습니다.\n\neconomics &lt;- economics[1:58,]\nlibrary(ggplot2)\nggplot(data=economics, aes(x=index, y=uempmed))+\ngeom_point()+\ngeom_smooth(method = \"lm\")\n\n`geom_smooth()` using formula = 'y ~ x'\n\n\n\n\n\n\n\n\n\n\n\nOne-way ANOVA\n\nsuppressMessages(library(psych))\nPlantGrowth ## 내장 dataset\n\n   weight group\n1    4.17  ctrl\n2    5.58  ctrl\n3    5.18  ctrl\n4    6.11  ctrl\n5    4.50  ctrl\n6    4.61  ctrl\n7    5.17  ctrl\n8    4.53  ctrl\n9    5.33  ctrl\n10   5.14  ctrl\n11   4.81  trt1\n12   4.17  trt1\n13   4.41  trt1\n14   3.59  trt1\n15   5.87  trt1\n16   3.83  trt1\n17   6.03  trt1\n18   4.89  trt1\n19   4.32  trt1\n20   4.69  trt1\n21   6.31  trt2\n22   5.12  trt2\n23   5.54  trt2\n24   5.50  trt2\n25   5.37  trt2\n26   5.29  trt2\n27   4.92  trt2\n28   6.15  trt2\n29   5.80  trt2\n30   5.26  trt2\n\n\n\nplot(weight~group, data = PlantGrowth) ## Boxplot으로 자동으로 그려준다.\n\n\n\n\n\n\n\n\n\nwith(PlantGrowth, describeBy(weight,group))\n\n\n Descriptive statistics by group \ngroup: ctrl\n   vars  n mean   sd median trimmed  mad  min  max range skew kurtosis   se\nX1    1 10 5.03 0.58   5.15       5 0.72 4.17 6.11  1.94 0.23    -1.12 0.18\n------------------------------------------------------------ \ngroup: trt1\n   vars  n mean   sd median trimmed  mad  min  max range skew kurtosis   se\nX1    1 10 4.66 0.79   4.55    4.62 0.53 3.59 6.03  2.44 0.47     -1.1 0.25\n------------------------------------------------------------ \ngroup: trt2\n   vars  n mean   sd median trimmed  mad  min  max range skew kurtosis   se\nX1    1 10 5.53 0.44   5.44     5.5 0.36 4.92 6.31  1.39 0.48    -1.16 0.14\n\n\n\nbartlett.test(PlantGrowth$weight ~ PlantGrowth$group) ## 등분산 가정을 체크함\n\n\n    Bartlett test of homogeneity of variances\n\ndata:  PlantGrowth$weight by PlantGrowth$group\nBartlett's K-squared = 2.8786, df = 2, p-value = 0.2371\n\n\n\naov_model &lt;- aov(weight~group, data = PlantGrowth)\nsummary(aov_model)\n\n            Df Sum Sq Mean Sq F value Pr(&gt;F)  \ngroup        2  3.766  1.8832   4.846 0.0159 *\nResiduals   27 10.492  0.3886                 \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n\n\n\nCorrelation tests\nPearson correlation formula\n\nSpearman correlation formula : non-parametric\n\nwhere 𝑥′ = 𝑟𝑎𝑛𝑘(𝑥) and 𝑦′ = 𝑟𝑎𝑛𝑘(𝑦)\nKendall correlation formula : non-parametric\n\nwhere 𝑛𝑐 : number of concordant pairs, 𝑛𝑑 : number of concordant pairs, 𝑛 : size of 𝑥 + 𝑦\n\nres &lt;- cor.test(economics$index, economics$uempmed, method = \"pearson\")\nres\n\n\n    Pearson's product-moment correlation\n\ndata:  economics$index and economics$uempmed\nt = 10.152, df = 56, p-value = 2.639e-14\nalternative hypothesis: true correlation is not equal to 0\n95 percent confidence interval:\n 0.6901407 0.8802298\nsample estimates:\n      cor \n0.8049464 \n\n\n\nres$p.value ## res는 리스트형태로 나오는 결과물이다. 여기에서 필요한 값만 골라냄\n\n[1] 2.639201e-14\n\n\n\nres$estimate\n\n      cor \n0.8049464 \n\n\n\nres2 &lt;- cor.test(economics$index, economics$uempmed, method = \"spearman\")\n\nWarning in cor.test.default(economics$index, economics$uempmed, method =\n\"spearman\"): Cannot compute exact p-value with ties\n\nres2\n\n\n    Spearman's rank correlation rho\n\ndata:  economics$index and economics$uempmed\nS = 9033.3, p-value = 1.578e-10\nalternative hypothesis: true rho is not equal to 0\nsample estimates:\n      rho \n0.7221299 \n\n\n\nres3 &lt;- cor.test(economics$index, economics$uempmed, method = \"kendall\")\nres3\n\n\n    Kendall's rank correlation tau\n\ndata:  economics$index and economics$uempmed\nz = 6.0101, p-value = 1.854e-09\nalternative hypothesis: true tau is not equal to 0\nsample estimates:\n      tau \n0.5541495 \n\n\n\n\nSurvival analysis\n\nKaplan Meier Analysis - Basic survival model survival::Surv\n\n\nkm &lt;- Surv(rotterdam$dtime, event = rotterdam$death) ## default type : \"right\"\nplot(km) ## km - Surv class (time, status) 가지고 있는 리스트\n\n\n\n\n\n\n\n\n\nmedian(km); mean(km) ## Surv 객체에 대한 method 함수들이 있다. plot.Surv포함\n\n$quantile\n  50 \n4033 \n\n$lower\n  50 \n3888 \n\n$upper\n  50 \n4309 \n\n\n[1] 1302.883\n\n\n\nKaplan Meier Analysis - survfit model km_\n\n\nkm_fit &lt;- survfit(km~rotterdam$meno)\nsummary(km_fit, c(365*1:19)) ### 정해진 time에 맞는 생존테이블표를 만든다.\n\nCall: survfit(formula = km ~ rotterdam$meno)\n\n                rotterdam$meno=0 \n time n.risk n.event survival std.err lower 95% CI upper 95% CI\n  365   1298      13    0.990 0.00274        0.985        0.995\n  730   1236      56    0.947 0.00617        0.935        0.959\n 1095   1140      90    0.878 0.00905        0.861        0.896\n 1460   1071      59    0.833 0.01035        0.813        0.853\n 1825    973      59    0.786 0.01141        0.764        0.809\n 2190    865      50    0.745 0.01222        0.721        0.769\n 2555    754      43    0.706 0.01292        0.681        0.732\n 2920    611      31    0.675 0.01354        0.649        0.702\n 3285    480      15    0.656 0.01397        0.629        0.684\n 3650    345      21    0.623 0.01505        0.594        0.653\n 4015    217      13    0.595 0.01631        0.563        0.627\n 4380    138       6    0.575 0.01760        0.542        0.611\n 4745     88       4    0.554 0.02000        0.516        0.594\n 5110     54       3    0.530 0.02334        0.487        0.578\n 5475     29       2    0.506 0.02783        0.455        0.564\n 5840     14       1    0.481 0.03617        0.415        0.558\n 6205      5       2    0.391 0.06658        0.280        0.546\n 6570      3       0    0.391 0.06658        0.280        0.546\n 6935      1       0    0.391 0.06658        0.280        0.546\n\n                rotterdam$meno=1 \n time n.risk n.event survival std.err lower 95% CI upper 95% CI\n  365   1616      46    0.972 0.00402       0.9645        0.980\n  730   1508     103    0.910 0.00701       0.8966        0.924\n 1095   1366     129    0.832 0.00919       0.8143        0.850\n 1460   1245     111    0.764 0.01046       0.7440        0.785\n 1825   1111      87    0.710 0.01122       0.6883        0.732\n 2190    944      82    0.655 0.01186       0.6326        0.679\n 2555    819      58    0.614 0.01231       0.5901        0.638\n 2920    642      45    0.577 0.01272       0.5530        0.603\n 3285    474      42    0.536 0.01334       0.5104        0.563\n 3650    342      31    0.496 0.01418       0.4685        0.524\n 4015    188      35    0.430 0.01614       0.3998        0.463\n 4380    113      17    0.386 0.01772       0.3531        0.423\n 4745     62       6    0.358 0.01989       0.3210        0.399\n 5110     28       7    0.309 0.02431       0.2652        0.361\n 5475     14       1    0.293 0.02796       0.2431        0.353\n 5840      8       3    0.217 0.04323       0.1469        0.321\n 6205      4       0    0.217 0.04323       0.1469        0.321\n 6570      1       1    0.163 0.05710       0.0819        0.324\n 6935      1       0    0.163 0.05710       0.0819        0.324\n\n\n\nsuppressMessages(library(survminer))\nplot(km_fit, col = rainbow(2), lty=1:2)\nlegend(\"topright\", legend = c(\"Menopause(-)\",\"Menopause(+)\"),\n       col= rainbow(2), lty=1:2)\nlibrary(survminer)\nggsurvplot(km_fit, data = rotterdam,\n           conf.int = T, xscale = 365.2425, ## xscale can be \"d_y\"\n           break.x.by = 5*365.2425,\n           pval = T, pval.size =4, surv.median.line = \"hv\",\n           risk.table = FALSE, ## if TRUE, risk table is displayed under graph\n           legend.title=\"Menopause\", legend.labs=c(\"No\",\"Yes\"),\n           palette = c(\"#E7B800\", \"#2E9FDF\"),)\n\nWarning in geom_segment(aes(x = 0, y = max(y2), xend = max(x1), yend = max(y2)), : All aesthetics have length 1, but the data has 2 rows.\nℹ Please consider using `annotate()` or provide this layer with data containing\n  a single row.\nAll aesthetics have length 1, but the data has 2 rows.\nℹ Please consider using `annotate()` or provide this layer with data containing\n  a single row.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n## ggplot + survminer package\n\nCox Proportional model\n\n\nargs(coxph)\n\nfunction (formula, data, weights, subset, na.action, init, control, \n    ties = c(\"efron\", \"breslow\", \"exact\"), singular.ok = TRUE, \n    robust, model = FALSE, x = FALSE, y = TRUE, tt, method = ties, \n    id, cluster, istate, statedata, nocenter = c(-1, 0, 1), ...) \nNULL\n\n\n\nlibrary(carData) ## Rossi data set 이용하기 위해서 사용\nsuppressMessages(library(car)) ## Anova function\ncolnames(Rossi) # emp1-52 : factor (yes or no)\n\n [1] \"week\"   \"arrest\" \"fin\"    \"age\"    \"race\"   \"wexp\"   \"mar\"    \"paro\"  \n [9] \"prio\"   \"educ\"   \"emp1\"   \"emp2\"   \"emp3\"   \"emp4\"   \"emp5\"   \"emp6\"  \n[17] \"emp7\"   \"emp8\"   \"emp9\"   \"emp10\"  \"emp11\"  \"emp12\"  \"emp13\"  \"emp14\" \n[25] \"emp15\"  \"emp16\"  \"emp17\"  \"emp18\"  \"emp19\"  \"emp20\"  \"emp21\"  \"emp22\" \n[33] \"emp23\"  \"emp24\"  \"emp25\"  \"emp26\"  \"emp27\"  \"emp28\"  \"emp29\"  \"emp30\" \n[41] \"emp31\"  \"emp32\"  \"emp33\"  \"emp34\"  \"emp35\"  \"emp36\"  \"emp37\"  \"emp38\" \n[49] \"emp39\"  \"emp40\"  \"emp41\"  \"emp42\"  \"emp43\"  \"emp44\"  \"emp45\"  \"emp46\" \n[57] \"emp47\"  \"emp48\"  \"emp49\"  \"emp50\"  \"emp51\"  \"emp52\" \n\n\n\ncox_model1 &lt;- coxph(Surv(week, arrest) ~\nfin + age + race + wexp + mar + paro + prio,\ndata = Rossi)\nsummary(cox_model1)\n\nCall:\ncoxph(formula = Surv(week, arrest) ~ fin + age + race + wexp + \n    mar + paro + prio, data = Rossi)\n\n  n= 432, number of events= 114 \n\n                   coef exp(coef) se(coef)      z Pr(&gt;|z|)   \nfinyes         -0.37942   0.68426  0.19138 -1.983  0.04742 * \nage            -0.05744   0.94418  0.02200 -2.611  0.00903 **\nraceother      -0.31390   0.73059  0.30799 -1.019  0.30812   \nwexpyes        -0.14980   0.86088  0.21222 -0.706  0.48029   \nmarnot married  0.43370   1.54296  0.38187  1.136  0.25606   \nparoyes        -0.08487   0.91863  0.19576 -0.434  0.66461   \nprio            0.09150   1.09581  0.02865  3.194  0.00140 **\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n               exp(coef) exp(-coef) lower .95 upper .95\nfinyes            0.6843     1.4614    0.4702    0.9957\nage               0.9442     1.0591    0.9043    0.9858\nraceother         0.7306     1.3688    0.3995    1.3361\nwexpyes           0.8609     1.1616    0.5679    1.3049\nmarnot married    1.5430     0.6481    0.7300    3.2614\nparoyes           0.9186     1.0886    0.6259    1.3482\nprio              1.0958     0.9126    1.0360    1.1591\n\nConcordance= 0.64  (se = 0.027 )\nLikelihood ratio test= 33.27  on 7 df,   p=2e-05\nWald test            = 32.11  on 7 df,   p=4e-05\nScore (logrank) test = 33.53  on 7 df,   p=2e-05\n\n\n\nAnova(cox_model1)\n\nAnalysis of Deviance Table (Type II tests)\n     LR Chisq Df Pr(&gt;Chisq)   \nfin    3.9862  1   0.045874 * \nage    7.9880  1   0.004709 **\nrace   1.1252  1   0.288812   \nwexp   0.5003  1   0.479352   \nmar    1.4312  1   0.231572   \nparo   0.1870  1   0.665450   \nprio   8.9766  1   0.002735 **\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n\n\nanova(cox_model1)\n\nAnalysis of Deviance Table\n Cox model: response is Surv(week, arrest)\nTerms added sequentially (first to last)\n\n      loglik   Chisq Df Pr(&gt;|Chi|)    \nNULL -675.38                          \nfin  -673.46  3.8371  1  0.0501315 .  \nage  -666.24 14.4526  1  0.0001437 ***\nrace -665.84  0.7887  1  0.3745021    \nwexp -664.22  3.2472  1  0.0715467 .  \nmar  -663.58  1.2841  1  0.2571359    \nparo -663.24  0.6798  1  0.4096690    \nprio -658.75  8.9766  1  0.0027346 ** \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n\n모델의 전체적인 생존곡선을 알고 싶으면 survfit 함수를 이용해서 생존곡선을 그릴 수 있다\n\nplot(survfit(cox_model1), ylim = c(0.6,1),xlab = \"weeks\",\nylab = \"Proportion not rearrested\")\n\n\n\n\n\n\n\n\n\nRossi.fin &lt;- with(Rossi, data.frame(fin=c(0, 1),\nage=rep(mean(age), 2), race=rep(mean(race == \"other\"), 2),\nwexp=rep(mean(wexp == \"yes\"), 2), mar=rep(mean(mar == \"not married\"), 2),\nparo=rep(mean(paro == \"yes\"), 2), prio=rep(mean(prio), 2)))\n## fin = 0,1 이것을 두그룹으로 나누고 나머지 변수들은 평균적인 값으로 고정해 버림\nplot(survfit(cox_model1, newdata = Rossi.fin), conf.int = T,\nlty = c(1,2), ylim = c(0.6,1),xlab = \"weeks\",\nylab = \"Proportion not rearrested\", col = c(\"blue\",\"red\")\n)\n\nWarning in model.frame.default(data = structure(list(fin = c(0, 1), age =\nc(24.5972222222222, : variable 'fin' is not a factor\n\n\nWarning in model.frame.default(data = structure(list(fin = c(0, 1), age =\nc(24.5972222222222, : variable 'race' is not a factor\n\n\nWarning in model.frame.default(data = structure(list(fin = c(0, 1), age =\nc(24.5972222222222, : variable 'wexp' is not a factor\n\n\nWarning in model.frame.default(data = structure(list(fin = c(0, 1), age =\nc(24.5972222222222, : variable 'mar' is not a factor\n\n\nWarning in model.frame.default(data = structure(list(fin = c(0, 1), age =\nc(24.5972222222222, : variable 'paro' is not a factor\n\nlegend(\"bottomleft\", legend=c(\"fin = no\", \"fin = yes\"), lty=c(1 ,2),\ncol=c(\"blue\",\"red\") , inset=0.02)",
    "crumbs": [
      "Statistics",
      "Basic statistics functions"
    ]
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Blog",
    "section": "",
    "text": "정렬\n       디폴트\n         \n          제목\n        \n         \n          날짜 - 날짜(오름차순)\n        \n         \n          날짜 - 날짜(내림차순)\n        \n         \n          저자\n        \n     \n  \n    \n      \n      \n    \n\n\n\n\n\n\n\n\n\n\nChi-Square Test\n\n\n\n\n\n\nstatistics\n\n\nChi-Square\n\n\nCategoical Data\n\n\n\nStatistics concept of Chi-Square test\n\n\n\n\n\n2024. 10. 4.\n\n\nRPythonStudyGroup feat. ChatGPT\n\n\n\n\n\n\n\n\n\n\n\n\nVS Code Setup\n\n\n\n\n\n\nPython\n\n\nVS Code\n\n\nsetup\n\n\n\nGuidance on Installing and Configuring VS Code\n\n\n\n\n\n2024. 8. 31.\n\n\nRPythonStudyGroup feat. ChatGPT\n\n\n\n\n\n\n\n\n\n\n\n\nGroup comparison in continuous variables\n\n\n\n\n\n\nstatistics\n\n\n\nStatistics concept in group comparison in continuous variables\n\n\n\n\n\n2024. 9. 27.\n\n\nRPythonStudyGroup feat. ChatGPT\n\n\n\n\n\n\n\n\n\n\n\n\nIntroduction to Quarto\n\n\n\n\n\n\nintroduction\n\n\n\nQuarto is a modern tool for reproducible research and data-centric reporting, supporting dynamic documentation in multi-language environments and integrating programming workflows.\n\n\n\n\n\n2024. 9. 1.\n\n\nRPythonStudyGroup feat. ChatGPT\n\n\n\n\n\n\n\n\n\n\n\n\nIntroduction to Resources\n\n\n\n\n\n\nintroduction\n\n\n\nIntroducing medical (big) data resources that are helpful for research\n\n\n\n\n\n2024. 8. 31.\n\n\nRPythonStudyGroup feat. ChatGPT\n\n\n\n\n\n\n\n\n\n\n\n\nIntroduction to statistics\n\n\n\n\n\n\nintroduction\n\n\n\nStatistics in R\n\n\n\n\n\n2024. 9. 27.\n\n\nRPythonStudyGroup feat. ChatGPT\n\n\n\n\n\n\n\n\n\n\n\n\nSurvival analysis\n\n\n\n\n\n\nR\n\n\nstatistics\n\n\nsurvival analysis\n\n\n\njust copy from other well-organized webpages\n\n\n\n\n\n2024. 8. 31.\n\n\nRPythonStudyGroup feat. ChatGPT\n\n\n\n\n\n\n\n\n\n\n\n\nIntroduction to Utilities\n\n\n\n\n\n\nintroduction\n\n\n\nIntroducing open source programs that are helpful for research groups\n\n\n\n\n\n2024. 9. 27.\n\n\nRPythonStudyGroup feat. ChatGPT\n\n\n\n\n\n\n\n\n\n\n\n\nManuscripting with Quarto Example\n\n\n\n\n\n\nR\n\n\nQuarto\n\n\n\nQuarto example how to wwite journal manuscript with unidentified real data\n\n\n\n\n\n2024. 8. 31.\n\n\nRPythonStudyGroup feat. ChatGPT\n\n\n\n\n\n\n\n\n\n\n\n\nGit & Github setup\n\n\n\n\n\n\nGit\n\n\nsetup\n\n\n\nGuidance on Installing and Configuring Git & Github\n\n\n\n\n\n2024. 5. 6.\n\n\nRPythonStudyGroup feat. ChatGPT\n\n\n\n\n\n\n\n\n\n\n\n\nPython setup\n\n\n\n\n\n\nPython\n\n\nsetup\n\n\n\nGuidance on Installing and Configuring Python\n\n\n\n\n\n2024. 9. 8.\n\n\nRPythonStudyGroup feat. ChatGPT\n\n\n\n\n\n\n\n\n\n\n\n\nIntroduction to Python\n\n\n\n\n\n\nPython\n\n\nintroduction\n\n\n\nBrief history of Python development and application examples in medical research\n\n\n\n\n\n2024. 9. 7.\n\n\nRPythonStudyGroup feat. ChatGPT\n\n\n\n\n\n\n\n\n\n\n\n\nR syntax\n\n\n\n\n\n\nR\n\n\nsyntax\n\n\n\nUnderstanding data type and manupulation\n\n\n\n\n\n2024. 8. 31.\n\n\nRPythonStudyGroup feat. ChatGPT\n\n\n\n\n\n\n\n\n\n\n\n\nBasic statistics functions\n\n\n\n\n\n\nR\n\n\n\nBrief introduction on basic statistics functions in R\n\n\n\n\n\n2024. 7. 17.\n\n\nHaewon Lee\n\n\n\n\n\n\n\n\n\n\n\n\nBuilt-in Data sets in R\n\n\n\n\n\n\nR\n\n\n\nR includes built-in datasets. These datasets are useful for testing, teaching, and practicing.\n\n\n\n\n\n2024. 7. 17.\n\n\nHaewon Lee\n\n\n\n\n\n\n\n\n\n\n\n\nOutliers detection in continuous variables\n\n\n\n\n\n\nR\n\n\npreprocessing\n\n\noutlier\n\n\n\nHow to detect outliers in continuous variables using normal distribution and Box-Cox transformation.\n\n\n\n\n\n2024. 7. 8.\n\n\nRPythonStudyGroup feat. ChatGPT\n\n\n\n\n\n\n\n\n\n\n\n\nR setup\n\n\n\n\n\n\nR\n\n\nsetup\n\n\n\nGuidance on Installing and Configuring R and Rtools\n\n\n\n\n\n2024. 5. 6.\n\n\nRPythonStudyGroup feat. ChatGPT\n\n\n\n\n\n\n\n\n\n\n\n\nRStudio setup\n\n\n\n\n\n\nR\n\n\nRStudio\n\n\nsetup\n\n\n\nGuidance on Installing and Configuring RStudio\n\n\n\n\n\n2024. 5. 6.\n\n\nRPythonStudyGroup feat. ChatGPT\n\n\n\n\n\n\n\n\n\n\n\n\nIntroduciton to R\n\n\n\n\n\n\nR\n\n\nintroduction\n\n\n\nBrief history of R developement and application examples in medical research\n\n\n\n\n\n2024. 5. 4.\n\n\nRPythonStudyGroup feat. ChatGPT\n\n\n\n\n\n\n\n\n\n\n\n\nfor Medical Big Data Analysis\n\n\n\n\n\n\nintroduction\n\n\n\nThis site was created to assist in-house researchers who are interested in analyzing medical data using R and Python.\n\n\n\n\n\n2024. 4. 12.\n\n\nRPythonStudyGroup feat. ChatGPT\n\n\n\n\n\n\n일치 없음"
  },
  {
    "objectID": "posts/about/about.html",
    "href": "posts/about/about.html",
    "title": "for Medical Big Data Analysis",
    "section": "",
    "text": "의료데이터 분석연구에서 R과 Python의 필요성\n의학연구를 통계프로그램으로 SPSS 또는 MedCalc가 많이 사용됩니다. 그러나 병원에서만 이용할 수 있고 분석과정을 자동화할 수 없습니다.\n이에 비해 오픈소스 통계언어인 R은 간단한 프로그램밍을 통해 분석과정을 자동화할 수 있고, 시각화에 뛰어나고 분석결과를 의학논문 작성까지 연계할 수 있고 웹에 게시하는 것도 용이합니다.\nPython은 범용적인 오픈소스 프로그램밍 언어이며 기계학습과 딥러닝에 강점이 있고 R과의 연계도 뛰어납니다. 공통적으로 둘다 빅데이터 분석이 가능하다는 장점도 있습니다.\n특정 저널에서는 재현가능한 연구를 위해 R Markdown 형식으로 투고를 받기도 합니다. 따라서 임상연구를 포함해서 연구자들에게 장점이 맞은 오픈소스툴입니다.\n\n\nR과 Python을 이용한 의료데이터 분석연구회 (RPythonStudy Group)\nR과 Python을 이용하여 의료데이터를 분석하고자 하는 원내 연구자들에게 도움이 되고자 이 사이트를 만들었습니다.\n\n\n\ne-mail\n\nr.python.study@gmail.com"
  },
  {
    "objectID": "posts/built-in-dataset/built_in_dataset.html",
    "href": "posts/built-in-dataset/built_in_dataset.html",
    "title": "Built-in Data sets in R",
    "section": "",
    "text": "data(\"volcano\") ## built-in dataset 중에서 volcano 사용 \nlibrary(survival) \ndata(package=\"survival\") ## survival package에 어떤 데이터 세트들이 있는지 확인 \ndata(cancer) ## data(cancer, package=\"survival\") 와 같이 사용해도 된다. \nstr(lung) ## cancer dataset에는 다양한 암종류의 생존분석용 데이터가 들어가 있다.\n\n'data.frame':   228 obs. of  10 variables:\n $ inst     : num  3 3 3 5 1 12 7 11 1 7 ...\n $ time     : num  306 455 1010 210 883 ...\n $ status   : num  2 2 1 2 2 1 2 2 2 2 ...\n $ age      : num  74 68 56 57 60 74 68 71 53 61 ...\n $ sex      : num  1 1 1 1 1 1 2 2 1 1 ...\n $ ph.ecog  : num  1 0 0 1 0 1 2 2 1 2 ...\n $ ph.karno : num  90 90 90 90 100 50 70 60 70 70 ...\n $ pat.karno: num  100 90 90 60 90 80 60 80 80 70 ...\n $ meal.cal : num  1175 1225 NA 1150 NA ...\n $ wt.loss  : num  NA 15 15 11 0 0 10 1 16 34 ...",
    "crumbs": [
      "R",
      "Built-in Data sets in R"
    ]
  },
  {
    "objectID": "posts/built-in-dataset/built_in_dataset.html#volcano",
    "href": "posts/built-in-dataset/built_in_dataset.html#volcano",
    "title": "Built-in Data sets in R",
    "section": "",
    "text": "data(\"volcano\") ## built-in dataset 중에서 volcano 사용 \nlibrary(survival) \ndata(package=\"survival\") ## survival package에 어떤 데이터 세트들이 있는지 확인 \ndata(cancer) ## data(cancer, package=\"survival\") 와 같이 사용해도 된다. \nstr(lung) ## cancer dataset에는 다양한 암종류의 생존분석용 데이터가 들어가 있다.\n\n'data.frame':   228 obs. of  10 variables:\n $ inst     : num  3 3 3 5 1 12 7 11 1 7 ...\n $ time     : num  306 455 1010 210 883 ...\n $ status   : num  2 2 1 2 2 1 2 2 2 2 ...\n $ age      : num  74 68 56 57 60 74 68 71 53 61 ...\n $ sex      : num  1 1 1 1 1 1 2 2 1 1 ...\n $ ph.ecog  : num  1 0 0 1 0 1 2 2 1 2 ...\n $ ph.karno : num  90 90 90 90 100 50 70 60 70 70 ...\n $ pat.karno: num  100 90 90 60 90 80 60 80 80 70 ...\n $ meal.cal : num  1175 1225 NA 1150 NA ...\n $ wt.loss  : num  NA 15 15 11 0 0 10 1 16 34 ...",
    "crumbs": [
      "R",
      "Built-in Data sets in R"
    ]
  },
  {
    "objectID": "posts/built-in-dataset/built_in_dataset.html#rotterdam-breast-cancer-dataset-in-survival-package",
    "href": "posts/built-in-dataset/built_in_dataset.html#rotterdam-breast-cancer-dataset-in-survival-package",
    "title": "Built-in Data sets in R",
    "section": "rotterdam : breast cancer dataset in survival package",
    "text": "rotterdam : breast cancer dataset in survival package\n\nlibrary(moonBook) \nmytable(grade~. , data=rotterdam)\n\n\n       Descriptive Statistics by 'grade'       \n———————————————————————————————————————————————— \n                  2               3          p  \n               (N=794)        (N=2188)    \n———————————————————————————————————————————————— \n pid       1328.4 ± 865.1  1569.0 ± 860.9  0.000\n year       1987.9 ±  3.1   1988.3 ±  3.0  0.004\n age         54.4 ± 12.7     55.3 ± 13.1   0.086\n meno                                      0.000\n   - 0       392 (49.4%)     920 (42.0%)        \n   - 1       402 (50.6%)    1268 (58.0%)        \n size                                      0.000\n   - &lt;=20    462 (58.2%)     925 (42.3%)        \n   - 20-50   290 (36.5%)    1001 (45.7%)        \n   - &gt;50     42 ( 5.3%)      262 (12.0%)        \n nodes        2.0 ±  3.7      3.0 ±  4.6   0.000\n pgr        236.2 ± 385.8   134.9 ± 242.8  0.000\n er         179.8 ± 291.9   161.8 ± 265.0  0.127\n hormon                                    0.000\n   - 0       735 (92.6%)    1908 (87.2%)        \n   - 1       59 ( 7.4%)      280 (12.8%)        \n chemo                                     1.000\n   - 0       640 (80.6%)    1762 (80.5%)        \n   - 1       154 (19.4%)     426 (19.5%)        \n rtime     2458.3 ± 1408.6 1967.1 ± 1370.8 0.000\n recur                                     0.000\n   - 0       480 (60.5%)     984 (45.0%)        \n   - 1       314 (39.5%)    1204 (55.0%)        \n dtime     2908.9 ± 1278.6 2495.2 ± 1287.8 0.000\n death                                     0.000\n   - 0       532 (67.0%)    1178 (53.8%)        \n   - 1       262 (33.0%)    1010 (46.2%)        \n———————————————————————————————————————————————— \n\n\n\n# suppressMessages(library(dplyr)) \n# mytable(grade~. , data=rotterdam) %&gt;% mylatex() %&gt;% cat}\n\nLaTeX을 이용하여 깔끔한 논문형식의 테이블을 만들 수 있는 방법은 위 코드를 실행시킬 수 있게 되면 다음에 소개하겠다.",
    "crumbs": [
      "R",
      "Built-in Data sets in R"
    ]
  },
  {
    "objectID": "posts/Git-setup/Git_setup.html",
    "href": "posts/Git-setup/Git_setup.html",
    "title": "Git & Github setup",
    "section": "",
    "text": "Git은 2005년 리누스 토르발스가 개발한 오픈 소스 분산 버전 관리 시스템(DVCS, Distributed Version Control System)으로, 소스코드의 스냅샷을 기록하여, 변경이력관리와 특정 시점으로 복귀하거나 다수의 개발자가 동시에 분산된 환경에서 브랜칭을 통해 코드를 개발하고, 병합 절차를 통해 충돌을 해결할 수 있는 기능이 있습니다. 이러한 분산형 구조와 성능 최적화 덕분에, Git은 전 세계적으로 대다수 개발팀에서 사용되는 표준 버전 관리 도구로 자리잡았습니다.",
    "crumbs": [
      "Utilities",
      "Git & Github setup"
    ]
  },
  {
    "objectID": "posts/Git-setup/Git_setup.html#git란",
    "href": "posts/Git-setup/Git_setup.html#git란",
    "title": "Git & Github setup",
    "section": "",
    "text": "Git은 2005년 리누스 토르발스가 개발한 오픈 소스 분산 버전 관리 시스템(DVCS, Distributed Version Control System)으로, 소스코드의 스냅샷을 기록하여, 변경이력관리와 특정 시점으로 복귀하거나 다수의 개발자가 동시에 분산된 환경에서 브랜칭을 통해 코드를 개발하고, 병합 절차를 통해 충돌을 해결할 수 있는 기능이 있습니다. 이러한 분산형 구조와 성능 최적화 덕분에, Git은 전 세계적으로 대다수 개발팀에서 사용되는 표준 버전 관리 도구로 자리잡았습니다.",
    "crumbs": [
      "Utilities",
      "Git & Github setup"
    ]
  },
  {
    "objectID": "posts/Git-setup/Git_setup.html#git-유용성",
    "href": "posts/Git-setup/Git_setup.html#git-유용성",
    "title": "Git & Github setup",
    "section": "Git 유용성",
    "text": "Git 유용성\n코딩초보에게는 Git 사용법이 다소 어려울 수 있지만, 코드를 수정하다가 문제가 발생했을 때, 변경이력관리 기능을 이용해 특정시점으로 되돌릴 수 있으며 이 자체가 백업 기능도 되므로 유용하기에 연구회에서는 Git 사용을 추천합니다.",
    "crumbs": [
      "Utilities",
      "Git & Github setup"
    ]
  },
  {
    "objectID": "posts/Git-setup/Git_setup.html#설치안내문서",
    "href": "posts/Git-setup/Git_setup.html#설치안내문서",
    "title": "Git & Github setup",
    "section": "설치안내문서",
    "text": "설치안내문서\nGit 설치에 대한 공식문서(https://git-scm.com/book/en/v2/Getting-Started-Installing-Git)를 참고하는 것이 이상적이지만 , 아래의 요약을 참고하여 설치 하셔도 됩니다.",
    "crumbs": [
      "Utilities",
      "Git & Github setup"
    ]
  },
  {
    "objectID": "posts/Git-setup/Git_setup.html#설치파일",
    "href": "posts/Git-setup/Git_setup.html#설치파일",
    "title": "Git & Github setup",
    "section": "설치파일",
    "text": "설치파일\nGit 공식다운로드사이트(https://git-scm.com/downloads)에서 자신의 운영체제에 적합한 최신 설치파일을 다운로드하고 설치합니다. 2024년 9월 23일 현재 윈도우용 64비트 최신 설치파일은 Git-2.46.2-64-bit.exe 입니다.",
    "crumbs": [
      "Utilities",
      "Git & Github setup"
    ]
  },
  {
    "objectID": "posts/Git-setup/Git_setup.html#설치옵션",
    "href": "posts/Git-setup/Git_setup.html#설치옵션",
    "title": "Git & Github setup",
    "section": "설치옵션",
    "text": "설치옵션\n\n설치경로\n기본값은 C:\\Program Files\\Git이며 기본값을 추천합니다.\n\n\n구성요소 선택\n기본값은 그림 1 와 같으며 기본값을 추천합니다.\n\n\n\n\n\n\n그림 1: Options to select Components\n\n\n\n\n\n바로가기아이콘\n기본값은 Git이란 시작메뉴폴더에 바로가기아이콘을 만드는 것입니다 그림 2 . 하지만 RStudio엣 Git을 사용할 경우 RStudio에서 Git을 사용할 수 있으므로 바로가기아이콘을 만들지 않는 것을 추천합니다.\n\n\n\n\n\n\n그림 2: Options to select Start Menu Folder for programs’ shortcut\n\n\n\n\n\n텍스트 에디터\n기본값은 Vim이며, 연구회는 Python IDE로 VS Code를 추천하고 있고 상대적으로 Vim보다 사용이 쉬우므로 이를 추천합니다 그림 3.\n\n\n\n\n\n\n그림 3: Options to select Text Editor\n\n\n\n\n\n기본 브렌치명\n기본값은 master이며, 2020년 10월 1일부터 GitHub에서는 기본 브렌치명을 master에서 main으로 변경하였습니다. 이에 따라 Git 설치 시 기본 브렌치명을 main으로 설정하는 것을 추천합니다 그림 4.\n\n\n\n\n\n\n그림 4: Options to select Default Branch Name\n\n\n\n\n\n환경변수 설정\n기본값은 환경변수에 Git 실행파일경로를 추가하는 것이며 그림 5, 기본값을 추천합니다.\n\n\n\n\n\n\n그림 5: Options to select Path Environment\n\n\n\n\n\nSSH 선택\nGit은 원격 저장소와의 안전한 통신을 위해 SSH를 사용하는 경우가 많습니다. GitHub, GitLab, Bitbucket과 같은 플랫폼은 SSH 키 기반 인증을 제공하여, 비밀번호 대신 SSH 키를 사용해 원격 저장소에 안전하게 접속할 수 있습니다. OpenSSH는 오픈 소스 소프트웨어로, Git 설치 시 선택적으로 설치할 수 있으며, SSH 기반 인증을 설정할 때 주로 사용됩니다. 설치 과정에서 OpenSSH는 기본적으로 선택되어 있으며 그림 6, 특별한 이유가 없다면 기본값을 사용하는 것이 권장됩니다.\n\n\n\n\n\n\n그림 6: Options to select OpenSSH\n\n\n\n\n\nSSL/TLS 라이브러리 선택\nSSL/TLS는 Git이 HTTPS 연결을 통해 원격 저장소와 통신할 때 사용하는 암호화 라이브러리입니다. OpenSSL은 더 넓은 암호화 기능과 최신 표준 지원, 리눅스와의 호환성이 중요한 경우 추천되며, Windows 고유 SSL/TLS 라이브러리(Schannel)는 Windows 시스템과의 통합과 간편한 설정을 원할 때 추천합니다. 연구회에서는 기본값인 OpenSSL을 추천합니다 그림 7.\n\n\n\n\n\n\n그림 7: Options to select SSL/TLS library\n\n\n\n\n\n줄바꿈 변환 설정\n윈도우에서는 줄바꿈 기본 설정이 CRLF(Carriage Return Line Feed)입니다. 반면, Unix 계열(리눅스, macOS)은 LF(Line Feed)를 사용합니다. 운영체제를 오가며 개발할 경우, Git은 이러한 줄바꿈 차이를 해결하기 위해 줄바꿈 변환 기능(Line Ending Conversion)을 지원합니다. checkout과 commit 시에 자동으로 줄바꿈을 변환할지 설정할 수 있는데, 기본값은 Checkout Windows-style, commit Unix-style line endings이며, 이는 Windows에서 개발할 때 적합한 설정입니다. Linux 또는 macOS에서 개발할 경우, Checkout as-is, commit Unix-style line endings를 선택하는 것이 좋습니다 그림 8.\n\n\n\n\n\n\n그림 8: Options to select Line Ending Conversion\n\n\n\n\n\n터미널 에뮬레이터\nGit Bash에서 사용할 터미널 환경을 결정하는 옵션입니다. 각 옵션은 Git Bash가 실행될 때 사용할 터미널을 정의하며, 사용자 경험과 터미널 기능에서 차이가 있습니다. MinTTY는 더 발전된 터미널 경험을 제공하며, 유닉스 스타일에 가까운 작업 환경을 제공합니다. 특히, 리눅스/유닉스에 익숙한 사용자나 Git Bash를 주로 사용하는 경우 적합합니다. Windows 기본 콘솔 창은 Windows에서 기본 제공되는 터미널 인터페이스로, CMD와 같은 익숙한 환경을 선호하는 사용자에게 적합합니다. 특히, Windows 사용자나 CMD를 주로 사용하는 경우 적합합니다 그림 9.\n\n\n\n\n\n\n그림 9: Options to select Terminal Emulator\n\n\n\n\n\ngit pull 설정\n이 설정은 git pull 명령을 실행했을 때, 로컬 브랜치와 원격 브랜치 간의 변경 사항을 어떻게 병합할지를 결정합니다 그림 10.\n1. Fast-forward or merge (기본 설정) 이 옵션은 기본값으로 설정되어 있으며, Git이 상황에 따라 fast-forward 병합 또는 병합 커밋(merge commit)을 선택합니다.\nFast-forward: 만약 로컬 브랜치에서 추가적인 변경 사항이 없고, 단순히 원격 브랜치의 커밋을 가져와서 이어 붙일 수 있는 경우, Git은 fast-forward 병합을 수행합니다. 이 경우 병합 커밋이 생성되지 않고, 기존 커밋의 연속선 상에 새로운 커밋이 추가됩니다.\n장점: 이력이 깔끔하게 이어져서, 불필요한 병합 커밋 없이 간결한 로그를 유지할 수 있습니다.\n단점: 협업 중 복잡한 병합 기록을 관리하는 데는 한계가 있을 수 있습니다.\nMerge: 로컬 브랜치에 변경 사항이 있거나, 원격 브랜치의 변경 사항을 단순히 이어 붙일 수 없는 경우에는 병합 커밋(merge commit)이 생성됩니다. 이 커밋은 두 브랜치의 이력을 병합하면서, 병합 지점을 명확하게 표시합니다.\n장점: 병합이 발생한 지점을 명확하게 구분할 수 있어, 누가 어떤 작업을 했는지 추적하기 쉽습니다.\n단점: 병합 커밋이 많아지면 로그가 복잡해질 수 있습니다.\n2. Rebase Rebase 옵션은 원격 브랜치의 변경 사항을 로컬 브랜치에 병합 커밋 없이 적용하는 방식입니다. Rebase는 커밋을 재정렬하여 마치 원격 브랜치에서 작업한 것처럼 히스토리를 재작성합니다.\nRebase 동작 방식: 로컬 브랜치에서 발생한 커밋을 잠시 제거한 후, 원격 브랜치의 변경 사항을 먼저 적용하고, 그 뒤에 로컬 커밋을 재적용합니다. 이렇게 하면 이력이 직선으로 이어져, 커밋 로그가 매우 깔끔해집니다.\n장점: 히스토리가 간결하고, 직선으로 정렬되어 있어, 로그를 읽기가 쉽습니다. 병합 커밋이 생기지 않기 때문에, 협업 중에도 깔끔한 이력을 유지할 수 있습니다.\n단점: Rebase는 히스토리를 재작성하는 방식이므로, 이미 공유된 커밋을 rebase하게 되면 협업 중 충돌이 발생하거나 다른 개발자들의 커밋에 영향을 줄 수 있습니다. 협업 중에는 신중하게 사용해야 하며, 특히 다수의 개발자가 동시에 작업하는 브랜치에서는 rebase가 문제가 될 수 있습니다.\n3. Only ever fast-forward Only ever fast-forward 옵션은 강력한 제약 조건을 설정하여, 항상 fast-forward 병합만 허용하는 방식입니다. 이 옵션을 선택하면 Git은 병합 커밋을 생성하지 않고, fast-forward가 가능한 경우에만 병합을 수행합니다.\n동작 방식: 로컬 브랜치가 원격 브랜치보다 앞서거나 충돌이 발생할 경우, 병합을 허용하지 않고 에러를 발생시킵니다. 즉, 단순히 브랜치가 원격 브랜치보다 뒤에 있을 때만 fast-forward 병합이 가능합니다.\n장점: 이력을 절대적으로 깔끔하게 유지할 수 있습니다. 병합 커밋이 생기지 않기 때문에, 히스토리가 매우 간결하게 유지됩니다. 히스토리를 관리하기가 쉬우며, 직선형으로 깔끔하게 이어지는 커밋 로그를 선호하는 경우 적합합니다.\n단점: 협업 중에 다른 개발자의 변경 사항과 로컬 변경 사항이 병합되어야 하는 경우에도 fast-forward만 허용하므로, Git이 병합을 거부할 수 있습니다. 이런 경우, 병합이 실패하고 수동으로 병합을 수행해야 할 수도 있습니다. 복잡한 협업 상황에서는 제약이 될 수 있습니다. 협업 중에는 병합 커밋이 필요할 수 있기 때문에, 이 옵션은 다소 제한적입니다.\n\n\n\n\n\n\n그림 10: Options to select git pull\n\n\n\n\n\nGit Credential Manager\nGit Credential Manager는 Git에서 원격 저장소에 대한 인증 정보를 안전하게 저장하고 자동으로 관리해주는 도구입니다. 이를 통해 사용자는 자격 증명을 반복적으로 입력할 필요 없이 안전하게 Git을 사용할 수 있으며, Windows, macOS, Linux 등 다양한 운영체제에서 지원됩니다. OAuth, 토큰 기반 인증 등 최신 인증 방식도 지원하여 보안성과 편리성을 모두 제공합니다. Git Credential Manager는 Git 설치 시 선택적으로 설치할 수 있으며, 기본값을 사용하는 것이 권장됩니다 그림 11.\n\n\n\n\n\n\n그림 11: Options to select Git Credential Manager\n\n\n\n\n\n기타 옵션\nFile System Caching은 Git이 파일 시스템에 대한 메타데이터(파일 상태, 권한, 타임스탬프 등)를 더 빠르게 조회할 수 있도록 캐시를 사용하는 기능입니다. 기본적으로, Git은 파일 시스템에서 파일 변경 사항을 확인하기 위해 파일의 상태(예: 수정 시간, 크기)를 체크합니다. 이 과정이 많은 파일을 포함하는 대형 프로젝트에서는 성능 저하를 일으킬 수 있습니다. Symbolic Links(심볼릭 링크)는 파일이나 디렉토리에 대한 참조를 가리키는 특별한 유형의 파일입니다. 심볼릭 링크는 원래 파일 또는 디렉토리의 경로를 저장하고, 이를 참조하는 방식으로 동작합니다. Git에서 Symbolic Links 옵션을 활성화하면, Git은 심볼릭 링크를 파일로 저장하는 대신, 심볼릭 링크 자체를 저장하고 관리할 수 있습니다. 리눅스 및 macOS에서 심볼릭 링크는 많이 사용되고 지원되므로, 이 옵션을 활성화하는 것이 일반적입니다. Windows에서는 심볼릭 링크가 기본적으로 제한되어 있으며, 활성화하려면 관리자 권한이나 특정 설정을 필요로 합니다. 따라서, Windows에서 이 옵션을 활성화하면 제대로 동작하지 않거나 예기치 않은 동작이 발생할 수 있습니다. 기본값은 File System Caching 활성화입니다 그림 12.\n\n\n\n\n\n\n그림 12: Options to select Extra Options",
    "crumbs": [
      "Utilities",
      "Git & Github setup"
    ]
  },
  {
    "objectID": "posts/Git-setup/Git_setup.html#설치확인",
    "href": "posts/Git-setup/Git_setup.html#설치확인",
    "title": "Git & Github setup",
    "section": "설치확인",
    "text": "설치확인\n커맨드창에서 아래의 명령을 실행하여 버전을 확인하시면 됩니다. (Git 설치 시 실행파일의 경로가 환경변수에 자동으로 등록되기 때문에 커맨드창을 여는 폴더위치가 관계 없이 버전이 표시되어야 합니다.)\n\n\n\nCommand Prompt\n\ngit --version",
    "crumbs": [
      "Utilities",
      "Git & Github setup"
    ]
  },
  {
    "objectID": "posts/Git-setup/Git_setup.html#git개념과-용어",
    "href": "posts/Git-setup/Git_setup.html#git개념과-용어",
    "title": "Git & Github setup",
    "section": "Git개념과 용어",
    "text": "Git개념과 용어\nGit 초기 설정에 앞서 Git에서 사용되는 개념과 용어를 이해하는 것이 좋습니다. Git 공식사이트의 한글매뉴얼(https://git-scm.com/book/ko/v2/%ec%8b%9c%ec%9e%91%ed%95%98%ea%b8%b0-Git-%ea%b8%b0%ec%b4%88)을 학습하시길 추천합니다. ### untracked/staged/committed Git에서는 프로젝트폴더 내의 모든 파일을 추적(=관리)대상파일과 추적대상이 아닌 파일로 구분합니다. 추적대상파일은 인 파일로 그림 13.\n\n\n\n\n\n\n그림 13: Concept of Git and terminology",
    "crumbs": [
      "Utilities",
      "Git & Github setup"
    ]
  },
  {
    "objectID": "posts/Git-setup/Git_setup.html#git-설정",
    "href": "posts/Git-setup/Git_setup.html#git-설정",
    "title": "Git & Github setup",
    "section": "Git 설정",
    "text": "Git 설정\n\n사용자정보 설정\nGit에서는 커밋을 할 때마다 누가 했는지를 사용자명과 이메일을 기록해둡니다. 이를 위해 설치 시 아래의 예시와 같이 사용자이름과 이메일 설정합니다.\n\n\n\nCommand Prompt\n\ngit config --global user.name \"BenKorea\"\n\n\n\n\n\nCommand Prompt\n\ngit config --global user.email \"kimbi.kirams@gmail.com\"\n\n\n\n\n사용자정보 설정 확인\n각각 아래의 명령으로 사용자명과 이메일 주소를 확인할 수 있습니다.\n\n\n\nCommand Prompt\n\ngit config user.name\n\n\n\n\n\nCommand Prompt\n\ngit config user.email\n\n\n\n\n기본브렌치 설정하기\n기본 브렌치 이름을 master가 아닌 main으로 설정할려면 아래의 같이 init.defautBranch를 main을 설정해 주시면 됩니다.\n\n\n\nCommand Prompt\n\ngit config --global init.defaultBranch main",
    "crumbs": [
      "Utilities",
      "Git & Github setup"
    ]
  },
  {
    "objectID": "posts/Git-setup/Git_setup.html#프로젝트에-git-적용하기",
    "href": "posts/Git-setup/Git_setup.html#프로젝트에-git-적용하기",
    "title": "Git & Github setup",
    "section": "프로젝트에 Git 적용하기",
    "text": "프로젝트에 Git 적용하기\n버전관리를 시작할려면 원하는 폴더 (=프로젝트 폴더)에서 git init 명령어를 실행하면 됩니다. 다른 표현으로는 저장소를 만든다고도 합니다. 실행결과로써 .git 이라는 숨김폴더가 생성되며, 이 폴더에는 버전관리에 필요한 파일들이 저장됩니다.\n\n\n\nCommand Prompt\n\ngit init",
    "crumbs": [
      "Utilities",
      "Git & Github setup"
    ]
  },
  {
    "objectID": "posts/Git-setup/Git_setup.html#github란",
    "href": "posts/Git-setup/Git_setup.html#github란",
    "title": "Git & Github setup",
    "section": "Github란?",
    "text": "Github란?\nGitHub는 Git을 기반으로 한 웹 기반 호스팅 서비스로, 소스 코드 관리와 협업을 위한 플랫폼입니다. GitHub는 Git을 사용하여 프로젝트의 코드베이스를 중앙에서 관리하며, 개발자들이 효율적으로 코드 리뷰, 이슈 관리, 프로젝트 관리, 그리고 협업을 할 수 있도록 다양한 도구와 인터페이스를 제공합니다. Pull Request(PR)를 통해 코드 변경 사항을 리뷰하고 병합할 수 있으며, Continuous Integration/Continuous Deployment(CI/CD)와 같은 자동화 기능을 지원해 소프트웨어 개발의 생산성과 품질을 높입니다.",
    "crumbs": [
      "Utilities",
      "Git & Github setup"
    ]
  },
  {
    "objectID": "posts/manuscript-example/manuscript_example.html",
    "href": "posts/manuscript-example/manuscript_example.html",
    "title": "Manuscripting with Quarto Example",
    "section": "",
    "text": "RStudio를 실행하고 파일메뉴에서 New Project… &gt; New Directory &gt; New Project를 단계적으로 선택하고\nC:\\R\\Projects (=Default working directory) 하위에 Directory name 입력란에는 아래의 예시와 같이 R의 버전과 프로젝트를 상징하는 이름을 조합하여 입력할 것을 추천합니다.\n\n\n\n예시\n\nR-4.4.1-RPythonStudy_HANJM\n\n\ngit repository(=저장소) 만들기와 renv 사용하기 check box는 예제 R프로젝트를 다운로드 하기 위해서는 선택해야 합니다.\n\n이제 탐색기로 프로젝트 폴더(C:.1-RPythonStudy_HANJM)를 살펴보면 .git 폴더, .Rproj.user 폴더, renv 폴더, .gitignore 파일, .Rprofile 파일, R-4.4.1-RPythonStudy-HANJM.Rproj 파일, renv.lock 파일들이 생성되었음을 확인하실 수 있습니다.\n\ngit를 사용하기 때문에 설정이 보관되는 .git 폴더와 버전관리 예외(규칙)이 기록되어 있는 .gitignore 파일이 생성되어 있습니다. renv를 사용하기 때문에 프로젝트에 패키지가 설치되는 renv 폴더가 생성되었고 설치되는 패키지의 대한 기록이 되는 renv.lock 파일 생성되어 있습니다. RStudio에서 프로젝트로 이 폴더를 사용하기 때문에 .Rproj.user 폴더, .Rprofile 파일, R-4.4.1-RPythonStudy_HANJM.Rproj 파일이 생성되어 있습니다.\n\n\n\n이 과정을 위해서는 당연히 git가 미리 설치되어 있어야 합니다. 설치 되어 있는지 확인은 Console 창의 Terminal tab에서 “git –version”을 실행하여 버전이 출력되면 적절히 설치가 되어 있는 것입니다 (Window 기준).\n\n\n\nTerminal\n\ngit --version\n\n\n아래는 github 원격저장소에 있는 생존분석데이터를 이용한 샘플용 R프로젝트를 나의 R 프로젝트 폴더에 다운로드 받는 방법입니다.\n먼저 현재의git 프로젝트에 github 원격저장소의 URL을 등록해야 합니다. Git 명령을 입력하기 위해 아래의 그림의 console pane의 Terminal 탭으로 이동하여 git remote add 명령을 실행합니다.\n\n\n\n\nTerminal\n\ngit remote add origin https://github.com/RPythonStudy/HANJM.git\n\n\n그리고 원격저장소가 적절히 등록되었는지는 아래의 명령으로 확인하시면 됩니다.\n\n\n\nTerminal\n\ngit remote -v\n\n\n만약 이미 등록되어 있는데 다시 등록한다면 “error: remote origin already exists.”라는 메세지가 나올 것입니다.\n😅 그리고 다운로드 준비를 해야 하는데 git pull 명령으로 원격저장소의 모든 파일을 다운로드 할 예정인데 로컬 폴더에 중복되는 파일이 하나라도 있으면 오류가 발생하므로, 중복이 되는 파일인 .gitignore, .Rprofile과 renv.lock 을 로컬 프로젝트폴더에서 삭제해 줍니다.\n이후 아래의 git 명령으로 원격저장소의 모든 파일을 다운로드 받아 주면 됩니다.\n\n\n\nTerminal\n\ngit pull origin master\n\n\n(중복이 있더라도 원격저장소으 파일로 강제로 덮어쓰는 명령이 있지만 제가 시도할 때는 오류 메세지가 같이 나오기 때문에 일단 여기에는 소개하지 않습니다.)\n\n필자주: 이전에 다운로드 받은 적이 있고, 원격저장소의 파일이 갱신되어 있어 로컬저장소를 갱신하고자할 때로 위의 pull 명령을 사용하시면 됩니다. 이전 다운로드 이후에 로컬에서 수정한 적이 없으면 잘 다운로드 됩니다. 이후에는 renv::store() 명령으로 원격저장소의 renv.lock파일에 기록된 패키지들이 로컬과 차이가 있는지 점검하는 것이 좋습니다. 만약 로컬에서 파일을 수정하였기 때문에 로컬과 원격의 충돌이 발생한다면 아래의 명령을 시도해 봅니다. 이 경우 로컬의 파일들이 지워지고 자동으로 백업이 되지는 않기 때문에 필요시에는 백업을 미리 해 두셔야 합니다. 이렇게 해도 문제가 있다면 프로젝트 폴더를 삭제하고 처음부터 과정을 다시 진행하시길 바랍니다.\n\n\n\n\nTerminal\n\ngit fetch origin\ngit reset --hard origin/master\n\n\n\n\n\n원격저장소에는 예제 R프로젝트 파일은 있지만 이를 위해 필요한 R 패키지까지 같이 있지는 않습니다. 하지만 renv.lock 파일에는 설치된 패키지 버전과 목록이 기록되어 있으므로 이를 이용해서 설치하시면 됩니다.\nConsole pane의 Consle 탭으로 이동해서 renv::restore() 명령을 실행하시면 됩니다.\n\n\n\nConsole\n\nrenv::restore ()\n\n\n만약 이전에 renv::restore()를 수행하여 패키지가 이미 update된 상태에서 다시 위 명령을 수행한다면 “- The library is already synchronized with the lockfile.”이라는 메세지가 출력할 것이며 이미 update된 것 상태이므로 다음 단계를 진행하시면 됩니다.\n\n\n\n예제 R로 논문쓰기 프로젝트를 실행할 때 raw data로써 “deidentified_han20230213.xlsx”이 필요합니다. 이 파일은 이미 개인정보보호조치(개인정보익명화, 날짜정보를 날짜간의 차이정보로 변환)가 되어 있지만 연구회의 방침상 업로드는 되어 있지는 않습니다. 내부연구자 분들이 실습을 위해 위 파일이 필요한 경우에는 연구회에 연락 바랍니다. 이 파일을 프로젝트 폴더 하부의 raw_data 폴더를 만들고 위 xlsx 파일을 복사해 주시면 됩니다.\n\n\n\n예제 R로 논문쓰기 프로젝트가 로컬에서 준비가 완료되었습니다. 원하는 기능들이 R청크에서 어떻게 구현되었는지 확인하시고 코드줄, 블록 또는 청크단위로 실행하시면서 구현결과를 확인하시면 됩니다.",
    "crumbs": [
      "Quarto",
      "Manuscripting with Quarto Example"
    ]
  },
  {
    "objectID": "posts/manuscript-example/manuscript_example.html#빈-프로젝트-만들기",
    "href": "posts/manuscript-example/manuscript_example.html#빈-프로젝트-만들기",
    "title": "Manuscripting with Quarto Example",
    "section": "",
    "text": "RStudio를 실행하고 파일메뉴에서 New Project… &gt; New Directory &gt; New Project를 단계적으로 선택하고\nC:\\R\\Projects (=Default working directory) 하위에 Directory name 입력란에는 아래의 예시와 같이 R의 버전과 프로젝트를 상징하는 이름을 조합하여 입력할 것을 추천합니다.\n\n\n\n예시\n\nR-4.4.1-RPythonStudy_HANJM\n\n\ngit repository(=저장소) 만들기와 renv 사용하기 check box는 예제 R프로젝트를 다운로드 하기 위해서는 선택해야 합니다.\n\n이제 탐색기로 프로젝트 폴더(C:.1-RPythonStudy_HANJM)를 살펴보면 .git 폴더, .Rproj.user 폴더, renv 폴더, .gitignore 파일, .Rprofile 파일, R-4.4.1-RPythonStudy-HANJM.Rproj 파일, renv.lock 파일들이 생성되었음을 확인하실 수 있습니다.\n\ngit를 사용하기 때문에 설정이 보관되는 .git 폴더와 버전관리 예외(규칙)이 기록되어 있는 .gitignore 파일이 생성되어 있습니다. renv를 사용하기 때문에 프로젝트에 패키지가 설치되는 renv 폴더가 생성되었고 설치되는 패키지의 대한 기록이 되는 renv.lock 파일 생성되어 있습니다. RStudio에서 프로젝트로 이 폴더를 사용하기 때문에 .Rproj.user 폴더, .Rprofile 파일, R-4.4.1-RPythonStudy_HANJM.Rproj 파일이 생성되어 있습니다.",
    "crumbs": [
      "Quarto",
      "Manuscripting with Quarto Example"
    ]
  },
  {
    "objectID": "posts/manuscript-example/manuscript_example.html#github로부터-다운로드",
    "href": "posts/manuscript-example/manuscript_example.html#github로부터-다운로드",
    "title": "Manuscripting with Quarto Example",
    "section": "",
    "text": "이 과정을 위해서는 당연히 git가 미리 설치되어 있어야 합니다. 설치 되어 있는지 확인은 Console 창의 Terminal tab에서 “git –version”을 실행하여 버전이 출력되면 적절히 설치가 되어 있는 것입니다 (Window 기준).\n\n\n\nTerminal\n\ngit --version\n\n\n아래는 github 원격저장소에 있는 생존분석데이터를 이용한 샘플용 R프로젝트를 나의 R 프로젝트 폴더에 다운로드 받는 방법입니다.\n먼저 현재의git 프로젝트에 github 원격저장소의 URL을 등록해야 합니다. Git 명령을 입력하기 위해 아래의 그림의 console pane의 Terminal 탭으로 이동하여 git remote add 명령을 실행합니다.\n\n\n\n\nTerminal\n\ngit remote add origin https://github.com/RPythonStudy/HANJM.git\n\n\n그리고 원격저장소가 적절히 등록되었는지는 아래의 명령으로 확인하시면 됩니다.\n\n\n\nTerminal\n\ngit remote -v\n\n\n만약 이미 등록되어 있는데 다시 등록한다면 “error: remote origin already exists.”라는 메세지가 나올 것입니다.\n😅 그리고 다운로드 준비를 해야 하는데 git pull 명령으로 원격저장소의 모든 파일을 다운로드 할 예정인데 로컬 폴더에 중복되는 파일이 하나라도 있으면 오류가 발생하므로, 중복이 되는 파일인 .gitignore, .Rprofile과 renv.lock 을 로컬 프로젝트폴더에서 삭제해 줍니다.\n이후 아래의 git 명령으로 원격저장소의 모든 파일을 다운로드 받아 주면 됩니다.\n\n\n\nTerminal\n\ngit pull origin master\n\n\n(중복이 있더라도 원격저장소으 파일로 강제로 덮어쓰는 명령이 있지만 제가 시도할 때는 오류 메세지가 같이 나오기 때문에 일단 여기에는 소개하지 않습니다.)\n\n필자주: 이전에 다운로드 받은 적이 있고, 원격저장소의 파일이 갱신되어 있어 로컬저장소를 갱신하고자할 때로 위의 pull 명령을 사용하시면 됩니다. 이전 다운로드 이후에 로컬에서 수정한 적이 없으면 잘 다운로드 됩니다. 이후에는 renv::store() 명령으로 원격저장소의 renv.lock파일에 기록된 패키지들이 로컬과 차이가 있는지 점검하는 것이 좋습니다. 만약 로컬에서 파일을 수정하였기 때문에 로컬과 원격의 충돌이 발생한다면 아래의 명령을 시도해 봅니다. 이 경우 로컬의 파일들이 지워지고 자동으로 백업이 되지는 않기 때문에 필요시에는 백업을 미리 해 두셔야 합니다. 이렇게 해도 문제가 있다면 프로젝트 폴더를 삭제하고 처음부터 과정을 다시 진행하시길 바랍니다.\n\n\n\n\nTerminal\n\ngit fetch origin\ngit reset --hard origin/master",
    "crumbs": [
      "Quarto",
      "Manuscripting with Quarto Example"
    ]
  },
  {
    "objectID": "posts/manuscript-example/manuscript_example.html#r-package-설치하기",
    "href": "posts/manuscript-example/manuscript_example.html#r-package-설치하기",
    "title": "Manuscripting with Quarto Example",
    "section": "",
    "text": "원격저장소에는 예제 R프로젝트 파일은 있지만 이를 위해 필요한 R 패키지까지 같이 있지는 않습니다. 하지만 renv.lock 파일에는 설치된 패키지 버전과 목록이 기록되어 있으므로 이를 이용해서 설치하시면 됩니다.\nConsole pane의 Consle 탭으로 이동해서 renv::restore() 명령을 실행하시면 됩니다.\n\n\n\nConsole\n\nrenv::restore ()\n\n\n만약 이전에 renv::restore()를 수행하여 패키지가 이미 update된 상태에서 다시 위 명령을 수행한다면 “- The library is already synchronized with the lockfile.”이라는 메세지가 출력할 것이며 이미 update된 것 상태이므로 다음 단계를 진행하시면 됩니다.",
    "crumbs": [
      "Quarto",
      "Manuscripting with Quarto Example"
    ]
  },
  {
    "objectID": "posts/manuscript-example/manuscript_example.html#raw_data-붙여넣기",
    "href": "posts/manuscript-example/manuscript_example.html#raw_data-붙여넣기",
    "title": "Manuscripting with Quarto Example",
    "section": "",
    "text": "예제 R로 논문쓰기 프로젝트를 실행할 때 raw data로써 “deidentified_han20230213.xlsx”이 필요합니다. 이 파일은 이미 개인정보보호조치(개인정보익명화, 날짜정보를 날짜간의 차이정보로 변환)가 되어 있지만 연구회의 방침상 업로드는 되어 있지는 않습니다. 내부연구자 분들이 실습을 위해 위 파일이 필요한 경우에는 연구회에 연락 바랍니다. 이 파일을 프로젝트 폴더 하부의 raw_data 폴더를 만들고 위 xlsx 파일을 복사해 주시면 됩니다.",
    "crumbs": [
      "Quarto",
      "Manuscripting with Quarto Example"
    ]
  },
  {
    "objectID": "posts/manuscript-example/manuscript_example.html#완료",
    "href": "posts/manuscript-example/manuscript_example.html#완료",
    "title": "Manuscripting with Quarto Example",
    "section": "",
    "text": "예제 R로 논문쓰기 프로젝트가 로컬에서 준비가 완료되었습니다. 원하는 기능들이 R청크에서 어떻게 구현되었는지 확인하시고 코드줄, 블록 또는 청크단위로 실행하시면서 구현결과를 확인하시면 됩니다.",
    "crumbs": [
      "Quarto",
      "Manuscripting with Quarto Example"
    ]
  },
  {
    "objectID": "posts/manuscript-example/manuscript_example.html#yaml-문법",
    "href": "posts/manuscript-example/manuscript_example.html#yaml-문법",
    "title": "Manuscripting with Quarto Example",
    "section": "YAML 문법",
    "text": "YAML 문법\nYAML 헤더는 quarto 문법 중 Front Matter (https://quarto.org/docs/authoring/front-matter.html)를 참고하면 YAML 문법에 맞게 작성할 수 있습니다.",
    "crumbs": [
      "Quarto",
      "Manuscripting with Quarto Example"
    ]
  },
  {
    "objectID": "posts/manuscript-example/manuscript_example.html#r-청크-옵션",
    "href": "posts/manuscript-example/manuscript_example.html#r-청크-옵션",
    "title": "Manuscripting with Quarto Example",
    "section": "R 청크 옵션",
    "text": "R 청크 옵션\nR코드청크(=code cell) 는 그 자체는 일반적인 R 스크립트와 같이 작성하면 되지만 청크의 실행과 출력결과를 조절하기 위한 옵션들(https://quarto.org/docs/reference/cells/cells-knitr.html)이 있습니다. R코드청크 내부에 #| 이후에 옵션을 설정하게 되며 아래에 예제 R프로젝트에 사용된 예시들이 있습니다.\n```{{r}}\n#| label: Load-raw-data #제목을 설정, \"_\"는 오류가 가능하다 하니 \"-\"로 단어 연결 추천\n#| label: fig-myplot #그래프의 라벨을 설정 \"fig-\" 시작해야 만 함\n#| label: tbl-mytable #테이블의 라벨을 설정 \"tbl-\" 시작해야 만 함\n#| output: false # 텍스트형태의 결과물이 문서에 포함되지 않음\n#| fig.show: 'hide'# 그래프형태의 결과물이 문서에 포함되지 않음\n#| fig.height: 6 \n#| fig.width: 6\n#| eval: false # 코드가 실행되지 않음\n```",
    "crumbs": [
      "Quarto",
      "Manuscripting with Quarto Example"
    ]
  },
  {
    "objectID": "posts/manuscript-example/manuscript_example.html#quarto-문법",
    "href": "posts/manuscript-example/manuscript_example.html#quarto-문법",
    "title": "Manuscripting with Quarto Example",
    "section": "Quarto 문법",
    "text": "Quarto 문법\nQuarto markdown 문법은 R Markdown과 비슷하지만 더 많은 기능을 제공합니다. Quarto markdown 문법은 https://quarto.org/docs/authoring/markdown-basics.html를 참고하면 됩니다. Quarto는 Visual Editor 모드를 지원하여, WYSIWYG(What You See Is What You Get) 방식으로 문서를 작성할 수 있습니다. Visual Mode를 사용하면, 코드 블록 삽입, 이미지 추가, 테이블 생성 등을 GUI를 통해 쉽게 할 수 있습니다.",
    "crumbs": [
      "Quarto",
      "Manuscripting with Quarto Example"
    ]
  },
  {
    "objectID": "posts/manuscript-example/manuscript_example.html#manuscript-프로젝트-폴더",
    "href": "posts/manuscript-example/manuscript_example.html#manuscript-프로젝트-폴더",
    "title": "Manuscripting with Quarto Example",
    "section": "manuscript 프로젝트 폴더",
    "text": "manuscript 프로젝트 폴더\nQuarto로 새로운 프로젝트를 만들 때 R로 논문쓰기에 적합한 manuscripit 프로젝트가 있으며 예제 R 프로젝트도 manuscript 프로젝트를 이용해 만들어졌습니다. 일반적인 폴더와 파일구성은 다음과 같은 구조를 가질 수 있습니다.\nProject/\n         ├─  _freeze/\n         ├─  _manuscript/\n         ├─  _quarto.yml\n         ├─  .gitignore\n         ├─  .Rhistory\n         ├─  .Rprofile\n         ├─  index.qmd\n         ├─  R-4.4.1-RPythonStudy_HANJM.Rproj\n         ├─  references.bib\n         ├─  renv/\n         └─  renv.lock\n\n\n_freeze 폴더\nQuarto는 청크 단위의 실행 결과를 캐싱할 수 있습니다. YAML 헤더의 execute.freeze 옵션을 auto 또는 true로 설정하면 캐싱을 위해 _freeze 폴더가 생성됩니다.\n\n\n_manuscript 폴더\nQuarto manuscript 프로젝트에서는 기본적으로 렌더링 결과를 _manuscript 폴더에 만듭니다. 출력 결과를 다른 폴더로 변경하고자 할 때에는 YAML 헤더에서 output-dir: 원하는 폴더명으로 수정하시면 됩니다.\n\n\n_quarto.yml 파일\n_quarto.yml 파일은 Quarto 프로젝트의 설정을 관리하는 구성 파일입니다. 이 파일을 통해 프로젝트의 전반적인 설정, 문서 렌더링 옵션, 그리고 특정 문서의 형식과 출력을 제어할 수 있습니다.\n아래는 예제 R 프로젝트에 사용된 _quarto.yml 의 부분입니다.\n\n\n\nexample of _quarto.yml\n\nproject:\n  type: manuscript\n\nmanuscript:\n  article: index.qmd\n\nformat:\n  html:\n    comments: \n      hypothesis: true \n#  docx: default \n#  jats: default\n\nexecute:\n  freeze: true\n\neditor: visual\n\n\nQuarto 프로젝트 설정은 문서 또는 기사 작성에 주로 사용되며, ‘manuscript’으로 유형이 지정되어 있습니다. 이 설정은 프로젝트의 메인 문서 파일로 ’index.qmd’를 지정하고 있습니다. ’index.qmd’ 파일은 Quarto Markdown 형식으로, 프로젝트의 핵심 내용을 포함하고 있습니다.\n문서의 출력 형식으로 HTML이 지정되어 있어, 생성된 문서가 웹 페이지 형태로 렌더링되어 표시될 것입니다. 이 HTML 출력 설정에는 댓글 기능이 포함되어 있으며, Hypothesis라는 오픈 소스 주석 도구가 활성화되어 있습니다. Hypothesis 도구를 통해 사용자는 웹 페이지에 직접 주석을 추가할 수 있습니다, 이는 인터랙티브한 문서 환경을 조성합니다.\n‘freeze: false’ 설정은 문서 빌드 시 실행 코드의 결과를 캐싱하지 않겠다는 것을 의미합니다. 즉, 이 설정은 문서가 빌드될 때마다 관련 코드가 매번 실행되어 결과가 갱신되도록 합니다.\n추가적으로, ‘docx’와 ’jats’ 형식은 현재 비활성화된 상태로 주석 처리되어 있습니다. 이는 렌더링 시간을 단축하기 위한 조치로, 비활성화된 상태에서는 이 포맷들이 문서 출력 형식으로 사용되지 않습니다.\n마지막으로, ‘editor: visual’ 설정은 Quarto 문서 작성 시 사용되는 에디터 유형을 명시합니다. Visual editor는 사용자가 마크다운 문법을 몰라도 문서를 작성할 수 있도록 지원하는 사용자 친화적인 인터페이스를 제공합니다. 이는 문서 작성 과정을 보다 직관적이고 접근하기 쉽게 만듭니다.\n이러한 설정들은 효과적인 문서 작성과 관리를 가능하게 하며, 사용자에게 다양한 도구와 옵션을 제공하여 유연한 작업 환경을 조성합니다.\n\n\n.gitignore 파일\n.gitignore 파일은 Git 버전 관리 시스템에서 특정 파일이나 디렉토리를 추적하지 않도록 설정하는 데 사용됩니다. 이 파일은 프로젝트 디렉토리 내에 위치하며, Git이 파일을 무시하도록 지시하는 패턴 목록을 포함하고 있습니다.\n\n\n.Rhistory 파일\n.Rhistory 파일은 R 프로그래밍 환경에서 사용자가 실행한 모든 명령어의 이력을 저장하는 파일입니다. 이 파일은 R 콘솔에서 직접 입력하거나 스크립트를 실행하는 동안의 사용자의 명령어들을 자동으로 기록합니다. 이 기능은 사용자가 이전 세션에서 수행한 작업을 추적하고, 필요한 경우 명령어를 재사용하거나 참조할 수 있게 해 줍니다.\n\n\n.Rprofile 파일\n.Rprofile 파일은 R 세션의 시작 시 자동으로 실행되는 스크립트를 포함하는 설정 파일입니다. 이 파일은 사용자 또는 특정 프로젝트에 대한 환경 설정을 사용자 정의하고, R 세션을 시작할 때마다 일관된 작업 환경을 구성하는 데 사용됩니다. .Rprofile은 R의 시작 시 자동으로 로드되므로, R을 사용하는 데 필요한 라이브러리 로딩, 옵션 설정, 환경 설정 등을 자동화할 수 있습니다. 예제 R프로젝트에서는 renv 환경이 활성화되도록 설정되어 있습니다.\n\n\nIndex.qmd 파일\nindex.qmd 파일은 Quarto 문서 프로젝트에서 중요한 역할을 하는 메인 문서 파일입니다. .qmd 확장자는 Quarto Markdown을 의미하며, 이 파일 형식은 Markdown의 확장 버전으로, Quarto에서 제공하는 다양한 기능을 지원합니다.\n\n\n*.Rproj 파일\n.Rproj 파일은 RStudio의 프로젝트 파일로, 특정 R 프로젝트와 관련된 설정과 환경을 저장합니다. 이 파일은 RStudio 환경에서 프로젝트를 더 효율적으로 관리할 수 있게 해 주며, 프로젝트별로 별도의 작업 공간과 설정을 유지할 수 있도록 도와줍니다.\n\n\nreferences.bib 파일\nreferences.bib 파일은 레퍼런스 관리와 문헌 인용을 위한 BibTeX 파일입니다. 이 파일은 주로 LaTeX 문서나 다양한 텍스트 편집 소프트웨어와 통합하여 사용되며, 학술적 작업, 연구 보고서, 논문 등에서 출처를 인용하고 관리하는 데 필요한 정보를 포함합니다.\n\n\nrenv 폴더\nrenv 폴더는 R 프로젝트에서 프로젝트별 종속성 관리를 위해 사용되는 renv 패키지에 의해 생성되는 디렉토리입니다. 이 폴더는 프로젝트의 라이브러리를 격리시켜 다른 프로젝트나 시스템의 R 패키지 설치와 독립적으로 유지할 수 있도록 도와줍니다. renv는 R의 프로젝트에 대한 복원 가능하고 재현 가능한 환경을 제공하는 데 중점을 두고 있습니다.\n\n\nrenv.lock 파일\nrenv.lock 파일은 R 프로젝트에서 renv 패키지를 사용할 때 생성되는 중요한 파일로, 프로젝트의 종속성(의존하는 R 패키지들)을 정확하고 재현 가능하게 기록합니다. 이 파일은 프로젝트에 필요한 모든 R 패키지의 버전과 소스 정보를 포함하여 프로젝트 환경을 재현할 수 있도록 돕습니다.",
    "crumbs": [
      "Quarto",
      "Manuscripting with Quarto Example"
    ]
  },
  {
    "objectID": "posts/manuscript-example/manuscript_example.html#quarto-렌더링",
    "href": "posts/manuscript-example/manuscript_example.html#quarto-렌더링",
    "title": "Manuscripting with Quarto Example",
    "section": "Quarto 렌더링",
    "text": "Quarto 렌더링\nQuarto 문서 렌더링은 .qmd 파일(Quarto Markdown 파일)을 다양한 출력 형식으로 변환하는 복잡한 과정을 포함합니다. 이 과정은 데이터 분석, 코드 실행, 결과의 시각화를 포함한 종합적인 문서 생성을 목표로 하며, 주로 Quarto의 명령줄 인터페이스(Command Line Interface, CLI)를 통해 실행됩니다. 예를 들어, quarto render mydocument.qmd 명령은 mydocument.qmd 파일을 지정된 형식으로 변환합니다. 이 CLI 명령은 RStudio의 콘솔 창 아래에 있는 터미널에서 실행할 수 있습니다. 추가적으로, RStudio에서는 ‘Render’ 버튼을 사용하여 문서의 미리보기가 가능합니다. 이 버튼은 RStudio 환경 내에서 Quarto 문서를 쉽게 렌더링하고 결과를 실시간으로 확인할 수 있는 사용자 친화적인 방법을 제공합니다. 이를 통해 사용자는 문서의 최종 형태를 확인하고 필요에 따라 수정할 수 있습니다.",
    "crumbs": [
      "Quarto",
      "Manuscripting with Quarto Example"
    ]
  },
  {
    "objectID": "posts/manuscript-example/manuscript_example.html#그림-삽입",
    "href": "posts/manuscript-example/manuscript_example.html#그림-삽입",
    "title": "Manuscripting with Quarto Example",
    "section": "그림 삽입",
    "text": "그림 삽입\nQuarto manual 중 해당부분(https://quarto.org/docs/manuscripts/authoring/rstudio.html)을 참고하시길 바라며, 간단히 요약하면 아래와 같습니다.\n그림(=그래프)의 생성은 manusctipt 앞부분에 위치한 R chunk의 흐름에 따라 생성되도록 하며, 삽입을 원하는 본문의 위치에 별도의 그래프용 chuck를 만드는 것을 추천합니다.\n아래는 예시입니다.\nPropensity score 를 구하기 위해 활용된 로지스틱 회귀분석에 적용된 변수는\n다음과 같습니다. 환자 factor 로서 성별, 연령, ASA score 등\nPrimary tumor factor 로서 tumor location, lymph node ratio 등\nMetastatic factor 로서 간엽 침범 정도, 전이 병변의 개수 등을 설정하였습니다. \n이에 따라 Propensity score 에 따른 allocation probability 의 AUC 는\n0.811, p-value 는 0.4906 로 나타났습니다 \n(@fig-AUC-allocation-probability-PSM).\n\n```{r} \n#| label: fig-AUC-allocation-probability-PSM \n#| fig.cap: Propensity score 에 따른 allocation probability 의 AUC \n#| fig.height: 6 \n#| fig.width: 6 \n\nROC(form=Adju_TA~pr.score, data=HAN_IPTW, plot = \"ROC\")}\n```\n렌더링하면 manuscrip에는 다음과 같이 보이게 됩니다. (화면을 캡쳐한 것이며 실제로는 HTML 문서입니다.)\n\n이때 chuck label은 fig-로 시작해야 cross-reference에서 인식됩니다.\n또한 chuck option을 통해서 caption, 크기 등을 설정할 수 있습니다.\n다음의 예시는 그래프 두 개를 나란히 하는 경우입니다.\n@fig-survival 은 연구에 포함된 환자 에 대한 Kaplan Meier 생존곡선입니다. 왼쪽은 metastases 에 대한 progression survival 을 나타내고 오른쪽은 overall survival 을 나타냅니다. f/u 기간의 중앙값은 45.5개월 이었으며, 관찰기간 중의 PFS event 는 85건, OS event 는 67건 이었습니다.\n\n```{r}\n#| label: fig-survival\n#| fig.cap: Kaplan Meier survival curves for patients with targeted therapy after surgical resection of colorectal liver metastasis\nlibrary(gridExtra)\n\ngrid.arrange(PFS$plot, OS_TA$plot, ncol=2)\n```\n결과는 아래와 같습니다.",
    "crumbs": [
      "Quarto",
      "Manuscripting with Quarto Example"
    ]
  },
  {
    "objectID": "posts/manuscript-example/manuscript_example.html#표-삽입",
    "href": "posts/manuscript-example/manuscript_example.html#표-삽입",
    "title": "Manuscripting with Quarto Example",
    "section": "표 삽입",
    "text": "표 삽입\n같은 방식으로 표를 삽입할 수 있습니다. 예시는 생략합니다. 다만 chuck label은 tbl-로 시작해야 cross-reference에서 인식됩니다. 그리고 table처럼 보이지만 HTML 테이블형식이 아닌 경우는 인식이 되지 않으므로 주의해야 합니다.",
    "crumbs": [
      "Quarto",
      "Manuscripting with Quarto Example"
    ]
  },
  {
    "objectID": "posts/manuscript-example/manuscript_example.html#참고문헌작성",
    "href": "posts/manuscript-example/manuscript_example.html#참고문헌작성",
    "title": "Manuscripting with Quarto Example",
    "section": "참고문헌작성",
    "text": "참고문헌작성\nQuarto에서 참고문헌을 작성하고 관리하는 방법은 매우 유연하며, 주로 .bib 파일과 함께 사용됩니다. Quarto는 LaTeX의 biblatex 스타일과 호환되며, 다양한 인용 스타일(Citation Style Language, CSL) 파일을 지원하여 특정 저널 형식에 맞춘 참고문헌을 생성할 수 있습니다.\n\n참고문헌 파일 준비 (.bib 파일)\n참고문헌을 관리하기 위해 먼저 .bib 파일을 준비합니다. 이 파일은 BibTeX 형식으로 작성되며, 모든 참고문헌 항목이 이 파일에 저장됩니다.\n\n\nQuarto 문서에 참고문헌 파일 포함\nQuarto 문서의 YAML 헤더에 참고문헌 파일을 지정합니다. 이를 통해 Quarto는 문서에서 인용된 항목을 자동으로 참조하고, 문서 끝에 참고문헌 목록을 생성합니다.\n\n\n본문에서 인용하기\n본문에서 참고문헌 항목을 인용할 때는 [@key] 형식을 사용합니다. 여기서 key는 .bib 파일에서 정의된 항목의 고유 키입니다.\n\n\n참고문헌 목록 생성\n문서의 끝에서 # References 섹션을 추가하면 Quarto는 인용된 항목을 자동으로 참고문헌 목록에 포함시킵니다.\n\n\nCitation Style (CSL) 사용\n특정 저널의 인용 스타일을 사용하려면 CSL 파일을 사용할 수 있습니다. 예를 들어, Nature 스타일을 사용하려면 nature.csl 파일을 다운로드하고, YAML 헤더에 추가합니다.\n예시는 annals of surgery의 citation style langue 을 https://www.zotero.org/styles로부터 다운로드 받아서 프로젝트 폴더에 위치시킨 후 설정한 것입니다.\n---\ntitle: Role of Targeted Therapy after Surgical Resection of Colorectal Liver Metastases\nauthor:\n  - name: Ui Sep Shin\n    orcid: 0000-0002-1714-7469\n    corresponding: true\n    roles: \n      - Formal Analysis\n      - Supervision\n    affiliations:\n      - name: KIRAMS\n        department: Department of General Surgery\n    email: uisupshin@kirams.re.kr\nbibliography: references.bib\ncsl: annals-of-surgery.csl\nnumber-sections: true\n---\n렌더링 후 결과는 아래와 같습니다.",
    "crumbs": [
      "Quarto",
      "Manuscripting with Quarto Example"
    ]
  },
  {
    "objectID": "posts/Python/introduction_to_Python.html",
    "href": "posts/Python/introduction_to_Python.html",
    "title": "Introduction to Python",
    "section": "",
    "text": "Python은 네덜란드 출신의 개발자 Guido van Rossum에 의해 개발되었습니다. 그는 CWI (Centrum Wiskunde & Informatica)에서 근무하며 교육용 프로그래밍 언어 ABC (A Basic Compiler)의 한계를 극복하기 위해 파이썬을 창안했습니다 [1].\nPython 0.9.0, 첫 release는 1991년에 발표되었으며, 클래스, 예외 처리(Exception Handling), 함수(Functionality) 등 현대 프로그래밍 언어의 핵심 기능을 포함했습니다. Python은 명료한 구문(Syntax)과 간결한 코드 작성을 목표로 설계되었으며, 확장성(Extensibility)을 갖춰 다양한 확장 모듈(Extension Modules)과 라이브러리(Libraries)를 쉽게 통합할 수 있습니다. 이러한 특성 덕분에, Python은 전 세계 개발자 커뮤니티에서 널리 수용되어 데이터 과학, 웹 개발, 자동화 스크립트, 기계 학습 등 다양한 기술 분야에서 선호되는 언어로 자리잡았습니다 [2].\n다음은 의학분야에서 Pathon의 몇 가지 활용 예시입니다:\n\n의료 이미지 분석: Python은 MRI, CT, X-ray 이미지 분석에 사용됩니다. 라이브러리인 PyDicom, OpenCV, TensorFlow, Keras를 통해 의료영상 분석에 활용되고 있습니다 [[3]][4][5].\n유전 데이터 분석: 생물정보학에서 Python은 유전자 서열 분석과 유전자 발현 데이터 처리에 활용됩니다. Biopython이 예시입니다 [6].\n임상 연구 데이터 관리: Python은 대규모 임상 연구 데이터의 관리 및 분석을 지원합니다. Pandas와 NumPy는 통계적 분석을 제공합니다 [[7]][8].\n예측 모델링과 기계 학습: Python은 환자 데이터를 활용한 질병 발병 예측 모델 개발에 사용됩니다. Scikit-learn 및 TensorFlow는 이러한 모델을 구축하는데 활용됩니다 [[3]][9].\n\n\n\n\n\n참고문헌\n\n1. Rossum G van. Foreword for \"Programming Python\" [Internet]. 1996. Retrieved (으)로부터: https://www.python.org/doc/essays/foreword/\n\n\n2. Wikipedia. History of Python [Internet]. 2024. Retrieved (으)로부터: https://en.wikipedia.org/wiki/History_of_Python\n\n\n3. Mason D. Pydicom: An Open Source DICOM Library. Medical Physics [Internet]. 2011년;38:3493–3. Retrieved (으)로부터: https://aapm.onlinelibrary.wiley.com/doi/abs/10.1118/1.3611983\n\n\n4. Abadi M, Agarwal A, Barham P, Brevdo E, Chen Z, Citro C, 기타. TensorFlow: Large-scale machine learning on heterogeneous systems. Mountain View, CA: Tensorflow; 2015.\n\n\n5. KERAS. Deep learning for humans [Internet]. 2024. Retrieved (으)로부터: https://keras.io/\n\n\n6. Cock PJ, Antao T, Chang JT, Chapman BA, Cox CJ, Dalke A, 기타. Biopython: freely available Python tools for computational molecular biology and bioinformatics. Bioinformatics. 2009년;25:1422.\n\n\n7. McKinney W, Team P. Pandas-Powerful python data analysis toolkit. Pandas—Powerful Python Data Analysis Toolkit. 2015년;1625.\n\n\n8. Numpy_team. NumPy: The fundamental package for scientific computing with Python [Internet]. 2024. Retrieved (으)로부터: https://numpy.org/\n\n\n9. Pedregosa F, Varoquaux G, Gramfort A, Michel V, Thirion B, Grisel O, 기타. Scikit-learn: Machine learning in Python. the Journal of machine Learning research. 2011년;12:2825–30.",
    "crumbs": [
      "Python",
      "Introduction to Python"
    ]
  },
  {
    "objectID": "posts/Quarto/introduction_to_Quarto.html",
    "href": "posts/Quarto/introduction_to_Quarto.html",
    "title": "Introduction to Quarto",
    "section": "",
    "text": "Quarto는 Posit (구 RStudio) 社에서 개발한 오픈소스 통합 출판 시스템으로, 2022년 4월 18일 공식 배포되었습니다. Quarto는 기존의 R Markdown과 차별화된 기능을 제공하며, R, Python 등 다양한 프로그래밍 언어의 실행 결과를 통합 문서에 포함시킬 수 있습니다. 이를 통해 MS Word, PDF, LaTeX 등의 다양한 형식으로 문서를 출력할 수 있을 뿐만 아니라, 반응형 동적 웹페이지와 같은 디지털 출판 플랫폼으로서도 강력한 기능을 제공합니다. Quarto는 특히 재현 가능한 연구 및 데이터 중심의 보고서 작성을 위한 현대적인 도구로서, 다중 언어 환경에서의 동적 문서화와 프로그래밍 워크플로우의 통합을 지원합니다.\n재현 가능한 연구(reproducible research)의 필요성\n의학 연구는 그 특성상 재현 가능한 연구가 필수적입니다. 재현 가능성은 다른 연구자들이 동일한 데이터를 기반으로 동일한 결과를 도출할 수 있도록 분석 과정과 데이터를 투명하게 제공하는 능력을 말합니다. Quarto는 R 및 Python과 같은 언어로 작성된 코드를 문서에 포함하고, 해당 문서를 렌더링할 때 코드가 자동으로 실행되어 분석 결과를 도출하게 합니다. 이를 통해 연구 결과와 분석 과정이 일관되게 유지되고 재현 가능합니다 .\n통합적 문서화 및 보고서 작성\nQuarto는 의학 논문, 보고서, 슬라이드 프레젠테이션, 블로그, 웹사이트 등을 손쉽게 생성할 수 있는 다목적 도구입니다. 이는 의사들이 분석 결과를 다양한 형식으로 배포하고 공유하는 데 있어 강력한 이점을 제공합니다. 특히 Quarto는 LaTeX, JATS, 그리고 Word 같은 다양한 출력 형식을 지원하므로, 의학 저널 투고 형식에 맞춘 문서도 손쉽게 생성할 수 있습니다 .\n데이터 시각화 및 프레젠테이션\n의료 데이터를 시각화하는 것은 복잡한 통계적 결과를 쉽게 이해하도록 돕는 중요한 과정입니다. Quarto는 고급 시각화 도구와의 호환성을 통해 고품질의 시각적 데이터를 제공하며, 특히 R의 ggplot2 패키지나 Python의 Matplotlib과 같은 라이브러리와 쉽게 통합됩니다 . 이를 통해 연구자는 정교한 그래프와 도표를 간편하게 문서에 포함시킬 수 있으며, 임상 프레젠테이션에서 시각적 효과를 극대화할 수 있습니다.",
    "crumbs": [
      "Quarto",
      "Introduction to Quarto"
    ]
  },
  {
    "objectID": "posts/R-setup/R_setup.html",
    "href": "posts/R-setup/R_setup.html",
    "title": "R setup",
    "section": "",
    "text": "R 공식사이트 CRAN (The Comprehensive R Archive Network, https://cran.r-project.org/index.html)에서 Documentation 중 Manuals 중 R Installation and Administration을 참고하는 것이 이상적이지만, 아래의 요약을 참고하여 설치 하셔도 됩니다.",
    "crumbs": [
      "R",
      "R setup"
    ]
  },
  {
    "objectID": "posts/R-setup/R_setup.html#r-설치안내문서",
    "href": "posts/R-setup/R_setup.html#r-설치안내문서",
    "title": "R setup",
    "section": "",
    "text": "R 공식사이트 CRAN (The Comprehensive R Archive Network, https://cran.r-project.org/index.html)에서 Documentation 중 Manuals 중 R Installation and Administration을 참고하는 것이 이상적이지만, 아래의 요약을 참고하여 설치 하셔도 됩니다.",
    "crumbs": [
      "R",
      "R setup"
    ]
  },
  {
    "objectID": "posts/R-setup/R_setup.html#r-설치-파일",
    "href": "posts/R-setup/R_setup.html#r-설치-파일",
    "title": "R setup",
    "section": "R 설치 파일",
    "text": "R 설치 파일\nCRAN (https://cran.r-project.org/index.html)에서 자신의 운영체제에 맞는 최신 버전을 다운로드 받아 설치합니다. 2024년 6월 14일 현재 64 bit 원도우용 설치파일은 R-4.4.1-win.exe 이 최신입니다.",
    "crumbs": [
      "R",
      "R setup"
    ]
  },
  {
    "objectID": "posts/R-setup/R_setup.html#r-설치경로",
    "href": "posts/R-setup/R_setup.html#r-설치경로",
    "title": "R setup",
    "section": "R 설치경로",
    "text": "R 설치경로\n윈도우의 경우 기본 설치폴더는 R 버전이 x.y.z이면 default로 C:\\\\Program Files\\\\R\\\\R-x.y.z로 되지만 연구회에서는 아래와 같이 추천합니다.\n\n\n\nR Install Option Window\n\nC:\\R\\R-4.4.1\n\n\n\n\n\n\n\n\nC:\\Program Files\\와 C:\\ 경로의 장단점\n\n\n\n\n\n\n대부분의 Windows 애플리케이션은 program Files 폴더에 설치되므로 시스템 소프트웨어와 애플리케이션을 관리하는 표준 위치이기 때문에 시스템의 정리가 용이합니다. 또한 Program Files 폴더는 특별한 시스템 권한을 요구하므로 일반 사용자가 이 폴더 내의 파일을 쉽게 변경할 수 없으므로, 악의적인 소프트웨어에 의한 변경으로부터 보호할 수 있습니다. 그러나 R 패키지를 설치하거나 업데이트할 때마다 관리자 권한이 필요하여 사용자가 R을 자유롭게 사용하고자 할 때 불편을 초래할 수 있고 `Program Files`는 경로 내에 공백을 포함하고 있어 일부 오래된 스크립트나 도구에서는 경로 내의 공백을 제대로 처리하지 못할 수 있어 문제가 발생할 수 있습니다.\nC:\\ 하부에 직접 설치 (예: C:\\R): 패키지 설치나 업데이트 시 관리자 권한을 요구하지 않고, 경로에 공백이 없기 때문에, 모든 스크립트나 프로그램에서 호환성 문제 없이 이 경로를 사용할 수 있습니다. 그러나 사용자 권한으로 설치된 프로그램은 보안이 상대적으로 약할 수 있으며, 악의적인 소프트웨어에 의해 변경되기 쉽고, 표준 설치 위치를 사용하지 않는 경우, 시스템의 소프트웨어와 애플리케이션이 분산되어 관리가 어려워질 수 있습니다.\n결론적으로, 설치 위치를 선택할 때는 보안, 사용 편의성, 시스템 관리의 용이성 등을 고려해야 하는데, 개인 사용자나 개발 환경에서는 C:\\R과 같은 사용자 지정 경로가 더 편리할 수 있으며, 기업 환경이나 보안이 중요한 상황에서는 C:\\Program Files 폴더 하에 설치하는 것이 더 적합할 수 있습니다.\n\n\n\n\n\n환경변수설정\n설치완료 후에는 시스템환경변수에 R 실행파일경로를 지정해 두어야 합니다.\n\n사용자나 RStdio와 같은 프로그램에서 R을 호출할 때나 package등을 설치할 때 시스템에서 R 실행파일의 설치경로를 알아야 원할히 진행됩니다.\nWin+R로 실행창을 열고 sysdm.cpl 을 입력하는 방식이 빠르며, 시스템속성 고급탭에서 환경변수를 선택한 후 시스템변수 목록에서 path를 선택한 후 새로만들기 또는 편집으로 R 실행파일의 경로를 지정해 주시면 됩니다.\n\n\n\n\nRun Dialog Box\n\nsysdm.cpl\n\n\n\n\n설치 검증\n\n정상적인 설치의 확인을 R을 실행시켜서 버전을 확인하시면 됩니다. 앞서에서 환경변수에 R의 실행파일의 경로를 등록해 두었기 때문에 R의 실행은 실행명령을 하는 폴더와는 무관하게 가능합니다. 구체적인 방법은, Win+R로 실행창을 열고 cmd 입력하여 커맨드창을 열고 “R” 을 입력하여 R을 실행시키고 커맨드창에 출력되는 R version이 일치하는지 확인하시면 됩니다.\n\n\n\n\nRun Dialog Box\n\ncmd\n\n\n\n\n\nCommand Prompt\n\nR",
    "crumbs": [
      "R",
      "R setup"
    ]
  },
  {
    "objectID": "posts/R-setup/R_setup.html#rtools-설치",
    "href": "posts/R-setup/R_setup.html#rtools-설치",
    "title": "R setup",
    "section": "Rtools 설치",
    "text": "Rtools 설치\n\nRtools 기능과 역할\nRtools는 R 프로그래밍 언어와 관련된 개발 도구 모음으로, 주로 Windows 운영 체제에서 사용됩니다. Rtools의 주요 역할과 기능은 다음과 같습니다:\n\n패키지 컴파일 및 설치: R 패키지를 설치하거나 업데이트할 때, 특히 CRAN에서 제공하는 패키지 중 일부는 소스 코드 형태로 제공됩니다. 이 경우 Rtools는 해당 소스 코드를 컴파일하여 설치할 수 있도록 도와줍니다.\nGNU 빌드 도구 제공: Rtools는 GCC(gnu 컴파일러 컬렉션), make, tar, git 등과 같은 GNU 빌드 도구를 포함하고 있어, Windows 환경에서도 리눅스와 유사한 빌드 환경을 제공합니다.\nR 패키지 개발 지원: R 패키지를 개발하는 과정에서 필요한 다양한 도구와 라이브러리를 제공합니다. 특히, C/C++ 코드와 연동되는 R 패키지를 개발할 때 유용합니다.\n명령줄 도구: 명령줄에서 R 및 관련 작업을 수행할 수 있는 도구들을 제공합니다. 이를 통해 보다 정교하고 복잡한 작업을 자동화할 수 있습니다.\n\n\n\n설치 파일\nRtools의 설치파일도 역시 CRAN(https://cran.r-project.org/index.html)에서 다운로드 하시면 되고, 2024년 6월 14일 현재 원도우의 경우 rtools44-6104-6039.exe가 최신 설치파일입니다.\n\n\n설치 경로\n설치경로 디폴트경로인 C: 드라이브 루트가 권장됩니다 (예시 C:\\rtools44). 시스템환경변수에서 Rtools 실행파일의 경로설정은 설치과정에서 자동으로 됩니다. (안되면 수동으로 설정하시길 바랍니다.)\n\n\n설치 검증\n시스템환경변수에 실행파일의 경로설정 확인은 R 콘솔에서 Sys.which(“make”) 실행하여 설치경로를 제대로 반환하면 성공임을 알 수 있습니다.",
    "crumbs": [
      "R",
      "R setup"
    ]
  },
  {
    "objectID": "posts/R-setup/R_setup.html#r-매뉴얼",
    "href": "posts/R-setup/R_setup.html#r-매뉴얼",
    "title": "R setup",
    "section": "R 매뉴얼",
    "text": "R 매뉴얼\nR을 심도있게 공부할려면 R 개발자들이 만든 매뉴얼 중 The R language definition과 R Internals이 적합할 것 같습니다 (https://cran.r-project.org/index.html). 하지만 처음부터 어려운 매뉴얼을 공부하는 것보다 자신의 자료를 분석하는데 필요한 명령과 함수들을 Help 기능 등으로 이해하는 방법으로 진행하는 것도 필요할 것 같습니다.",
    "crumbs": [
      "R",
      "R setup"
    ]
  },
  {
    "objectID": "posts/R-setup/R_setup.html#프로젝트-관리",
    "href": "posts/R-setup/R_setup.html#프로젝트-관리",
    "title": "R setup",
    "section": "프로젝트 관리",
    "text": "프로젝트 관리\n\n프로젝트 폴더 구조\n\n실행파일 설치 폴더\nR 새 버전으로 업데이트하면 드물겠지만 기존 코드나 사용 중인 패키지가 예상대로 작동하지 않을 수 있으며, 새 버전에서는 패키지의 지원이 변경될 수 있어 시스템의 안정성을 유지하기 위해 이전 버전의 실행파일을 유지하는 것도 필요합니다. 따라서 아래의 예시와 같은 폴더구조가 추천됩니다.\nC:\\R\\\n         ├─ R-4.4.0\\\n         └─ R-4.4.1\\",
    "crumbs": [
      "R",
      "R setup"
    ]
  },
  {
    "objectID": "posts/R-setup/R_setup.html#패키지-종속성-관리를-위한-renv",
    "href": "posts/R-setup/R_setup.html#패키지-종속성-관리를-위한-renv",
    "title": "R setup",
    "section": "패키지 종속성 관리를 위한 renv",
    "text": "패키지 종속성 관리를 위한 renv\n원래 R에서 패키지는 해당버전 R의 설치폴더 하부의 library 폴더에 설치됩니다. renv는 R 프로젝트에서 패키지 의존성을 관리하기 위해 설계된 도구로써, renv를 설치하고 활성화하면 해당 프로젝트 폴더 하부에 renv 폴더가 만들어지고, 그 하부에 패키지를 설치하게 됩니다. 또한 설치된 패키지들의 정보를 renv.lock 파일에 관리하게 됩니다. 이러한 방법으로 R에서는 프로젝트별로 패키지를 관리할 수 있으므로 필자를 이를 추천합니다.\nRStudio에서 새로운 프로젝트를 생성할 때 renv 사용여부를 check하면 자동으로 설정됩니다.\n사용법에 대해서는 https://rstudio.github.io/renv/articles/renv.html 참고하시길 바랍니다.",
    "crumbs": [
      "R",
      "R setup"
    ]
  },
  {
    "objectID": "posts/Resources/introduction_to_resources.html",
    "href": "posts/Resources/introduction_to_resources.html",
    "title": "Introduction to Resources",
    "section": "",
    "text": "연구회에 도움이 되는 medical (big) data resource들을 소개합니다.",
    "crumbs": [
      "Resources",
      "Introduction to Resources"
    ]
  },
  {
    "objectID": "posts/statistics/introduction_to_statistics.html",
    "href": "posts/statistics/introduction_to_statistics.html",
    "title": "Introduction to statistics",
    "section": "",
    "text": "R에서 사용되는 통계의 이론에 대해 소개합니다.",
    "crumbs": [
      "Statistics",
      "Introduction to statistics"
    ]
  },
  {
    "objectID": "posts/Utilities/introduction_to_utilities.html",
    "href": "posts/Utilities/introduction_to_utilities.html",
    "title": "Introduction to Utilities",
    "section": "",
    "text": "연구회에 도움이 되는 open source program들을 소개합니다.",
    "crumbs": [
      "Utilities",
      "Introduction to Utilities"
    ]
  }
]